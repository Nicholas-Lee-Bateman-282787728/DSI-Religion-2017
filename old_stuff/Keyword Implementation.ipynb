{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setKeywords(self,method='adjAdv',wordCount=10,startCount=0):\n",
    "        '''\n",
    "        function to automatically assign keywords if manual ones have not been assigned\n",
    "        \n",
    "        Inputs\n",
    "        ======\n",
    "        method: string\n",
    "            Method used to pick automatically defined keywords. Choose from:\n",
    "            adjAdv- picks most common adj and adv in text (default and \n",
    "                catch if other method doesn't exist)\n",
    "            judgement-Under development\n",
    "            SME - get a list of words from subject matter expert\n",
    "        wordCount: int\n",
    "            Number of keywords returned (default 10)\n",
    "        startCount: int\n",
    "            Index where keywords are extracted (default 0 i.e. start of list)\n",
    "        \n",
    "        Attributes\n",
    "        ==========\n",
    "        keywords: list\n",
    "            List of keywords automatically generated (can also be assigned \n",
    "            outside of function manually)\n",
    "        '''\n",
    "        #Save input values\n",
    "        self.keywordCount=wordCount\n",
    "        self.keywordStar=startCount\n",
    "        \n",
    "        #Judgement method\n",
    "        if method=='judgement':\n",
    "            posList=nounList+tagFilterList\n",
    "            #Define target dict\n",
    "            targetDict={}\n",
    "            for fileName in self.fileList:\n",
    "                for judgementStr in self.judgements[fileName]:\n",
    "                    tagList=tagger.tag(nltk.word_tokenize(judgementStr))\n",
    "            \n",
    "                    \n",
    "                    #Loop through each tag in list and get count of tag and word\n",
    "                    for tag in tagList:\n",
    "                        if tag[1] in posList:\n",
    "                            word=str.lower(''.join([c for c in tag[0] if c not in string.punctuation]))\n",
    "                            #Stem words if useStem True\n",
    "                            newStopWords=stopWords\n",
    "                            if self.useStem:\n",
    "                                word=stemmer.stem(word)\n",
    "                                newStopWords=[stemmer.stem(x) for x in stopWords]\n",
    "                             \n",
    "                            #Remove stopwords if useStopwords ==False\n",
    "                            if not self.useStopwords: \n",
    "                                newStopWords.append(\"\")\n",
    "\n",
    "                                \n",
    "                            #Filter out codecerrors\n",
    "                            if word not in ['codecerror']+[' ']+newStopWords:\n",
    "                                try:\n",
    "                                    targetDict[word]=targetDict[word]+1\n",
    "                                except:\n",
    "                                    targetDict[word]=1\n",
    "            #Create data frame with counts and sort\n",
    "            targetDF=pd.DataFrame([[k,v] for k,v in targetDict.items()],columns=['word','count'])\n",
    "            targetDF.sort(['count'],inplace=True,ascending=False)\n",
    "            \n",
    "            #Create keywords based on startCount and wordCount\n",
    "            self.keywords=list(targetDF['word'])[startCount:wordCount+startCount]\n",
    "            \n",
    "        #Default to 'adjAdv'\n",
    "        elif method=='adjAdv':\n",
    "            #Get total text string\n",
    "            txtString=''.join([x for x in self.rawText.values()])\n",
    "            \n",
    "            #Get total tag list\n",
    "            tagList=tagger.tag(nltk.word_tokenize(txtString))\n",
    "            \n",
    "            #Define target dict\n",
    "            targetDict={}\n",
    "            \n",
    "            #Loop through each tag in list and get count of tag and word\n",
    "            for tag in tagList:\n",
    "                if tag[1] in tagFilterList:\n",
    "                    word=str.lower(''.join([c for c in tag[0] if c not in string.punctuation]))\n",
    "                    #Filter out codecerrors\n",
    "                    if word != 'codecerror':\n",
    "                        try:\n",
    "                            targetDict[word]=targetDict[word]+1\n",
    "                        except:\n",
    "                            targetDict[word]=1\n",
    "        \n",
    "            #Create data frame with counts and sort\n",
    "            targetDF=pd.DataFrame([[k,v] for k,v in targetDict.items()],columns=['word','count'])\n",
    "            targetDF.sort(['count'],inplace=True,ascending=False)\n",
    "            \n",
    "            #Create keywords based on startCount and wordCount\n",
    "            self.keywords=list(targetDF['word'])[startCount:wordCount+startCount]\n",
    "        elif method == 'SME':\n",
    "            \n",
    "        else:\n",
    "            print('ERROR: Method not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which group would you like to look at? DSI\n",
      "['big', 'data', 'capstone', 'advisor', 'graduate', 'dell', 'science', 'career']\n"
     ]
    }
   ],
   "source": [
    "# Keyword Implementation Prototype\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Pull data from the csv file\n",
    "filepath = \"/Users/samanthagarofalo/Documents/Data Science/Capstone/Keywords.csv\"\n",
    "\n",
    "# Create dataframe with manually entered keywords\n",
    "targetDF = pd.read_csv(filepath)\n",
    "\n",
    "# User input to select the group that we are looking at keywords for\n",
    "group = input(\"Which group would you like to look at? \")\n",
    "\n",
    "keywords = list(targetDF.Keywords[targetDF['Group'] == group])\n",
    "\n",
    "for element in keywords:\n",
    "    keywords = element.split(' ')\n",
    "    \n",
    "print(keywords)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
