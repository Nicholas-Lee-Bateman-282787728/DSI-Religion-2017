#library(glmnet)
#dfm <- as.matrix(df)
x <- model.matrix(y~., data=df)[,2:ncol(df)]
y <- df$y
df.ridge <- glmnet(x, y, alpha=0)
## Ridge coefficicent estimates
#coef(df.ridge)
# pick optimal lambda with cross-validated test set MSE
set.seed (seed)
cv.out = cv.glmnet(x, y, alpha=0, nfolds=nrow(x))
plot(cv.out)
bestlam=cv.out$lambda.min
print(paste("Best Lambda:", bestlam))
## Create the ridge trace plot
plot(df.ridge,xvar="lambda",label=TRUE)
abline(v=log(bestlam), lty=2)
## fit with best lambda
best.ridge <- glmnet(x, y, alpha=0, lambda=bestlam)
## look at residual sum of squares
ridge.preds <- predict(best.ridge ,s=bestlam ,newx=x)
orig.preds <- predict(lm(y ~ x))
ridge.SSres <- sum( (y - ridge.preds)^2 )
orig.SSres <- sum( (y - orig.preds)^2 )
print("SSres")
print(paste("Ridge:", ridge.SSres))
print(paste("Original:", orig.SSres))
## R^2
ridge.R2 <- sum((ridge.preds - mean(y))^2) / sum((y - mean(y))^2)
orig.R2 <- sum((orig.preds - mean(y))^2) / sum((y - mean(y))^2)
print("R^2")
print(paste("Ridge:", ridge.R2))
print(paste("Original:", orig.R2))
# check a held out test set MSE
train=sample(1:nrow(df), nrow(df)*.75)
trainx <- x[train, ]
trainy <- y[train]
testx <- x[-train, ]
testy <- y[-train]
tt.ridge <- glmnet(trainx, trainy, alpha=0, lambda=bestlam)
tt.orig <- lm(y ~ ., data=df[train,])
# print test MSE
MSE.ridge <- sum((testy - predict(tt.ridge,s=bestlam,newx=testx))^2) / nrow(testx)
MSE.orig <- sum((testy - predict(tt.orig,newdata=df[-train,]))^2) / nrow(testx)
print("Test Set MSE")
print(paste("Ridge:", MSE.ridge))
print(paste("Original:", MSE.orig))
#return the optimal model
glmnet(x, y, alpha=0, lambda=bestlam)
}
lassoit <- function(df, seed = 1) { ### RESPONSE MUST BE NAMED 'y'
#library(car)
#library(glmnet)
#dfm <- as.matrix(df)
x <- model.matrix(y~., data=df)[,2:ncol(df)]
y <- df$y
df.lasso <- glmnet(x, y, alpha=1)
## lasso coefficicent estimates
#coef(df.lasso)
# pick optimal lambda with cross-validated test set MSE
set.seed (seed)
cv.out = cv.glmnet(x, y, alpha=1, nfolds=nrow(x))
plot(cv.out)
bestlam=cv.out$lambda.min
print(paste("Best Lambda:", bestlam))
## Create the lasso trace plot
plot(df.lasso,xvar="lambda",label=TRUE)
abline(v=log(bestlam), lty=2)
## fit with best lambda
best.lasso <- glmnet(x, y, alpha=1, lambda=bestlam)
## look at residual sum of squares
lasso.preds <- predict(best.lasso ,s=bestlam ,newx=x)
orig.preds <- predict(lm(y ~ x))
lasso.SSres <- sum( (y - lasso.preds)^2 )
orig.SSres <- sum( (y - orig.preds)^2 )
print("SSres")
print(paste("Lasso:", lasso.SSres))
print(paste("Original:", orig.SSres))
## R^2
lasso.R2 <- sum((lasso.preds - mean(y))^2) / sum((y - mean(y))^2)
orig.R2 <- sum((orig.preds - mean(y))^2) / sum((y - mean(y))^2)
print("R^2")
print(paste("Lasso:", lasso.R2))
print(paste("Original:", orig.R2))
# check a held out test set MSE
train=sample(1:nrow(df), nrow(df)*.75)
trainx <- x[train, ]
trainy <- y[train]
testx <- x[-train, ]
testy <- y[-train]
tt.lasso <- glmnet(trainx, trainy, alpha=1, lambda=bestlam)
tt.orig <- lm(y ~ ., data=df[train,])
# print test MSE
MSE.lasso <- sum((testy - predict(tt.lasso,s=bestlam,newx=testx))^2) / nrow(testx)
MSE.orig <- sum((testy - predict(tt.orig,newdata=df[-train,]))^2) / nrow(testx)
print("Test Set MSE")
print(paste("Lasso:", MSE.lasso))
print(paste("Original:", MSE.orig))
#return the optimal model
glmnet(x, y, alpha=1, lambda=bestlam)
}
## cross validate with the ridge and lasso
cv.rl <- function(train, k=5, style='ridge') { ## vars should be a character vector of variable names/combinations
# the function to do the cross-validation
theCV <- function(train, k) {
#make column for preds
train$preds <- numeric(nrow(train))
#randomize the indexes
nums <- sample(row.names(train), nrow(train))
#split the indexes into k groups
nv <- split(nums, cut(seq_along(nums), k, labels = FALSE))
#subset the training data into k folds
trainlist <- list()
for (i in 1:k) {
trainlist[[i]] <- train[nv[[i]], ]
}
#trainlist
#run on each fold
for (i in 1:k) {
ftrainlist <- trainlist[-i]
ftrain <- ftrainlist[[1]]
for (j in 2:length(ftrainlist)) {
ftrain <- rbind(ftrain, ftrainlist[[j]])
}
####
#mod <- lm(as.formula(paste(form,' - preds')), data = ftrain) ### the model
#trainlist[[i]]$preds <- predict(mod, newdata = trainlist[[i]])
####
if (style=='lasso') {
mod <- lassoit(ftrain)
} else {
mod <- ridgeit(ftrain)
}
#
rlpred <- function(mod, newdata) {
if('y' %in% names(newdata)) {
newdata <- subset(newdata, select = -y) # get rid of y, if it's included
}
mm <- model.matrix(~., data=newdata)[,2:(ncol(newdata)+1)]
as.numeric(predict(mod, newx=mm))
}
#
trainlist[[i]]$preds <- rlpred(mod, trainlist[[i]])
#####
}
#reassemble
cvdata <- ftrainlist[[1]]
for (j in 2:length(trainlist)) {
cvdata <- rbind(cvdata, trainlist[[j]])
}
# cross-validated test set MSE
###degfree <- nrow(cvdata) - ncol(subset(cvdata, select = -c(y, preds))) ##just use n?
MSE <- sum((cvdata$y-cvdata$preds)^2) / nrow(cvdata)
##training set stats
m <- lm(as.formula(paste(form,' - preds')), data = train)
# adjusted R-squared
aR2 <- summary(m)$adj.r.squared
# p-value from F-stat
lmp <- function (modelobject) {
if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
f <- summary(modelobject)$fstatistic
p <- pf(f[1],f[2],f[3],lower.tail=F)
attributes(p) <- NULL
return(p)
}
p <- lmp(m)
list(form, MSE, aR2, p)
}
#
# now call that function on all the variable combinations
#dfM <- sapply(vars, theCV, train=train, k=k, simplify = 'array', USE.NAMES = F)
dfM <- theCV(train, k)
df <- data.frame(formula = unlist(dfM[1,]),
MSE = unlist(dfM[2,]),
adj.R2 = unlist(dfM[3,]),
p.value = unlist(dfM[4,]), stringsAsFactors = F)
df
}
cv.rl(train)
library(gdata)
library(car)
library(glmnet)
## cross validate with the ridge and lasso
cv.rl <- function(train, k=5, style='ridge') { ## vars should be a character vector of variable names/combinations
# the function to do the cross-validation
theCV <- function(train, k) {
#make column for preds
train$preds <- numeric(nrow(train))
#randomize the indexes
nums <- sample(row.names(train), nrow(train))
#split the indexes into k groups
nv <- split(nums, cut(seq_along(nums), k, labels = FALSE))
#subset the training data into k folds
trainlist <- list()
for (i in 1:k) {
trainlist[[i]] <- train[nv[[i]], ]
}
#trainlist
#run on each fold
for (i in 1:k) {
ftrainlist <- trainlist[-i]
ftrain <- ftrainlist[[1]]
for (j in 2:length(ftrainlist)) {
ftrain <- rbind(ftrain, ftrainlist[[j]])
}
####
#mod <- lm(as.formula(paste(form,' - preds')), data = ftrain) ### the model
#trainlist[[i]]$preds <- predict(mod, newdata = trainlist[[i]])
####
if (style=='lasso') {
mod <- lassoit(ftrain)
} else {
mod <- ridgeit(ftrain)
}
#
rlpred <- function(mod, newdata) {
if('y' %in% names(newdata)) {
newdata <- subset(newdata, select = -y) # get rid of y, if it's included
}
mm <- model.matrix(~., data=newdata)[,2:(ncol(newdata)+1)]
as.numeric(predict(mod, newx=mm))
}
#
trainlist[[i]]$preds <- rlpred(mod, trainlist[[i]])
#####
}
#reassemble
cvdata <- ftrainlist[[1]]
for (j in 2:length(trainlist)) {
cvdata <- rbind(cvdata, trainlist[[j]])
}
# cross-validated test set MSE
###degfree <- nrow(cvdata) - ncol(subset(cvdata, select = -c(y, preds))) ##just use n?
MSE <- sum((cvdata$y-cvdata$preds)^2) / nrow(cvdata)
##training set stats
m <- lm(as.formula(paste(form,' - preds')), data = train)
# adjusted R-squared
aR2 <- summary(m)$adj.r.squared
# p-value from F-stat
lmp <- function (modelobject) {
if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
f <- summary(modelobject)$fstatistic
p <- pf(f[1],f[2],f[3],lower.tail=F)
attributes(p) <- NULL
return(p)
}
p <- lmp(m)
list(form, MSE, aR2, p)
}
#
# now call that function on all the variable combinations
#dfM <- sapply(vars, theCV, train=train, k=k, simplify = 'array', USE.NAMES = F)
dfM <- theCV(train, k)
df <- data.frame(formula = unlist(dfM[1,]),
MSE = unlist(dfM[2,]),
adj.R2 = unlist(dfM[3,]),
p.value = unlist(dfM[4,]), stringsAsFactors = F)
df
}
cv.rl(train)
modrl <- ridgeit(train)
## cross validate with the ridge and lasso
cv.rl <- function(train, k=5, style='ridge') { ## vars should be a character vector of variable names/combinations
# the function to do the cross-validation
theCV <- function(train, k) {
#make column for preds
train$preds <- numeric(nrow(train))
#randomize the indexes
nums <- sample(row.names(train), nrow(train))
#split the indexes into k groups
nv <- split(nums, cut(seq_along(nums), k, labels = FALSE))
#subset the training data into k folds
trainlist <- list()
for (i in 1:k) {
trainlist[[i]] <- train[nv[[i]], ]
}
#trainlist
#run on each fold
for (i in 1:k) {
ftrainlist <- trainlist[-i]
ftrain <- ftrainlist[[1]]
for (j in 2:length(ftrainlist)) {
ftrain <- rbind(ftrain, ftrainlist[[j]])
}
####
#mod <- lm(as.formula(paste(form,' - preds')), data = ftrain) ### the model
#trainlist[[i]]$preds <- predict(mod, newdata = trainlist[[i]])
####
if (style=='lasso') {
mod <- lassoit(ftrain)
} else {
mod <- ridgeit(ftrain)
}
#
rlpred <- function(mod, newdata) {
if('y' %in% names(newdata)) {
newdata <- subset(newdata, select = -y) # get rid of y, if it's included
}
mm <- model.matrix(~., data=newdata)[,2:(ncol(newdata)+1)]
as.numeric(predict(mod, newx=mm))
}
#
trainlist[[i]]$preds <- rlpred(mod, trainlist[[i]])
#####
}
#reassemble
cvdata <- ftrainlist[[1]]
for (j in 2:length(trainlist)) {
cvdata <- rbind(cvdata, trainlist[[j]])
}
# cross-validated test set MSE
###degfree <- nrow(cvdata) - ncol(subset(cvdata, select = -c(y, preds))) ##just use n?
MSE <- sum((cvdata$y-cvdata$preds)^2) / nrow(cvdata)
# ##training set stats
# #m <- lm(as.formula(paste(form,' - preds')), data = train)
# if (style=='lasso') {
#   m <- lassoit(train)
# } else {
#   m <- ridgeit(train)
# }
# # adjusted R-squared
# aR2 <- summary(m)$adj.r.squared
#
# # p-value from F-stat
# lmp <- function (modelobject) {
#   if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
#   f <- summary(modelobject)$fstatistic
#   p <- pf(f[1],f[2],f[3],lower.tail=F)
#   attributes(p) <- NULL
#   return(p)
# }
# p <- lmp(m)
#
# list(form, MSE, aR2, p)
MSE
}
#
# # now call that function on all the variable combinations
# dfM <- sapply(vars, theCV, train=train, k=k, simplify = 'array', USE.NAMES = F)
#
# df <- data.frame(formula = unlist(dfM[1,]),
#                  MSE = unlist(dfM[2,]),
#                  adj.R2 = unlist(dfM[3,]),
#                  p.value = unlist(dfM[4,]), stringsAsFactors = F)
# df
#
cvMSE <- theCV(train, k)
print(paste("cross-validated MSE with", style, ":", cvMSE))
cvMSE
}
cv.rl(train)
setwd("~/Documents/DSI/Capstone/DSI-Religion-2017")
library(ggplot2)
signalDF <- read.csv('./pythonOutput/run1/cleanedOutput/coco_3_cv_3_netAng_30_sc_0/run0/masterOutput.csv', stringsAsFactors = F)
for (i in 1:nrow(signalDF)) {
signalDF$groupName[i] <- unlist(strsplit(signalDF$groupId[i], "_"))[1]
}
### BY GROUP
ggplot(signalDF, aes(x=avgSD, y =avgEVC, colour = groupName)) + geom_point()
ggplot(signalDF, aes(x=avgSD, y =judgementFrac, colour = groupName)) + geom_point()
### RANKINGS
ranks <- data.frame(groupName=c('WBC', 'PastorAnderson', 'NaumanKhan', 'DorothyDay', 'JohnPiper', 'Shepherd',
'Rabbinic', 'Unitarian', 'MehrBaba','NawDawg','SeaShepherds','IntegralYoga','Bahai'),
groupRank=c(1,2,3,4,4,4,6,7,8,4,2,7,6))
DF <- merge(signalDF, ranks, by = "groupName")
## RANKINGS discrete
DF$rankDiscrete <- as.factor(DF$groupRank)
ggplot(DF, aes(x=avgSD, y =judgementFrac, colour = rankDiscrete)) + geom_point()
## RANKINGS continuous
mid = 4
## zoomed in
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" ) + xlim(0,1) + ylim(0,1)
ggplot(DF, aes(x=perPos, y =perNeg, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=judgementFrac, y =judgementCount, colour = groupName)) + geom_point()
## Judgements by RANK ######Not really a difference...
ggplot(DF, aes(x=judgementFrac, y =judgementCount, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" ) + xlim(0,1) + ylim(0,1)
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=perPos, y =perNeg, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=judgementFrac, y =judgementCount, colour = groupName)) + geom_point()
ggplot(DF, aes(x=judgementCount, y =judgementFrac, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=judgementCount, y =judgementFrac, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="yellow", high="black", space ="Lab" )
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
## scaled to 0 and 1
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" ) + xlim(0,1) + ylim(0,1)
ggplot(DF, aes(x=judgementCount, y =judgementFrac, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="yellow", high="black", space ="Lab" )
ggplot(DF, aes(x=perPos, y =perNeg, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
ggplot(DF, aes(x=avgSD, y =avgEVC, colour = groupRank)) + geom_point() + scale_color_gradient2(midpoint=mid, low="red", mid="white", high="blue", space ="Lab" )
setwd("~/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF")
wikiTrim <- function(oldDir, newDir, len, links) {
start = Sys.time()
#get list of all files
files <- list.files(path=oldDir)
#make new directory to put filtered files in
if (!dir.exists(newDir)) {
dir.create(newDir)
} else {
warning(paste(newDir, "already exists. Adding files to pre-existing directory. Duplicate files will be overwritten."))
}
#
for (j in 1:length(files)) {
#load each file
con <- file(paste(oldDir, files[j], sep="/"))
wiki <- readLines(con)
close(con)
#test file against len and links
wiki <- unlist(strsplit(wiki, ":LINKNUM:"))
if(nchar(wiki[1]) > len & as.numeric(wiki[2]) > links) {
write(paste(wiki, collapse = " :LINKNUM:"),
paste(newDir,files[j], sep="/"))
}
}
print(paste("ALL DONE with", newDir, start - Sys.time()))
}
setwd("~/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF")
wikiTrim("wiki-articles-test", "wiki-articles-30k300-test", 30000, 300) # cut to
setwd('/Volumes/SethBoxMini/Silverchair/A1-taxonomy-project/wikipedia/json-wikipedia')
wikiTrim <- function(oldDir, newDir, len, links) {
start = Sys.time()
#get list of all files
files <- list.files(path=oldDir)
#make new directory to put filtered files in
if (!dir.exists(newDir)) {
dir.create(newDir)
} else {
warning(paste(newDir, "already exists. Adding files to pre-existing directory. Duplicate files will be overwritten."))
}
#
for (j in 1:length(files)) {
#load each file
con <- file(paste(oldDir, files[j], sep="/"))
wiki <- readLines(con)
close(con)
#test file against len and links
wiki <- unlist(strsplit(wiki, ":LINKNUM:"))
if(nchar(wiki[1]) > len & as.numeric(wiki[2]) > links) {
write(paste(wiki, collapse = " :LINKNUM:"),
paste(newDir,files[j], sep="/"))
}
}
print(paste("ALL DONE with", newDir, Sys.time() - start))
}
#setwd("~/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF")
#wikiTrim("wiki-articles-test", "wiki-articles-30k300-test", 30000, 300) # cut to 90% on test
setwd('/Volumes/SethBoxMini/Silverchair/A1-taxonomy-project/wikipedia/json-wikipedia')
wikiTrim("wiki-articles", "wiki-articles-30k300", 30000, 300) # cut to 90% on test
wikiTrim("wiki-articles", "wiki-articles-15k200", 15000, 200) # cut to 60% on test
wikiTrim("wiki-articles", "wiki-articles-10k50", 10000, 50) # cut to %30 on test
wikiTrim <- function(oldDir, newDir, len, links) {
start = Sys.time()
#get list of all files
files <- list.files(path=oldDir)
#make new directory to put filtered files in
if (!dir.exists(newDir)) {
dir.create(newDir)
} else {
warning(paste(newDir, "already exists. Adding files to pre-existing directory. Duplicate files will be overwritten."))
}
#
for (j in 1:length(files)) {
#load each file
con <- file(paste(oldDir, files[j], sep="/"))
wiki <- readLines(con)
close(con)
#test file against len and links
if(nchar(wiki) > len) {
write(wiki, paste(newDir,files[j], sep="/"))
}
}
print(paste("ALL DONE with", newDir, Sys.time() - start))
}
#setwd("~/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF")
#wikiTrim("wiki-articles-test", "wiki-articles-30k300-test", 30000, 300) # cut to 90% on test
setwd('/Volumes/SethBoxMini/Silverchair/A1-taxonomy-project/wikipedia/json-wikipedia')
wikiTrim("wiki-articles", "wiki-articles-30k300", 30000) # cut to 90% on test
wikiTrim("wiki-articles", "wiki-articles-15k200", 15000, 200) # cut to 60% on test
wikiTrim("wiki-articles", "wiki-articles-10k50", 10000, 50) # cut to %30 on test
setwd("~/Documents/DSI/Capstone/DSI-Religion-2017")
wikiTrimNoLink <- function(oldDir, newDir, len, links) {
start = Sys.time()
#get list of all files
files <- list.files(path=oldDir)
#make new directory to put filtered files in
if (!dir.exists(newDir)) {
dir.create(newDir)
} else {
warning(paste(newDir, "already exists. Adding files to pre-existing directory. Duplicate files will be overwritten."))
}
#
for (j in 1:length(files)) {
#load each file
con <- file(paste(oldDir, files[j], sep="/"))
wiki <- readLines(con)
close(con)
#test file against len and links
if(nchar(wiki) > len) {
write(wiki, paste(newDir,files[j], sep="/"))
}
}
print(paste("ALL DONE with", newDir, Sys.time() - start))
}
setwd('/Volumes/SethBoxMini/Silverchair/A1-taxonomy-project/wikipedia/json-wikipedia')
wikiTrimNoLink("wiki-articles", "wiki-articles-5k", 5000) #
wikiTrimNoLink("wiki-articles", "wiki-articles-7500", 7500) #
setwd("~/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF")
wikiTrimNoLink("wiki-articles", "wiki-articles-15k", 15000) # cut to 60% on test
wikiTrimNoLink("wiki-articles", "wiki-articles-10k", 10000) # cut to %30 on test
setwd('/Volumes/SethBoxMini/Silverchair/A1-taxonomy-project/wikipedia/json-wikipedia')
wikiTrimNoLink("wiki-articles", "wiki-articles-15k", 15000) # cut to 60% on test
wikiTrimNoLink("wiki-articles", "wiki-articles-10k", 10000) # cut to %30 on test
setwd("~/Documents/DSI/Capstone/DSI-Religion-2017")
