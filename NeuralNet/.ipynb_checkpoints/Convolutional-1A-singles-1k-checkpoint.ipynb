{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lingualTF as la\n",
    "\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "# REPLACE THESE WITH CORRECT PATHS #\n",
    "####################################\n",
    "docsFolder = '/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/data_dsicap_single/'\n",
    "docRanks = pd.read_csv('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/refData/docRanks.csv')\n",
    "docRanks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupName</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>WBC347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>WBC410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>WBC418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>WBC421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>WBC422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    groupName  rank\n",
       "273    WBC347     2\n",
       "274    WBC410     1\n",
       "275    WBC418     1\n",
       "276    WBC421     1\n",
       "277    WBC422     1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docRanks = docRanks.ix[~((docRanks['groupName']=='YV03')|(docRanks['groupName']=='YV04'))]\n",
    "docRanks.reset_index(inplace=True, drop=True)\n",
    "docRanks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocab from this list http://www.wordfrequency.info/5k_lemmas_download.asp\n",
    "w5k = pd.read_table('refData/5000-words.txt')\n",
    "\n",
    "## process words to match lingualObject processing\n",
    "w5k['Word'] = la.cleanTokens(w5k['Word'])\n",
    "\n",
    "vocab = list(w5k['Word'][:1000]) ##### USE ONLY THE TOP 1000 (we could try more later)\n",
    "\n",
    "# add UNKNOWN and VALUE tokens\n",
    "vocab += ['UNK', 'VAL']\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'c', 'e', 'd', 'i', 'j', 'm', 'n', 'p', 'r', 'u', 't', 'v', 'x']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parts of Speech ##### Thought about using only POS + UNK + VAL, could be an option...\n",
    "pos = list(set(w5k['POS']))\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docToNumpy(doc, vocab, keywordCount=20, lengthThreshold=500, warnOnPad=False):\n",
    "    # tokenize, etc. document\n",
    "    self = la.lingualObject(doc)\n",
    "    fileName = self.fileList[0]\n",
    "    # set the keywords\n",
    "    self.setKeywords(wordCount=keywordCount)\n",
    "    # create array of each word in doc with len(vocab)-dimensional sparse one-hot vectors\n",
    "    sparse = [la.wordToInd(word, vocab, self.keywords) for word in self.tokens[fileName]]\n",
    "    # if less words than the threshold, pad with UNK\n",
    "    if len(sparse) < lengthThreshold:\n",
    "        if warnOnPad==True:\n",
    "            print('PADDING: ' + doc + ' has only ' + str(len(sparse)) + ' words. Adding ' + str((lengthThreshold - len(sparse))) + ' UNKs.')\n",
    "        sparse += [(len(vocab) - 2)] * (lengthThreshold - len(sparse))\n",
    "    # create dense array of zeros, then fill in the correct ones\n",
    "    docArr = np.zeros((lengthThreshold,len(vocab)), dtype=np.int) # default is 500, 1002\n",
    "    for i in range(0, lengthThreshold):\n",
    "        docArr[i][sparse[i]] = 1\n",
    "    # \n",
    "    return docArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data (set up X and Y as numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [02:11<00:00,  1.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(278, 500, 1002)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct X matrix FROM SCRATCH\n",
    "X = [docToNumpy(docsFolder + adoc + '/raw/' + adoc + '.txt', vocab) for adoc in tqdm(docRanks['groupName'])]\n",
    "X = np.array([docArr for docArr in X if docArr is not None])\n",
    "np.save('/Users/Seth/Documents/DSI/Capstone/big-data/X-single-1k-278.npy', X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 500, 1002)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR load X matrix from disk (already processed)\n",
    "#X = np.load('/Users/Seth/Documents/DSI/Capstone/big-data/X-single-1k-193.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct Y matrix\n",
    "Y = np.array([np.array([y]) for y in docRanks['rank']])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 9)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a Y vector for classification\n",
    "Y_cat = np.zeros((len(Y),9))\n",
    "\n",
    "for i in range(0,len(Y)):\n",
    "    Y_cat[i][Y[i]-1] = Y[i]\n",
    "\n",
    "Y_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([223,  20, 163,  29, 254, 237,  53, 174, 151, 156,\n",
       "            ...\n",
       "             96, 225, 214,  57, 123, 106,  83,  17, 230,  98],\n",
       "           dtype='int64', length=278)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the seed if you want to\n",
    "np.random.seed(123)\n",
    "#\n",
    "shuf = docRanks.sample(frac=1).index\n",
    "shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitPoint = int(len(shuf) * .8)\n",
    "#train = docRanks.iloc[shuf[:splitPoint]]\n",
    "#test = docRanks.iloc[shuf[(splitPoint+1):]]\n",
    "splitPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[shuf[:splitPoint]]\n",
    "Y_train = Y[shuf[:splitPoint]]\n",
    "Y_cat_train = Y_cat[shuf[:splitPoint]]\n",
    "\n",
    "X_test = X[shuf[(splitPoint+1):]]\n",
    "Y_test = Y[shuf[(splitPoint+1):]]\n",
    "Y_cat_test = Y_cat[shuf[(splitPoint+1):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## train the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 5, border_mode='same', input_shape=(X.shape[1],X.shape[2]), activation='relu'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same', activation='relu'))\n",
    "model.add(AveragePooling1D(pool_length=2))\n",
    "model.add(Convolution1D(32, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#\n",
    "#model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_cross_entropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 6s - loss: 10.7537 - mean_absolute_error: 2.7335     \n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 6s - loss: 4.5683 - mean_absolute_error: 1.6928     \n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 6s - loss: 3.3494 - mean_absolute_error: 1.4548     \n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 6s - loss: 3.7144 - mean_absolute_error: 1.5524     \n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 8s - loss: 3.3548 - mean_absolute_error: 1.4106     \n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 9s - loss: 3.3981 - mean_absolute_error: 1.4427     \n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 8s - loss: 3.5905 - mean_absolute_error: 1.4780     \n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 7s - loss: 3.5521 - mean_absolute_error: 1.5132     \n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 7s - loss: 4.2791 - mean_absolute_error: 1.6603     \n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 8s - loss: 4.0264 - mean_absolute_error: 1.5910     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1572f1510>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(data, labels, nb_epoch=10, batch_size=32) ### generic call from documentation\n",
    "model.fit(X_train, Y_train, nb_epoch=10, batch_size=32)\n",
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.2785804767500268, 1.414863161607222]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.57582235],\n",
       "       [ 3.57571745],\n",
       "       [ 3.57571578],\n",
       "       [ 3.57579255],\n",
       "       [ 3.57573724],\n",
       "       [ 3.57581782],\n",
       "       [ 3.5758729 ],\n",
       "       [ 3.57578802],\n",
       "       [ 3.5757606 ],\n",
       "       [ 3.57588077],\n",
       "       [ 3.57573581],\n",
       "       [ 3.57574964],\n",
       "       [ 3.57576323],\n",
       "       [ 3.57579875],\n",
       "       [ 3.57584596]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [6],\n",
       "       [9],\n",
       "       [5]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DSIacc(y_true, y_pred):\n",
    "    return float(len([i for i in range(len(y_pred)) if abs(y_true[i][0]-y_pred[i][0])<=1])/float(len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454545454545453"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## train the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 5, border_mode='same', input_shape=(X.shape[1],X.shape[2]), activation='relu'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same', activation='relu'))\n",
    "model.add(AveragePooling1D(pool_length=2))\n",
    "model.add(Convolution1D(32, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "#model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 11s - loss: 7.6788 - acc: 0.2883    \n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 11s - loss: 7.2954 - acc: 0.3018    \n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 10s - loss: 7.3005 - acc: 0.3018    \n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 11s - loss: 7.2220 - acc: 0.3018    \n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 10s - loss: 7.2110 - acc: 0.2883    \n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 10s - loss: 7.1892 - acc: 0.3018    \n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 10s - loss: 7.2505 - acc: 0.2973    \n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 10s - loss: 7.2113 - acc: 0.3018    \n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 10s - loss: 7.1738 - acc: 0.3018    \n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 10s - loss: 7.2260 - acc: 0.2883    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1658b18d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(data, labels, nb_epoch=10, batch_size=32) ### generic call from documentation\n",
    "#model.fit(X_train, Y_cat_train, nb_epoch=10, batch_size=32)\n",
    "model.fit(X_train, Y_cat_train, nb_epoch=10, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/55 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.5096577687696975, 0.30909090909090908]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert softmax vectors to class picks\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4], [4], [4], [4], [4], [4], [4], [4], [4], [4], [4], [4], [4], [4], [4]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702399,  0.00548415],\n",
       "       [ 0.04131708,  0.05839049,  0.17507198,  0.25584197,  0.12958422,\n",
       "         0.16597278,  0.08131333,  0.08702398,  0.00548415]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [visLang2]",
   "language": "python",
   "name": "Python [visLang2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
