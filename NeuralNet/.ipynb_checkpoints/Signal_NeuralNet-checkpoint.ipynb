{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if want to try tensor flow:\n",
    "\n",
    "source: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/multilayer_perceptron.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# signalOutput-coco_3_cv_3_netAng_30_twc_10_tfidfNoPro_pronoun_bin_1-OQD9U4.csv\n",
    "rawSignals = pd.read_csv('signalOutput-coco_3_cv_3_netAng_30_twc_10_tfidfNoPro_pronoun_bin_1-OQD9U4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docRanks = pd.read_csv('docRanks.csv')\n",
    "docRanks[['groupId']] = docRanks[['groupName']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(rawSignals.ix[:,:], docRanks.ix[:,1:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop('files', 1)\n",
    "data = data.drop('timeRun', 1)\n",
    "data = data.drop('keywords', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change to vector of binary scores\n",
    "data['one'] = 0\n",
    "condition = data['rank'] == 1\n",
    "data.loc[condition, 'one'] = 1\n",
    "data.loc[~condition, 'one'] = 0\n",
    "\n",
    "data['two'] = 0\n",
    "condition = data['rank'] == 2\n",
    "data.loc[condition, 'two'] = 1\n",
    "data.loc[~condition, 'two'] = 0\n",
    "\n",
    "data['three'] = 0\n",
    "condition = data['rank'] == 3\n",
    "data.loc[condition, 'three'] = 1\n",
    "data.loc[~condition, 'three'] = 0\n",
    "\n",
    "data['four'] = 0\n",
    "condition = data['rank'] == 4\n",
    "data.loc[condition, 'four'] = 1\n",
    "data.loc[~condition, 'four'] = 0\n",
    "\n",
    "data['five'] = 0\n",
    "condition = data['rank'] == 5\n",
    "data.loc[condition, 'five'] = 1\n",
    "data.loc[~condition, 'five'] = 0\n",
    "\n",
    "data['six'] = 0\n",
    "condition = data['rank'] == 6\n",
    "data.loc[condition, 'six'] = 1\n",
    "data.loc[~condition, 'six'] = 0\n",
    "\n",
    "data['seven'] = 0\n",
    "condition = data['rank'] == 7\n",
    "data.loc[condition, 'seven'] = 1\n",
    "data.loc[~condition, 'seven'] = 0\n",
    "\n",
    "data['eight'] = 0\n",
    "condition = data['rank'] == 8\n",
    "data.loc[condition, 'eight'] = 1\n",
    "data.loc[~condition, 'eight'] = 0\n",
    "\n",
    "data['nine'] = 0\n",
    "condition = data['rank'] == 9\n",
    "data.loc[condition, 'nine'] = 1\n",
    "data.loc[~condition, 'nine'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = data.ix[:,1:18]\n",
    "y = data.ix[:, 19:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.as_matrix()\n",
    "y = y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STANDARDIZE THE X-MATRIX - why do we do this?\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "class nn_MSECriterion:\n",
    "    def forward(self, predictions, labels):\n",
    "        return np.sum(np.square(predictions - labels))\n",
    "        \n",
    "    def backward(self, predictions, labels):\n",
    "        num_samples = labels.shape[0]\n",
    "        return num_samples * 2 * (predictions - labels)\n",
    "\n",
    "# activation function\n",
    "class nn_ReLU:\n",
    "    def forward(self, x):\n",
    "        if x > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def inverse:# to make predictions\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        if x > 0:\n",
    "            return np.multiply(1, gradOutput)\n",
    "        else:\n",
    "            return np.multiply(0, gradOutput)\n",
    "\n",
    "# linear layer\n",
    "class nn_Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # Initialized with random numbers from a gaussian N(0, 0.001)\n",
    "        self.weight = np.matlib.randn(input_dim, output_dim) * 0.01\n",
    "        self.bias = np.matlib.randn((1, output_dim)) * 0.01\n",
    "        self.gradWeight = np.zeros_like(self.weight)\n",
    "        self.gradBias = np.zeros_like(self.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return np.dot(x, self.weight) + self.bias\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # dL/dw = dh/dw * dL/dv\n",
    "        self.gradWeight = np.dot(x.T, gradOutput)\n",
    "        # dL/db = dh/db * dL/dv\n",
    "        self.gradBias = np.copy(gradOutput)\n",
    "        # return dL/dx = dh/dx * dL/dv\n",
    "        return np.dot(gradOutput, self.weight.T)\n",
    "    \n",
    "    def getParameters(self):\n",
    "        params = [self.weight, self.bias]\n",
    "        gradParams = [self.gradWeight, self.gradBias]\n",
    "        return params, gradParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hiddenlayer = 5\n",
    "learningRate = 0.1\n",
    "\n",
    "model = {}\n",
    "model['layer1'] = nn_Linear(17,hiddenlayer)\n",
    "model['layer2'] = nn_Linear(hiddenlayer,9)\n",
    "model['relu'] = nn_ReLu()\n",
    "model['loss'] = nn_MSECriterion()\n",
    "\n",
    "preds = []\n",
    "\n",
    "for epoch in range(0, 1000):\n",
    "    loss = 0\n",
    "    for i in range(0, x_train.shape[0]):\n",
    "        xi = x[i:i+1, :]\n",
    "        yi = y[i:i+1, :]\n",
    "\n",
    "        # Forward.\n",
    "        a0 = model['layer1'].forward(xi)\n",
    "        a1 = model['relu'].forward(a0)\n",
    "        a2 = model['layer2'].forward(a1)\n",
    "        a3 = model['relu'].forward(a2)\n",
    "        if epoch == 1000: \n",
    "            preds = preds + [float(a3)]\n",
    "        loss += model['loss'].forward(a3, yi)\n",
    "\n",
    "        # Backward.\n",
    "        da3 = model['loss'].backward(a3, yi)\n",
    "        da2 = model['relu'].backward(a2, da3)\n",
    "        da1 = model['layer2'].backward(a1, da2)\n",
    "        da0 = model['relu'].backward(a0, da1)\n",
    "        model['layer1'].backward(xi, da0)\n",
    "\n",
    "        model['layer1'].weight = model['layer1'].weight - learningRate * model['layer1'].gradWeight\n",
    "        model['layer1'].bias = model['layer1'].bias - learningRate * model['layer1'].gradBias\n",
    "        \n",
    "        model['layer2'].weight = model['layer2'].weight - learningRate * model['layer2'].gradWeight\n",
    "        model['layer2'].bias = model['layer2'].bias - learningRate * model['layer2'].gradBias\n",
    "    \n",
    "    if epoch % 100 == 0: print('epoch[%d] = %.8f' % (epoch, loss / dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Accuracy(yActual, yPred):\n",
    "    return float(len([i for i in range(len(yPred)) if abs(yActual[i]-yPred[i])<=1])/float(len(yPred)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
