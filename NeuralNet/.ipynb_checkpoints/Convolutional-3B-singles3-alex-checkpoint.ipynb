{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lingualTF as la\n",
    "\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, AveragePooling1D, AveragePooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupName</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>WBC347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>WBC410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>WBC418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>WBC421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>WBC422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    groupName  rank\n",
       "273    WBC347     2\n",
       "274    WBC410     1\n",
       "275    WBC418     1\n",
       "276    WBC421     1\n",
       "277    WBC422     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "# REPLACE THESE WITH CORRECT PATHS #\n",
    "####################################\n",
    "docRanks = pd.read_csv('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/refData/docRanks.csv')\n",
    "#docRanks.head()\n",
    "docRanks = docRanks.ix[~((docRanks['groupName']=='YV03')|(docRanks['groupName']=='YV04'))]\n",
    "docRanks.reset_index(inplace=True, drop=True)\n",
    "docRanks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DSIacc(y_true, y_pred):\n",
    "    return float(len([i for i in range(len(y_pred)) if abs(y_true[i][0]-y_pred[i][0])<=1])/float(len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data from file (processed in earlier scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 500, 1002)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR load X matrix from disk (already processed)\n",
    "X = np.load('/Users/Seth/Documents/DSI/Capstone/big-data/X-single-1k-278.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct Y matrix\n",
    "Y = np.array([np.array([y]) for y in docRanks['rank']])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a Y vector for classification\n",
    "Y_cat = np.zeros((len(Y),9))\n",
    "\n",
    "for i in range(0,len(Y)):\n",
    "    Y_cat[i][Y[i]-1] = Y[i]\n",
    "\n",
    "Y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 72,   4,  79, 171, 112,  71,  90,  93, 182, 147,\n",
       "            ...\n",
       "             96,  57, 123, 106,  83,  17,  98,  66, 126, 109],\n",
       "           dtype='int64', length=193)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the seed if you want to\n",
    "np.random.seed(123)\n",
    "#\n",
    "shuf = docRanks.sample(frac=1).index\n",
    "shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitPoint = int(len(X) * .8)\n",
    "#train = docRanks.iloc[shuf[:splitPoint]]\n",
    "#test = docRanks.iloc[shuf[(splitPoint+1):]]\n",
    "splitPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[shuf[:splitPoint]]\n",
    "Y_train = Y[shuf[:splitPoint]]\n",
    "Y_cat_train = Y_cat[shuf[:splitPoint]]\n",
    "\n",
    "X_test = X[shuf[(splitPoint+1):]]\n",
    "Y_test = Y[shuf[(splitPoint+1):]]\n",
    "Y_cat_test = Y_cat[shuf[(splitPoint+1):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "#model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DSIacc(y_true, y_pred):\n",
    "    return float(len([i for i in range(len(y_pred)) if abs(y_true[i][0]-y_pred[i][0])<=1])/float(len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_cross_entropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Batch size mattered a lot on this one\n",
    "with `batch_size=1` we got huge numbers and 0 accuracy, with `batch_size=154` we got tiny numbers and 23% accuracy (basically all the 1's and maybe a few 2's). With `batch_size=32` we did a little better, but still not convincing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/154 [==============================] - 30s - loss: 9.8408 - mean_absolute_error: 2.3931    \n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 19s - loss: 4.9736 - mean_absolute_error: 1.7372    \n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 21s - loss: 1.8986 - mean_absolute_error: 1.0706    \n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 22s - loss: 1.4224 - mean_absolute_error: 0.8983    \n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 22s - loss: 0.8198 - mean_absolute_error: 0.6821    \n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 20s - loss: 0.9426 - mean_absolute_error: 0.6953    \n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 19s - loss: 0.6338 - mean_absolute_error: 0.5472    \n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 19s - loss: 0.8980 - mean_absolute_error: 0.6109    \n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 19s - loss: 0.5644 - mean_absolute_error: 0.5045    \n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 19s - loss: 1.3336 - mean_absolute_error: 0.7867    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e0ed6610>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size=1)\n",
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size= 154)\n",
    "model.fit(X_train, Y_train, nb_epoch=10, batch_size=32) # 32 did way better than 1 on regression (opposite of classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.7362385999754464, 1.9637867494633323]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.50487661],\n",
       "       [ 2.2623558 ],\n",
       "       [ 1.64483905],\n",
       "       [ 2.32016873],\n",
       "       [ 2.46636415],\n",
       "       [ 2.67332745],\n",
       "       [ 1.48190165],\n",
       "       [ 2.11560202],\n",
       "       [ 4.07303762],\n",
       "       [ 1.78270376]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39473684210526316"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/154 [==============================] - 23s - loss: 2.1119 - mean_absolute_error: 0.5316 - acc: 0.0649    \n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 20s - loss: 2.0717 - mean_absolute_error: 0.5241 - acc: 0.1169    \n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 19s - loss: 2.0620 - mean_absolute_error: 0.5228 - acc: 0.1299    \n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 19s - loss: 2.0163 - mean_absolute_error: 0.5149 - acc: 0.1948    \n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 19s - loss: 1.9859 - mean_absolute_error: 0.5089 - acc: 0.2597    \n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 19s - loss: 1.9826 - mean_absolute_error: 0.5081 - acc: 0.2662    \n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 21s - loss: 1.9425 - mean_absolute_error: 0.5006 - acc: 0.3377    \n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 21s - loss: 1.9086 - mean_absolute_error: 0.4931 - acc: 0.3896    \n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 20s - loss: 1.8972 - mean_absolute_error: 0.4911 - acc: 0.3961    \n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 19s - loss: 1.8711 - mean_absolute_error: 0.4863 - acc: 0.4026    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e36a5f10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(data, labels, nb_epoch=10, batch_size=32) ### generic call from documentation\n",
    "model.fit(X_train,Y_cat_train, nb_epoch=10, batch_size=32)\n",
    "#model.fit(X_train, Y_cat_train, nb_epoch=10, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 3s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9382272260753732, 0.52708534308170019, 0.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9], [9], [9], [9], [9], [9], [9], [9], [9], [9]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05263157894736842"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DROPOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## regression model - WITH DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/154 [==============================] - 27s - loss: 8.7342 - mean_absolute_error: 2.3272 - acc: 0.1688    \n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 19s - loss: 6.2432 - mean_absolute_error: 1.9193 - acc: 0.1429    \n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 19s - loss: 4.5440 - mean_absolute_error: 1.7019 - acc: 0.1753    \n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 19s - loss: 3.7729 - mean_absolute_error: 1.5095 - acc: 0.2532    \n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 20s - loss: 3.4053 - mean_absolute_error: 1.5112 - acc: 0.2013    \n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 20s - loss: 4.1259 - mean_absolute_error: 1.5702 - acc: 0.1948    \n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 21s - loss: 3.6565 - mean_absolute_error: 1.4601 - acc: 0.2532    \n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 19s - loss: 2.8172 - mean_absolute_error: 1.3335 - acc: 0.2597    \n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 19s - loss: 3.4040 - mean_absolute_error: 1.4566 - acc: 0.1883    \n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 20s - loss: 3.0488 - mean_absolute_error: 1.3946 - acc: 0.1948    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f2e36990>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size= 1) #just like without dropout, this produced crazy predictions\n",
    "model.fit(X_train,Y_train, nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 3s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.75673301184648, 2.7896891173563505, 0.10526315789473684]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7896136 ],\n",
       "       [ 0.68153262],\n",
       "       [ 1.1205163 ],\n",
       "       [ 0.94476587],\n",
       "       [ 1.22108889],\n",
       "       [ 1.24291325],\n",
       "       [ 1.58358204],\n",
       "       [ 1.77549183],\n",
       "       [ 2.11056042],\n",
       "       [ 0.94681972]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13157894736842105"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## classification model - WITH DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/154 [==============================] - 48s - loss: 2.1054 - mean_absolute_error: 0.5272 - acc: 0.0909    \n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 44s - loss: 2.1048 - mean_absolute_error: 0.5271 - acc: 0.1883    \n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 42s - loss: 2.1042 - mean_absolute_error: 0.5270 - acc: 0.1299    \n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 42s - loss: 2.1037 - mean_absolute_error: 0.5270 - acc: 0.1234    \n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 43s - loss: 2.1032 - mean_absolute_error: 0.5269 - acc: 0.1234    \n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 42s - loss: 2.1026 - mean_absolute_error: 0.5268 - acc: 0.1299    \n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 42s - loss: 2.1021 - mean_absolute_error: 0.5267 - acc: 0.1299    \n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 42s - loss: 2.1016 - mean_absolute_error: 0.5266 - acc: 0.1299    \n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 44s - loss: 2.1011 - mean_absolute_error: 0.5265 - acc: 0.1299    \n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 42s - loss: 2.1006 - mean_absolute_error: 0.5264 - acc: 0.1299    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3075dfad0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(data, labels, nb_epoch=10, batch_size=32) ### generic call from documentation\n",
    "#model.fit(X_train,Y_cat_train, nb_epoch=10, batch_size=32)\n",
    "model.fit(X_train, Y_cat_train, nb_epoch=10, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 3s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0233917981386185, 0.5146198970706839, 0.15789473684210525]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3], [1], [9], [3], [3], [3], [3], [3], [3], [1]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with a larger batch size (spoiler, it does really badly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#THE FULL SETUP, compacted\n",
    "model = Sequential(); model.add(Convolution1D(64, 11, border_mode='same', input_shape=(X.shape[1],X.shape[2]))); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(128, 7, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(192, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(256, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3))\n",
    "model.add(Flatten()); model.add(Dense(4096, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.5)); model.add(Dense(1000, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.25)); model.add(Dense(200, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu'))\n",
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/154 [==============================] - 17s - loss: 1.7685 - mean_absolute_error: 0.4772 - acc: 0.1104\n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 13s - loss: 1.7589 - mean_absolute_error: 0.4756 - acc: 0.1234\n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 14s - loss: 1.7193 - mean_absolute_error: 0.4671 - acc: 0.2273\n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 12s - loss: 1.7050 - mean_absolute_error: 0.4638 - acc: 0.2468\n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 12s - loss: 1.6714 - mean_absolute_error: 0.4573 - acc: 0.3052\n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 11s - loss: 1.6584 - mean_absolute_error: 0.4531 - acc: 0.3766\n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 10s - loss: 1.6316 - mean_absolute_error: 0.4470 - acc: 0.4481\n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 9s - loss: 1.6042 - mean_absolute_error: 0.4421 - acc: 0.4156\n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 13s - loss: 1.5912 - mean_absolute_error: 0.4398 - acc: 0.4870\n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 13s - loss: 1.5510 - mean_absolute_error: 0.4296 - acc: 0.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2128cdad0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_cat_train, nb_epoch=10, batch_size=154)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 4s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4969771743605012, 0.4399002076763856, 0.18421052631578946]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3], [3], [3], [3], [3], [3], [3], [3], [3], [3]]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: this looks a little encouraging, but it's not\n",
    "It just guesses 3 for everything, and since about half the examples are 2,3,4, it counts those are correct. Also, if you run this identical thing a few times, it will come out differently, but always picking the same number for every testing observation. Last time it pick 7 for everything and got 10% accuracy.\n",
    "\n",
    "I also tried batch size 32 and got about the same result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running for more epochs (back to batch size 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#THE FULL SETUP, compacted\n",
    "model = Sequential(); model.add(Convolution1D(64, 11, border_mode='same', input_shape=(X.shape[1],X.shape[2]))); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(128, 7, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(192, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(256, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3))\n",
    "model.add(Flatten()); model.add(Dense(4096, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.5)); model.add(Dense(1000, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.25)); model.add(Dense(200, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu'))\n",
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "154/154 [==============================] - 35s - loss: 1.7544 - mean_absolute_error: 0.4767 - acc: 0.1364    \n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 30s - loss: 1.7540 - mean_absolute_error: 0.4766 - acc: 0.1104    \n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 27s - loss: 1.7535 - mean_absolute_error: 0.4765 - acc: 0.2208    \n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 27s - loss: 1.7531 - mean_absolute_error: 0.4764 - acc: 0.2013    \n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 27s - loss: 1.7526 - mean_absolute_error: 0.4764 - acc: 0.1948    \n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 26s - loss: 1.7521 - mean_absolute_error: 0.4763 - acc: 0.1364    \n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 23s - loss: 1.7517 - mean_absolute_error: 0.4762 - acc: 0.1623    \n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 23s - loss: 1.7513 - mean_absolute_error: 0.4761 - acc: 0.1558    \n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 23s - loss: 1.7508 - mean_absolute_error: 0.4760 - acc: 0.1364    \n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 23s - loss: 1.7504 - mean_absolute_error: 0.4759 - acc: 0.1364    \n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 23s - loss: 1.7499 - mean_absolute_error: 0.4758 - acc: 0.1494    \n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 24s - loss: 1.7495 - mean_absolute_error: 0.4758 - acc: 0.1234    \n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 25s - loss: 1.7490 - mean_absolute_error: 0.4757 - acc: 0.1429    \n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 26s - loss: 1.7486 - mean_absolute_error: 0.4756 - acc: 0.1429    \n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 25s - loss: 1.7482 - mean_absolute_error: 0.4755 - acc: 0.1558    \n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 25s - loss: 1.7477 - mean_absolute_error: 0.4754 - acc: 0.1494    \n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 25s - loss: 1.7473 - mean_absolute_error: 0.4753 - acc: 0.1364    \n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 25s - loss: 1.7469 - mean_absolute_error: 0.4752 - acc: 0.1494    \n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 27s - loss: 1.7465 - mean_absolute_error: 0.4751 - acc: 0.1299    \n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 24s - loss: 1.7460 - mean_absolute_error: 0.4750 - acc: 0.1494    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218457950>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_cat_train, nb_epoch=20, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/38 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6345029257630046, 0.45906433737591695, 0.026315789473684209]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8], [8], [4], [8], [8], [7], [3], [8], [8], [8]]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18421052631578946"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [visLang2]",
   "language": "python",
   "name": "Python [visLang2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
