{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "\n",
    "# This is referred above as f(u).\n",
    "class nn_MSECriterion:\n",
    "    def forward(self, predictions, labels):\n",
    "        return np.sum(np.square(predictions - labels))\n",
    "        \n",
    "    def backward(self, predictions, labels):\n",
    "        num_samples = labels.shape[0]\n",
    "        return num_samples * 2 * (predictions - labels) ### why num_samples * ... ?\n",
    "\n",
    "# This is referred above as g(v).\n",
    "class nn_Sigmoid:\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def inverse(self, x):\n",
    "        return np.log(x/(1-x))\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # It is usually a good idea to use gv from the forward pass and not recompute it again here.\n",
    "        gv = 1 / (1 + np.exp(-x))  \n",
    "        return np.multiply(np.multiply(gv, (1 - gv)), gradOutput) ### what is gradOutput?\n",
    "\n",
    "# This is referred above as h(W, b)\n",
    "class nn_Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # Initialized with random numbers from a gaussian N(0, 0.001)\n",
    "        self.weight = np.matlib.randn(input_dim, output_dim) * 0.01\n",
    "        self.bias = np.matlib.randn((1, output_dim)) * 0.01\n",
    "        self.gradWeight = np.zeros_like(self.weight)\n",
    "        self.gradBias = np.zeros_like(self.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return np.dot(x, self.weight) + self.bias\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # dL/dw = dh/dw * dL/dv\n",
    "        self.gradWeight = np.dot(x.T, gradOutput)\n",
    "        # dL/db = dh/db * dL/dv\n",
    "        self.gradBias = np.copy(gradOutput)\n",
    "        # return dL/dx = dh/dx * dL/dv\n",
    "        return np.dot(gradOutput, self.weight.T)\n",
    "    \n",
    "    def getParameters(self):\n",
    "        params = [self.weight, self.bias]\n",
    "        gradParams = [self.gradWeight, self.gradBias]\n",
    "        return params, gradParams\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data with to numpy array\n",
    "# to pandas first?\n",
    "# signalOutput-coco_3_cv_3_netAng_30_twc_10_tfidfNoPro_pronoun_bin_1-OQD9U4.csv\n",
    "rawSignals = pd.read_csv('signalOutput-coco_3_cv_3_netAng_30_twc_10_tfidfNoPro_pronoun_bin_1-OQD9U4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02436323,  0.01904762,  1.        ,  0.        ,  0.20304569],\n",
       "       [ 0.01027027,  0.01513514,  0.        ,  1.        ,  0.39130435],\n",
       "       [ 0.03768116,  0.02318841,  1.        ,  0.        ,  0.88235294],\n",
       "       [ 0.04921136,  0.02618297,  1.        ,  0.        ,  0.49418605],\n",
       "       [ 0.04949153,  0.02067797,  1.        ,  0.        ,  0.21269841]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GET X MATRIX\n",
    "xBig = rawSignals.ix[:,4:].as_matrix()\n",
    "print(len(xBig[0]))\n",
    "xBig[0:5,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STANDARDIZE THE X-MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x = StandardScaler().fit_transform(xBig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###OR (if you don't want to standardize)\n",
    "#x = xBig\n",
    "###but you probably do...\n",
    "### Accuracy on 400 epochs of 2-layer was 41%\n",
    "### ... on 1000 epochs of 5-layer was 39% (the same? something must be wrong...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Make the y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splits = [group.split(\"_\") for group in rawSignals['groupId']]\n",
    "rawSignals['groupId'] = [doc[0] for doc in splits]\n",
    "rawSignals = rawSignals.assign(tt = [doc[1] for doc in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rawSignals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupName</th>\n",
       "      <th>rank</th>\n",
       "      <th>groupId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACLU01</td>\n",
       "      <td>3</td>\n",
       "      <td>ACLU01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACLU02</td>\n",
       "      <td>3</td>\n",
       "      <td>ACLU02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACLU03</td>\n",
       "      <td>3</td>\n",
       "      <td>ACLU03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACLU04</td>\n",
       "      <td>3</td>\n",
       "      <td>ACLU04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACLU05</td>\n",
       "      <td>3</td>\n",
       "      <td>ACLU05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  groupName  rank groupId\n",
       "0    ACLU01     3  ACLU01\n",
       "1    ACLU02     3  ACLU02\n",
       "2    ACLU03     3  ACLU03\n",
       "3    ACLU04     3  ACLU04\n",
       "4    ACLU05     3  ACLU05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docRanks = pd.read_csv('docRanks.csv')\n",
    "docRanks[['groupId']] = docRanks[['groupName']] \n",
    "docRanks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupId</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unitarian145</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACLU07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SeaShepherds397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JohnPiper413</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shepherd695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           groupId  rank\n",
       "0     Unitarian145     7\n",
       "1           ACLU07     3\n",
       "2  SeaShepherds397     1\n",
       "3     JohnPiper413     2\n",
       "4      Shepherd695     4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yFull = pd.merge(rawSignals.ix[:,:1], docRanks.ix[:,1:] )\n",
    "yFull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yBig = np.array(yFull['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 1, 2, 4, 2, 2, 5, 5, 4, 6, 6, 1, 3, 8, 2, 8, 2, 5, 3, 1, 2, 3,\n",
       "       9, 2, 2, 3, 2, 5, 1, 2, 6, 4, 3, 3, 5, 6, 2, 2, 6, 1, 1, 3, 5, 1, 3,\n",
       "       3, 7, 1, 1, 5, 6, 3, 1, 1, 1, 5, 3, 3, 1, 4, 2, 2, 2, 2, 5, 1, 1, 5,\n",
       "       1, 4, 2, 6, 1, 8, 5, 8, 3, 8, 3, 5, 5, 4, 3, 1, 5, 5, 1, 8, 2, 5, 5,\n",
       "       6, 3, 8, 3, 8, 3, 1, 4, 1, 4, 5, 1, 4, 1, 3, 1, 6, 3, 3, 3, 3, 4, 1,\n",
       "       4, 1, 2, 4, 3, 2, 3, 2, 2, 3, 4, 3, 3, 7, 3, 3, 5, 3, 8, 3, 5, 4, 2,\n",
       "       6, 1, 2, 1, 2, 4, 7, 5, 3, 6, 1, 1, 3, 2, 5, 3, 2, 3, 1, 1, 1, 3, 4,\n",
       "       1, 2, 4, 5, 8, 1, 3, 3, 1, 3, 2, 5, 7, 5, 4, 3, 6, 8, 2, 5, 1, 2, 5,\n",
       "       4, 3, 6, 1, 3, 5, 1, 3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yBig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nn_Sigmoid().forward(yBig)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the sigmoid on the y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990889488055994"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_Sigmoid().forward(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0000000000000471"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_Sigmoid().inverse(0.9990889488055994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the 2-layer (same as VisLang homework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] = 0.03106804\n",
      "************\n",
      "epoch[100] = 0.00658460\n",
      "************\n",
      "epoch[200] = 0.00638634\n",
      "************\n",
      "epoch[300] = 0.00607706\n",
      "************\n",
      "epoch[400] = 0.00565687\n",
      "************\n",
      "epoch[401] = 0.00565294\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.1\n",
    "\n",
    "model = {}  \n",
    "#\n",
    "#model['linear1'] = nn_Linear(4, 5)\n",
    "#model['linear2'] = nn_Linear(5, 3)\n",
    "model['linear1'] = nn_Linear(x.shape[1], 5)\n",
    "model['linear2'] = nn_Linear(5, 1)\n",
    "#\n",
    "model['sigmoid'] = nn_Sigmoid()\n",
    "model['loss'] = nn_MSECriterion()\n",
    "\n",
    "preds100 = []\n",
    "preds400 = []\n",
    "\n",
    "epochsToRun = 401\n",
    "for epoch in range(0, epochsToRun+1):\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(0, x.shape[0]):\n",
    "        xi = x[i:i+1, :]\n",
    "        #yi = y[i:i+1, :] \n",
    "        yi = y[i:i+1]\n",
    "\n",
    "        # Forward layer 1\n",
    "        a0_L1 = model['linear1'].forward(xi)\n",
    "        a1_L1 = model['sigmoid'].forward(a0_L1)\n",
    "        # Forward layer 2\n",
    "        a0_L2 = model['linear2'].forward(a1_L1)\n",
    "        a1_L2 = model['sigmoid'].forward(a0_L2)\n",
    "        #\n",
    "        if epoch == 100: \n",
    "            preds100 = preds100 + [float(a1_L2)]\n",
    "        if epoch == 400: \n",
    "            preds400 = preds400 + [float(a1_L2)]\n",
    "            #print(a1_L2)\n",
    "            #print(yi)\n",
    "            #print(model['loss'].forward(a1_L2, yi))\n",
    "        #\n",
    "        loss += model['loss'].forward(a1_L2, yi)\n",
    "\n",
    "        # Backward layer 2\n",
    "        da1_L2 = model['loss'].backward(a1_L2, yi)\n",
    "        da0_L2 = model['sigmoid'].backward(a0_L2, da1_L2)\n",
    "        da1_L1 = model['linear2'].backward(a1_L1, da0_L2) # IS THIS RIGHT???\n",
    "\n",
    "        # Backward layer 1\n",
    "        #da1_L1 = model['loss'].backward(a1_L1, y2i) ### AND IS THIS WHAT GETS PASSED HERE?\n",
    "        da0_L1 = model['sigmoid'].backward(a0_L1, da1_L1)\n",
    "        model['linear1'].backward(xi, da0_L1)\n",
    "        \n",
    "        ##update layer 2\n",
    "        model['linear2'].weight = model['linear2'].weight - learningRate * model['linear2'].gradWeight\n",
    "        model['linear2'].bias = model['linear2'].bias - learningRate * model['linear2'].gradBias\n",
    "        #\n",
    "        ##update layer 1\n",
    "        model['linear1'].weight = model['linear1'].weight - learningRate * model['linear1'].gradWeight\n",
    "        model['linear1'].bias = model['linear1'].bias - learningRate * model['linear1'].gradBias\n",
    "          \n",
    "    if (epoch % 100 == 0) | (epoch == epochsToRun):\n",
    "        print('epoch[%d] = %.8f' % (epoch, loss / x.shape[0]))\n",
    "        #print('$$$ ' + 'weight = \\n' + str(model['linear'].weight))\n",
    "        #print('$$$ ' + 'bias = \\n' + str(model['linear'].bias))\n",
    "        print('************')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.6010303414367244,\n",
       " 1.3455039468729162,\n",
       " 1.8232434596667109,\n",
       " 2.3983093920701313,\n",
       " 3.6060067434999339,\n",
       " 2.0168084557116441,\n",
       " 2.3038982676203852,\n",
       " 1.9995111218376229,\n",
       " 3.9836879856909815,\n",
       " 2.9271971435578732,\n",
       " 2.1571224982227211,\n",
       " 3.8293889189737205,\n",
       " 2.0251408893245335,\n",
       " 4.0502298306859386,\n",
       " 3.2776849379905335,\n",
       " 2.8108477604535484,\n",
       " 2.9283347016473349,\n",
       " 1.893386146286685,\n",
       " 4.2273498280527333,\n",
       " 1.793682764756005,\n",
       " 1.1998190623075218,\n",
       " 1.3057503041376204,\n",
       " 2.9277035513377969,\n",
       " 2.3443095056968981,\n",
       " 1.4845161679974597,\n",
       " 2.1915905543348004,\n",
       " 3.0413613844895231,\n",
       " 2.3286423688511921,\n",
       " 3.7816962619121672,\n",
       " 2.6207094169982841,\n",
       " 2.342078092787951,\n",
       " 2.2493933565911273,\n",
       " 2.3945358971029904,\n",
       " 2.517149073709565,\n",
       " 2.6979085983027722,\n",
       " 3.617011688549626,\n",
       " 4.6127102331624217,\n",
       " 2.414019543475491,\n",
       " 2.9587379655986155,\n",
       " 2.2882194805987304,\n",
       " 1.6095120425819112,\n",
       " 1.3528908165291929,\n",
       " 2.8334251884905024,\n",
       " 3.8426155409623903,\n",
       " 1.4620392678917367,\n",
       " 3.1625949917377336,\n",
       " 4.0040944096012279,\n",
       " 2.8684300996132093,\n",
       " 2.2236838754417794,\n",
       " 2.5856665984856075,\n",
       " 3.127664686833199,\n",
       " 3.9094779475348433,\n",
       " 1.9132672978008343,\n",
       " 1.5017346251319867,\n",
       " 0.9983617861791807,\n",
       " 1.0184553455141889,\n",
       " 1.9909184404314115,\n",
       " 1.9509034323248562,\n",
       " 2.2416582456755858,\n",
       " 1.4374564170393294,\n",
       " 3.6710016330240713,\n",
       " 1.9394608401579587,\n",
       " 1.9912097087864438,\n",
       " 1.6594248549334263,\n",
       " 2.9818079073660839,\n",
       " 2.398974088662948,\n",
       " 1.4256828658351623,\n",
       " 2.5734562793809093,\n",
       " 2.8049307635052525,\n",
       " 2.4665037167138939,\n",
       " 1.977153979330103,\n",
       " 1.6773336261423692,\n",
       " 2.7141140940841,\n",
       " 2.273311886781189,\n",
       " 3.1183391049915414,\n",
       " 2.5870062206202493,\n",
       " 3.488534757032888,\n",
       " 2.7706821742417205,\n",
       " 2.4063260896406438,\n",
       " 2.5953508092925603,\n",
       " 3.5763684436125156,\n",
       " 2.36329484821283,\n",
       " 1.9958784066126667,\n",
       " 2.7055422283597181,\n",
       " 1.2915901791868614,\n",
       " 2.6820634373867587,\n",
       " 4.037615841270239,\n",
       " 1.5465406962071027,\n",
       " 3.7010085699023572,\n",
       " 3.2943079956624275,\n",
       " 2.2313780351913786,\n",
       " 3.2419771401590043,\n",
       " 2.2744874925931011,\n",
       " 3.1146406664155557,\n",
       " 3.975630526965813,\n",
       " 3.6316371330007979,\n",
       " 2.6472537161264325,\n",
       " 2.1326582298925754,\n",
       " 1.0232200634221567,\n",
       " 2.2058151402499777,\n",
       " 2.0222766719437577,\n",
       " 3.3991646248986593,\n",
       " 2.0199160328271217,\n",
       " 1.1711205094512509,\n",
       " 4.1021607505200404,\n",
       " 1.3982408531898174,\n",
       " 2.4241943622653355,\n",
       " 1.5799138108984649,\n",
       " 3.0964828514347502,\n",
       " 3.4677298580505025,\n",
       " 3.5491630814231501,\n",
       " 3.3859816056627081,\n",
       " 3.6911731996837989,\n",
       " 3.6439189049473439,\n",
       " 1.8386466051782124,\n",
       " 3.0645698432780741,\n",
       " 2.6412690078063719,\n",
       " 3.21113662549751,\n",
       " 3.6808078666979416,\n",
       " 1.9211323556436073,\n",
       " 2.5703673966153264,\n",
       " 2.962991028981433,\n",
       " 1.6506311941678322,\n",
       " 2.6801808131119045,\n",
       " 3.2391863859184924,\n",
       " 3.1666496475593378,\n",
       " 3.1732562880486066,\n",
       " 3.6394081106355363,\n",
       " 2.8566701008620181,\n",
       " 1.6119728762183372,\n",
       " 1.8646428482027346,\n",
       " 3.1195970015120285,\n",
       " 2.0733857787596475,\n",
       " 3.0979027289889287,\n",
       " 2.7460800757976602,\n",
       " 2.2383542234449765,\n",
       " 2.6922383459041073,\n",
       " 1.8352626970352626,\n",
       " 2.7703927627677567,\n",
       " 1.4056215550360496,\n",
       " 1.9337032551196884,\n",
       " 1.0310435218732588,\n",
       " 1.8678314802722229,\n",
       " 3.0439303364267123,\n",
       " 3.0236029983203134,\n",
       " 2.087035735721563,\n",
       " 2.5943165292708112,\n",
       " 2.8038528997890948,\n",
       " 1.8654012078324071,\n",
       " 1.709169596113373,\n",
       " 2.1372305665001923,\n",
       " 1.3681516753945644,\n",
       " 2.90864900153576,\n",
       " 1.8439938354130183,\n",
       " 2.220774049228738,\n",
       " 2.3579848004924373,\n",
       " 1.8445649837697164,\n",
       " 2.0534335288072669,\n",
       " 1.2010620427359386,\n",
       " 2.6906585738525735,\n",
       " 2.7112726433042575,\n",
       " 3.3219065264260532,\n",
       " 2.4171037282296344,\n",
       " 3.6326907673296613,\n",
       " 2.9459121066034157,\n",
       " 4.1032500925354807,\n",
       " 1.5930003926434089,\n",
       " 3.1986906405261646,\n",
       " 3.7031300743259803,\n",
       " 2.2391063802757691,\n",
       " 2.9882145757343337,\n",
       " 2.6725732294027793,\n",
       " 3.2869503913347704,\n",
       " 3.6250065058114158,\n",
       " 3.6852751513086828,\n",
       " 3.3195196749020282,\n",
       " 3.1817274125495358,\n",
       " 3.6055303639010545,\n",
       " 2.4245585601751261,\n",
       " 1.4751816870197247,\n",
       " 2.3634861102116864,\n",
       " 2.13168367084669,\n",
       " 1.3390980005828053,\n",
       " 3.04645750657934,\n",
       " 3.2474965217914984,\n",
       " 3.5838126144451343,\n",
       " 3.294716844774408,\n",
       " 2.2756091418760964,\n",
       " 1.4647567770503551,\n",
       " 3.186656336478392,\n",
       " 1.2107992839163515,\n",
       " 3.5133471886382002,\n",
       " 1.710527388047427]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nn_Sigmoid().inverse(pred) for pred in preds400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the 5-layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] = 0.03110181\n",
      "************\n",
      "epoch[100] = 0.00980162\n",
      "************\n",
      "epoch[200] = 0.00980153\n",
      "************\n",
      "epoch[300] = 0.00980143\n",
      "************\n",
      "epoch[400] = 0.00980134\n",
      "************\n",
      "epoch[500] = 0.00980125\n",
      "************\n",
      "epoch[600] = 0.00980115\n",
      "************\n",
      "epoch[700] = 0.00980106\n",
      "************\n",
      "epoch[800] = 0.00980097\n",
      "************\n",
      "epoch[900] = 0.00980087\n",
      "************\n",
      "epoch[1000] = 0.00980078\n",
      "************\n",
      "epoch[1001] = 0.00980078\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.1\n",
    "\n",
    "model = {}  \n",
    "#\n",
    "#model['linear1'] = nn_Linear(4, 5)\n",
    "#model['linear2'] = nn_Linear(5, 3)\n",
    "model['linear1'] = nn_Linear(x.shape[1], 12)\n",
    "model['linear2'] = nn_Linear(12, 8)\n",
    "model['linear3'] = nn_Linear(8, 5)\n",
    "model['linear4'] = nn_Linear(5, 5)\n",
    "\n",
    "model['linearF'] = nn_Linear(5, 1)\n",
    "#\n",
    "model['sigmoid'] = nn_Sigmoid()\n",
    "model['loss'] = nn_MSECriterion()\n",
    "\n",
    "preds100 = []\n",
    "preds1000 = []\n",
    "\n",
    "epochsToRun = 1001\n",
    "for epoch in range(0, epochsToRun+1):\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(0, x.shape[0]):\n",
    "        xi = x[i:i+1, :]\n",
    "        #yi = y[i:i+1, :] \n",
    "        yi = y[i:i+1]\n",
    "\n",
    "        # Forward layer 1\n",
    "        a0_L1 = model['linear1'].forward(xi)\n",
    "        a1_L1 = model['sigmoid'].forward(a0_L1)\n",
    "        # Forward layer 2\n",
    "        a0_L2 = model['linear2'].forward(a1_L1)\n",
    "        a1_L2 = model['sigmoid'].forward(a0_L2)\n",
    "        # Forward layer 3\n",
    "        a0_L3 = model['linear3'].forward(a1_L2)\n",
    "        a1_L3 = model['sigmoid'].forward(a0_L3)\n",
    "        # Forward layer 4\n",
    "        a0_L4 = model['linear4'].forward(a1_L3)\n",
    "        a1_L4 = model['sigmoid'].forward(a0_L4)\n",
    "        # Forward layer F\n",
    "        a0_LF = model['linearF'].forward(a1_L4)\n",
    "        a1_LF = model['sigmoid'].forward(a0_LF)\n",
    "        #\n",
    "        if epoch == 100: \n",
    "            preds100 = preds100 + [float(a1_LF)]\n",
    "        if epoch == 1000: \n",
    "            preds1000 = preds1000 + [float(a1_LF)]\n",
    "            #print(a1_L2)\n",
    "            #print(yi)\n",
    "            #print(model['loss'].forward(a1_L2, yi))\n",
    "        #\n",
    "        loss += model['loss'].forward(a1_LF, yi)\n",
    "\n",
    "        # Backward layer F\n",
    "        da1_LF = model['loss'].backward(a1_LF, yi)\n",
    "        da0_LF = model['sigmoid'].backward(a0_LF, da1_LF)\n",
    "        da1_L4 = model['linearF'].backward(a1_L4, da0_LF) # IS THIS RIGHT???\n",
    "        # Backward layer 4\n",
    "        da0_L4 = model['sigmoid'].backward(a0_L4, da1_L4)\n",
    "        da1_L3 = model['linear4'].backward(a1_L3, da0_L4)\n",
    "        # Backward layer 3\n",
    "        da0_L3 = model['sigmoid'].backward(a0_L3, da1_L3)\n",
    "        da1_L2 = model['linear3'].backward(a1_L2, da0_L3)\n",
    "\n",
    "        # Backward layer 2\n",
    "        da0_L2 = model['sigmoid'].backward(a0_L2, da1_L2)\n",
    "        da1_L1 = model['linear2'].backward(a1_L1, da0_L2)\n",
    "\n",
    "        # Backward layer 1\n",
    "        da0_L1 = model['sigmoid'].backward(a0_L1, da1_L1)\n",
    "        model['linear1'].backward(xi, da0_L1)\n",
    "        \n",
    "        ####\n",
    "        ##update layer F\n",
    "        model['linearF'].weight = model['linearF'].weight - learningRate * model['linearF'].gradWeight\n",
    "        model['linearF'].bias = model['linearF'].bias - learningRate * model['linearF'].gradBias\n",
    "        ##update layer 4\n",
    "        model['linear4'].weight = model['linear4'].weight - learningRate * model['linear4'].gradWeight\n",
    "        model['linear4'].bias = model['linear4'].bias - learningRate * model['linear4'].gradBias\n",
    "        ##update layer 3\n",
    "        model['linear3'].weight = model['linear3'].weight - learningRate * model['linear3'].gradWeight\n",
    "        model['linear3'].bias = model['linear3'].bias - learningRate * model['linear3'].gradBias\n",
    "\n",
    "        ##update layer 2\n",
    "        model['linear2'].weight = model['linear2'].weight - learningRate * model['linear2'].gradWeight\n",
    "        model['linear2'].bias = model['linear2'].bias - learningRate * model['linear2'].gradBias\n",
    "        #\n",
    "        ##update layer 1\n",
    "        model['linear1'].weight = model['linear1'].weight - learningRate * model['linear1'].gradWeight\n",
    "        model['linear1'].bias = model['linear1'].bias - learningRate * model['linear1'].gradBias\n",
    "          \n",
    "    if (epoch % 100 == 0) | (epoch == epochsToRun):\n",
    "        print('epoch[%d] = %.8f' % (epoch, loss / x.shape[0]))\n",
    "        #print('$$$ ' + 'weight = \\n' + str(model['linear'].weight))\n",
    "        #print('$$$ ' + 'bias = \\n' + str(model['linear'].bias))\n",
    "        print('************')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3401095262686087,\n",
       " 2.3436322656354833,\n",
       " 2.3452547971257469,\n",
       " 2.3379300828404275,\n",
       " 2.3366652620360218,\n",
       " 2.33951425632941,\n",
       " 2.3382457016809699,\n",
       " 2.3369801356681061,\n",
       " 2.3402861055011308,\n",
       " 2.3435735718632618,\n",
       " 2.3463862465343857,\n",
       " 2.3498100850999966,\n",
       " 2.3532146003071084,\n",
       " 2.3459058593418445,\n",
       " 2.3475184235400484,\n",
       " 2.3510219777527763,\n",
       " 2.3497268649737433,\n",
       " 2.3532178704380109,\n",
       " 2.3519177701154956,\n",
       " 2.3551408856258949,\n",
       " 2.3567134786956565,\n",
       " 2.3494118309641134,\n",
       " 2.3481203745271917,\n",
       " 2.3497233063207812,\n",
       " 2.3532228538520146,\n",
       " 2.3519227293745719,\n",
       " 2.3506255637039293,\n",
       " 2.3522176156308876,\n",
       " 2.3509197738040934,\n",
       " 2.3541483674802723,\n",
       " 2.3468415089194887,\n",
       " 2.3455559419332204,\n",
       " 2.3489844623295628,\n",
       " 2.3517689698185151,\n",
       " 2.3533560648471599,\n",
       " 2.3549363253568645,\n",
       " 2.3581429329207308,\n",
       " 2.3615009091053589,\n",
       " 2.360182352955031,\n",
       " 2.358866689012848,\n",
       " 2.3622206665005954,\n",
       " 2.3549302963395347,\n",
       " 2.3476250653691753,\n",
       " 2.3492301469020584,\n",
       " 2.3524679995539342,\n",
       " 2.3451577915969808,\n",
       " 2.3467736203254757,\n",
       " 2.3483823976322009,\n",
       " 2.3518578375393013,\n",
       " 2.3445463896610885,\n",
       " 2.3372203418459128,\n",
       " 2.3405249375472219,\n",
       " 2.3439820177538553,\n",
       " 2.3456029693495917,\n",
       " 2.3382790083057312,\n",
       " 2.3309406393806831,\n",
       " 2.3235880796081898,\n",
       " 2.3269699040320115,\n",
       " 2.3286664981229666,\n",
       " 2.3303554564131685,\n",
       " 2.32300177929991,\n",
       " 2.3259237468544591,\n",
       " 2.3246877631103477,\n",
       " 2.3234548088231977,\n",
       " 2.3222248673151427,\n",
       " 2.3209979619555501,\n",
       " 2.324394611003572,\n",
       " 2.3170296085876467,\n",
       " 2.309650814853538,\n",
       " 2.3131132335017135,\n",
       " 2.3057272412561236,\n",
       " 2.3087437845787289,\n",
       " 2.3075508119098922,\n",
       " 2.3112005136414036,\n",
       " 2.3038110307175916,\n",
       " 2.307572046433918,\n",
       " 2.3110466503531164,\n",
       " 2.3147638861093536,\n",
       " 2.3165161836628125,\n",
       " 2.3202006462246749,\n",
       " 2.3219279888449371,\n",
       " 2.3253192964067391,\n",
       " 2.3286911945142568,\n",
       " 2.3315825832082191,\n",
       " 2.3332584279609669,\n",
       " 2.3259103626621167,\n",
       " 2.3292788974379008,\n",
       " 2.3326282422541436,\n",
       " 2.325278967801403,\n",
       " 2.3289114346235964,\n",
       " 2.3276681753387609,\n",
       " 2.3310266987455686,\n",
       " 2.3343661489251235,\n",
       " 2.3378584531602717,\n",
       " 2.3395063832876004,\n",
       " 2.3430558618903894,\n",
       " 2.3446808857542552,\n",
       " 2.3482006122416781,\n",
       " 2.3498031577592324,\n",
       " 2.342487663972455,\n",
       " 2.345306016195384,\n",
       " 2.3379815102922117,\n",
       " 2.3408235255734136,\n",
       " 2.3441079031006473,\n",
       " 2.3367810882467133,\n",
       " 2.3396294124243631,\n",
       " 2.3322937602986347,\n",
       " 2.3339664149243626,\n",
       " 2.3266197661905381,\n",
       " 2.330156886527651,\n",
       " 2.33183911929145,\n",
       " 2.3335138403991835,\n",
       " 2.3351810527660777,\n",
       " 2.3368408494459758,\n",
       " 2.3396888704816483,\n",
       " 2.3323533393166942,\n",
       " 2.3352251453247455,\n",
       " 2.3278809188187055,\n",
       " 2.3266401778545016,\n",
       " 2.3295425249875485,\n",
       " 2.3312275376081439,\n",
       " 2.3299786939175671,\n",
       " 2.3316617304906266,\n",
       " 2.3304118655316817,\n",
       " 2.3291650005374946,\n",
       " 2.3308517055760638,\n",
       " 2.3337315193139982,\n",
       " 2.3353977362601177,\n",
       " 2.3370565881181049,\n",
       " 2.3405968343988106,\n",
       " 2.3422326449529045,\n",
       " 2.3438612708990463,\n",
       " 2.3471287678770998,\n",
       " 2.3487359867404507,\n",
       " 2.3522325479114246,\n",
       " 2.3538176320241946,\n",
       " 2.3570303042677394,\n",
       " 2.3597733387632949,\n",
       " 2.3584585673055494,\n",
       " 2.3618147487491492,\n",
       " 2.3545236749071354,\n",
       " 2.3532206465076353,\n",
       " 2.3459120816280952,\n",
       " 2.3446286615513361,\n",
       " 2.3474357798336993,\n",
       " 2.3509165542807842,\n",
       " 2.3541450983809913,\n",
       " 2.3557219479491147,\n",
       " 2.3590933274964327,\n",
       " 2.3517966741347545,\n",
       " 2.3444852493066559,\n",
       " 2.3461039733106452,\n",
       " 2.3448201212651383,\n",
       " 2.348082299854469,\n",
       " 2.3496853483265596,\n",
       " 2.3483932807967443,\n",
       " 2.3499949733232048,\n",
       " 2.3426799141985151,\n",
       " 2.3353503084601641,\n",
       " 2.3280063796345116,\n",
       " 2.3296982739476628,\n",
       " 2.3325842352959336,\n",
       " 2.3252349518986772,\n",
       " 2.3240006620171445,\n",
       " 2.3269172051163531,\n",
       " 2.3302799486280636,\n",
       " 2.3338830073667061,\n",
       " 2.3265362280547528,\n",
       " 2.3282347615893642,\n",
       " 2.3299256382854452,\n",
       " 2.322571278593013,\n",
       " 2.3242877746128512,\n",
       " 2.323055816546606,\n",
       " 2.3264406043022254,\n",
       " 2.3300426369779625,\n",
       " 2.3333876094912251,\n",
       " 2.3362539074493207,\n",
       " 2.3379089124913937,\n",
       " 2.3413808644354326,\n",
       " 2.3449194849480661,\n",
       " 2.343638372220211,\n",
       " 2.3469070826913505,\n",
       " 2.3395858689766431,\n",
       " 2.3383171927891855,\n",
       " 2.3416155779873482,\n",
       " 2.3444384204731472,\n",
       " 2.3460573567467518,\n",
       " 2.3494829423011123,\n",
       " 2.3421668936172417,\n",
       " 2.343795803743645,\n",
       " 2.3470636251812822,\n",
       " 2.3397427419795815,\n",
       " 2.341382297398952]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nn_Sigmoid().inverse(pred) for pred in preds1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Accuracy(yActual, yPred):\n",
    "    return float(len([i for i in range(len(yPred)) if abs(yActual[i]-yPred[i])<=1])/float(len(yPred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.533678756476684"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the 2-layer\n",
    "Accuracy(yBig, [nn_Sigmoid().inverse(pred) for pred in preds400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39896373056994816"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the 5-layer\n",
    "Accuracy(yBig, [nn_Sigmoid().inverse(pred) for pred in preds1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [visLang2]",
   "language": "python",
   "name": "Python [visLang2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
