{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "\n",
    "# This is referred above as f(u).\n",
    "class nn_MSECriterion:\n",
    "    def forward(self, predictions, labels):\n",
    "        return np.sum(np.square(predictions - labels))\n",
    "        \n",
    "    def backward(self, predictions, labels):\n",
    "        num_samples = labels.shape[0]\n",
    "        return num_samples * 2 * (predictions - labels) ### why num_samples * ... ?\n",
    "\n",
    "# This is referred above as g(v).\n",
    "class nn_Sigmoid:\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # It is usually a good idea to use gv from the forward pass and not recompute it again here.\n",
    "        gv = 1 / (1 + np.exp(-x))  \n",
    "        return np.multiply(np.multiply(gv, (1 - gv)), gradOutput) ### what is gradOutput?\n",
    "\n",
    "# This is referred above as h(W, b)\n",
    "class nn_Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # Initialized with random numbers from a gaussian N(0, 0.001)\n",
    "        self.weight = np.matlib.randn(input_dim, output_dim) * 0.01\n",
    "        self.bias = np.matlib.randn((1, output_dim)) * 0.01\n",
    "        self.gradWeight = np.zeros_like(self.weight)\n",
    "        self.gradBias = np.zeros_like(self.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return np.dot(x, self.weight) + self.bias\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # dL/dw = dh/dw * dL/dv\n",
    "        self.gradWeight = np.dot(x.T, gradOutput)\n",
    "        # dL/db = dh/db * dL/dv\n",
    "        self.gradBias = np.copy(gradOutput)\n",
    "        # return dL/dx = dh/dx * dL/dv\n",
    "        return np.dot(gradOutput, self.weight.T)\n",
    "    \n",
    "    def getParameters(self):\n",
    "        params = [self.weight, self.bias]\n",
    "        gradParams = [self.gradWeight, self.gradBias]\n",
    "        return params, gradParams\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupId</th>\n",
       "      <th>files</th>\n",
       "      <th>timeRun</th>\n",
       "      <th>keywords</th>\n",
       "      <th>perPos</th>\n",
       "      <th>perNeg</th>\n",
       "      <th>perPosDoc</th>\n",
       "      <th>perNegDoc</th>\n",
       "      <th>PSJudge</th>\n",
       "      <th>judgementCount</th>\n",
       "      <th>...</th>\n",
       "      <th>nous</th>\n",
       "      <th>vous</th>\n",
       "      <th>je</th>\n",
       "      <th>ils</th>\n",
       "      <th>il</th>\n",
       "      <th>elle</th>\n",
       "      <th>le</th>\n",
       "      <th>UniqueWordCount</th>\n",
       "      <th>avgSD</th>\n",
       "      <th>avgEVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unitarian145_train</td>\n",
       "      <td>1</td>\n",
       "      <td>5.807484</td>\n",
       "      <td>experi, dont, let, theolog, els, hallway, tell...</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203046</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.042303</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.012625</td>\n",
       "      <td>0.256921</td>\n",
       "      <td>0.677372</td>\n",
       "      <td>0.514338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACLU07_train</td>\n",
       "      <td>1</td>\n",
       "      <td>2.433201</td>\n",
       "      <td>camp, polic, dakota, protector, morton, survei...</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>0.278919</td>\n",
       "      <td>0.581728</td>\n",
       "      <td>0.723923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SeaShepherds397_train</td>\n",
       "      <td>1</td>\n",
       "      <td>1.377950</td>\n",
       "      <td>turtl, shepherd, save, gift, donat, pollut, ja...</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046377</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524638</td>\n",
       "      <td>0.671658</td>\n",
       "      <td>0.437063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JohnPiper413_test</td>\n",
       "      <td>1</td>\n",
       "      <td>3.986198</td>\n",
       "      <td>love, homosexu, say, command, fulfil, scriptur...</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494186</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033123</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.204416</td>\n",
       "      <td>0.721582</td>\n",
       "      <td>0.636675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shepherd695_train</td>\n",
       "      <td>1</td>\n",
       "      <td>4.140041</td>\n",
       "      <td>love, got, debt, rememb, pay, don, husband, pr...</td>\n",
       "      <td>0.049492</td>\n",
       "      <td>0.020678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212698</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017627</td>\n",
       "      <td>0.025085</td>\n",
       "      <td>0.021695</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>0.271864</td>\n",
       "      <td>0.642954</td>\n",
       "      <td>0.508893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 groupId  files   timeRun  \\\n",
       "0     Unitarian145_train      1  5.807484   \n",
       "1           ACLU07_train      1  2.433201   \n",
       "2  SeaShepherds397_train      1  1.377950   \n",
       "3      JohnPiper413_test      1  3.986198   \n",
       "4      Shepherd695_train      1  4.140041   \n",
       "\n",
       "                                            keywords    perPos    perNeg  \\\n",
       "0  experi, dont, let, theolog, els, hallway, tell...  0.024363  0.019048   \n",
       "1  camp, polic, dakota, protector, morton, survei...  0.010270  0.015135   \n",
       "2  turtl, shepherd, save, gift, donat, pollut, ja...  0.037681  0.023188   \n",
       "3  love, homosexu, say, command, fulfil, scriptur...  0.049211  0.026183   \n",
       "4  love, got, debt, rememb, pay, don, husband, pr...  0.049492  0.020678   \n",
       "\n",
       "   perPosDoc  perNegDoc   PSJudge  judgementCount    ...         nous  \\\n",
       "0        1.0        0.0  0.203046           233.0    ...     0.014839   \n",
       "1        0.0        1.0  0.391304            27.0    ...     0.002162   \n",
       "2        1.0        0.0  0.882353            15.0    ...     0.046377   \n",
       "3        1.0        0.0  0.494186           119.0    ...     0.033123   \n",
       "4        1.0        0.0  0.212698           192.0    ...     0.017627   \n",
       "\n",
       "       vous        je       ils        il      elle        le  \\\n",
       "0  0.010410  0.042303  0.008638  0.003987  0.009967  0.012625   \n",
       "1  0.000541  0.000000  0.011351  0.001081  0.000000  0.005946   \n",
       "2  0.023188  0.000000  0.005797  0.000000  0.000000  0.000000   \n",
       "3  0.006940  0.008517  0.011356  0.008833  0.004101  0.009464   \n",
       "4  0.025085  0.021695  0.012203  0.027797  0.007797  0.015593   \n",
       "\n",
       "   UniqueWordCount     avgSD    avgEVC  \n",
       "0         0.256921  0.677372  0.514338  \n",
       "1         0.278919  0.581728  0.723923  \n",
       "2         0.524638  0.671658  0.437063  \n",
       "3         0.204416  0.721582  0.636675  \n",
       "4         0.271864  0.642954  0.508893  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data with to numpy array\n",
    "# to pandas first?\n",
    "# signalOutput-coco_3_cv_3_netAng_30_twc_10_tfidfNoPro_pronoun_bin_1-OQD9U4.csv\n",
    "rawSignals = pd.read_csv('signalOutput-coco_3_cv_3_netAng_30_twc_10_tfidfNoPro_pronoun_bin_1-OQD9U4.csv', index_col=0)\n",
    "rawSignals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learningRate = 0.1\n",
    "\n",
    "model = {}  \n",
    "model['linear1'] = nn_Linear(4, 5)\n",
    "model['linear2'] = nn_Linear(5, 3)\n",
    "model['sigmoid'] = nn_Sigmoid()\n",
    "model['loss'] = nn_MSECriterion()\n",
    "\n",
    "epochsToRun = 401\n",
    "for epoch in range(0, epochsToRun+1):\n",
    "    loss = 0\n",
    "    for i in range(0, dataset_size):\n",
    "        xi = x[i:i+1, :]\n",
    "        yi = y[i:i+1, :] \n",
    "\n",
    "        # Forward layer 1\n",
    "        a0_L1 = model['linear1'].forward(xi)\n",
    "        a1_L1 = model['sigmoid'].forward(a0_L1)\n",
    "        # Forward layer 2\n",
    "        a0_L2 = model['linear2'].forward(a1_L1)\n",
    "        a1_L2 = model['sigmoid'].forward(a0_L2)\n",
    "        #\n",
    "        loss += model['loss'].forward(a1_L2, yi)\n",
    "\n",
    "        # Backward layer 2\n",
    "        da1_L2 = model['loss'].backward(a1_L2, yi)\n",
    "        da0_L2 = model['sigmoid'].backward(a0_L2, da1_L2)\n",
    "        da1_L1 = model['linear2'].backward(a1_L1, da0_L2) # IS THIS RIGHT???\n",
    "\n",
    "        # Backward layer 1\n",
    "        #da1_L1 = model['loss'].backward(a1_L1, y2i) ### AND IS THIS WHAT GETS PASSED HERE?\n",
    "        da0_L1 = model['sigmoid'].backward(a0_L1, da1_L1)\n",
    "        model['linear1'].backward(xi, da0_L1)\n",
    "        \n",
    "        ##update layer 2\n",
    "        model['linear2'].weight = model['linear2'].weight - learningRate * model['linear2'].gradWeight\n",
    "        model['linear2'].bias = model['linear2'].bias - learningRate * model['linear2'].gradBias\n",
    "        #\n",
    "        ##update layer 1\n",
    "        model['linear1'].weight = model['linear1'].weight - learningRate * model['linear1'].gradWeight\n",
    "        model['linear1'].bias = model['linear1'].bias - learningRate * model['linear1'].gradBias\n",
    "          \n",
    "    if (epoch % 100 == 0) | (epoch == epochsToRun):\n",
    "        print('epoch[%d] = %.8f' % (epoch, loss / dataset_size))\n",
    "        #print('$$$ ' + 'weight = \\n' + str(model['linear'].weight))\n",
    "        #print('$$$ ' + 'bias = \\n' + str(model['linear'].bias))\n",
    "        print('************')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [visLang2]",
   "language": "python",
   "name": "Python [visLang2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
