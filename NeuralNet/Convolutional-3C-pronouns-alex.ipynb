{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lingualTF as la\n",
    "\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, AveragePooling1D, AveragePooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupName</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>WBC347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>WBC410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>WBC418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>WBC421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>WBC422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    groupName  rank\n",
       "273    WBC347     2\n",
       "274    WBC410     1\n",
       "275    WBC418     1\n",
       "276    WBC421     1\n",
       "277    WBC422     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "# REPLACE THESE WITH CORRECT PATHS #\n",
    "####################################\n",
    "docRanks = pd.read_csv('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/refData/docRanks.csv')\n",
    "#docRanks.head()\n",
    "docRanks = docRanks.ix[~((docRanks['groupName']=='YV03')|(docRanks['groupName']=='YV04'))]\n",
    "docRanks.reset_index(inplace=True, drop=True)\n",
    "docRanks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DSIacc(y_true, y_pred):\n",
    "    return float(len([i for i in range(len(y_pred)) if abs(y_true[i][0]-y_pred[i][0])<=1])/float(len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS TAGGINGS - skip a bit brother..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/data_dsicap_single/ACLU01/raw/ACLU01.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsFolder = '/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/data_dsicap_single/'\n",
    "doc = docsFolder + docRanks['groupName'][0] + '/raw/' + docRanks['groupName'][0] + '.txt'\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/data_dsicap_single/ACLU01/raw/ACLU01.txt']\n"
     ]
    }
   ],
   "source": [
    "lo = la.lingualObject(doc)\n",
    "print(lo.fileList)\n",
    "fileName = lo.fileList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'VBG',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'IN']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lo.pos_with_val()\n",
    "lo.tags[fileName][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'VBG',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'WP',\n",
       " 'RB',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'VAL',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'VBD',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'VBN',\n",
       " 'CC',\n",
       " 'VAL',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'VAL',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VAL',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " ',',\n",
       " 'EX',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'VB',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'VAL',\n",
       " 'NNS',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'VBZ',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'IN',\n",
       " 'CD',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " ',',\n",
       " 'VAL',\n",
       " 'JJ',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " ',',\n",
       " 'WDT',\n",
       " 'PRP',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'JJ',\n",
       " 'NNP',\n",
       " 'VAL',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'EX',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'VAL',\n",
       " 'DT',\n",
       " 'JJS',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'VAL',\n",
       " 'NNP',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VAL',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'VBN',\n",
       " 'VAL',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " ',',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNS',\n",
       " 'VBD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'VBD',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'VAL',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJR',\n",
       " ':',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ':',\n",
       " 'CC',\n",
       " 'VBD',\n",
       " 'VAL',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'VAL',\n",
       " '.',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'VAL',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'CC',\n",
       " 'VBN',\n",
       " 'CC',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " ',',\n",
       " 'WRB',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'VAL',\n",
       " 'VBZ',\n",
       " 'PRP$',\n",
       " 'VAL',\n",
       " 'RB',\n",
       " 'RB',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'VAL',\n",
       " 'NNS',\n",
       " 'TO',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " ',',\n",
       " 'VAL',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'RB',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'VAL',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'VBD',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'VAL',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'VAL',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'VAL',\n",
       " ',',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'VAL',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'VAL',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " ',',\n",
       " 'VBG',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'VBZ',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'CC',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'VAL',\n",
       " ',',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'NNS',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " ',',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " ',',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " ',',\n",
       " 'VAL',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'NN',\n",
       " '.',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'VAL',\n",
       " '.',\n",
       " 'VAL',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'VBP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'VAL',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'WDT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'VBN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'JJR',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'VBN',\n",
       " 'VBN',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'IN',\n",
       " 'VAL',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'VBZ',\n",
       " 'VAL',\n",
       " 'VAL',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'RBS',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'RB',\n",
       " ',',\n",
       " 'VAL',\n",
       " ',',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'CC',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'VBN',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VAL',\n",
       " 'VBP',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'VAL',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VAL',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " ',',\n",
       " 'WDT',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'VBG',\n",
       " 'RBR',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'JJS',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " '.',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VAL',\n",
       " 'VBZ',\n",
       " 'JJ',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'CC',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyInds = []\n",
    "for i in range(0,len(lo.tokens[fileName])):\n",
    "    if lo.tokens[fileName][i] in lo.keywords:\n",
    "        keyInds += [i]\n",
    "        \n",
    "['VAL' if i in keyInds else lo.tags[fileName][i] for i in range(0,len(lo.tokens[fileName]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def docToNumpyPOS(doc,keywordCount=20, lengthThreshold=500, warnOnPad=False):\n",
    "    vocab = la.allTags\n",
    "    # tokenize, etc. document\n",
    "    self = la.lingualObject(doc)\n",
    "    fileName = self.fileList[0]\n",
    "    # set the keywords\n",
    "    self.pos_with_val(keywords = keywordCount, useVal=True)\n",
    "    # create array of each word in doc with len(vocab)-dimensional sparse one-hot vectors\n",
    "    sparse = [la.wordToInd(word, vocab, self.keywords) for word in self.tags[fileName]]\n",
    "    # if less words than the threshold, pad with UNK\n",
    "    if len(sparse) < lengthThreshold:\n",
    "        if warnOnPad==True:\n",
    "            print('PADDING: ' + doc + ' has only ' + str(len(sparse)) + ' words. Adding ' + str((lengthThreshold - len(sparse))) + ' UNKs.')\n",
    "        sparse += [(len(vocab) - 2)] * (lengthThreshold - len(sparse))\n",
    "    # create dense array of zeros, then fill in the correct ones\n",
    "    docArr = np.zeros((lengthThreshold,len(vocab)), dtype=np.int) # default is 500, 1002\n",
    "    for i in range(0, lengthThreshold):\n",
    "        docArr[i][sparse[i]] = 1\n",
    "    # \n",
    "    return docArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docArr = docToNumpyPOS(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docArr[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'VBG',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'VAL',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VAL',\n",
       " 'IN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lo.pos_with_val()\n",
    "lo.tags[fileName][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data from file (processed in earlier scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docToNumpyPOS(doc,keywordCount=20, lengthThreshold=500, warnOnPad=False):\n",
    "    # tokenize, etc. document\n",
    "    self = la.lingualObject(doc)\n",
    "    fileName = self.fileList[0]\n",
    "    vocab = la.allTags\n",
    "    # set the keywords\n",
    "    self.pos_with_val(keywords = keywordCount, useVal=True)\n",
    "    # create array of each word in doc with len(vocab)-dimensional sparse one-hot vectors\n",
    "    sparse = [la.wordToInd(word, vocab, self.keywords) for word in self.tags[fileName]]\n",
    "    # if less words than the threshold, pad with UNK\n",
    "    if len(sparse) < lengthThreshold:\n",
    "        if warnOnPad==True:\n",
    "            print('PADDING: ' + doc + ' has only ' + str(len(sparse)) + ' words. Adding ' + str((lengthThreshold - len(sparse))) + ' UNKs.')\n",
    "        sparse += [(len(vocab) - 2)] * (lengthThreshold - len(sparse))\n",
    "    # create dense array of zeros, then fill in the correct ones\n",
    "    docArr = np.zeros((lengthThreshold,len(vocab)), dtype=np.int) # default is 500, 1002\n",
    "    for i in range(0, lengthThreshold):\n",
    "        docArr[i][sparse[i]] = 1\n",
    "    # \n",
    "    return docArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [01:29<00:00,  1.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(278, 500, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct X matrix FROM SCRATCH\n",
    "docsFolder = '/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/data_dsicap_single/'\n",
    "#\n",
    "X = np.array([docToNumpyPOS(docsFolder + adoc + '/raw/' + adoc + '.txt') for adoc in tqdm(docRanks['groupName'])])\n",
    "np.save('/Users/Seth/Documents/DSI/Capstone/big-data/X-single-POS.npy', X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 500, 38)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR load X matrix from disk (already processed)\n",
    "#X = np.load('/Users/Seth/Documents/DSI/Capstone/big-data/X-single-5k.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct Y matrix\n",
    "Y = np.array([np.array([y]) for y in docRanks['rank']])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a Y vector for classification\n",
    "Y_cat = np.zeros((len(Y),9))\n",
    "\n",
    "for i in range(0,len(Y)):\n",
    "    Y_cat[i][Y[i]-1] = Y[i]\n",
    "\n",
    "Y_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([223,  20, 163,  29, 254, 237,  53, 174, 151, 156,\n",
       "            ...\n",
       "             96, 225, 214,  57, 123, 106,  83,  17, 230,  98],\n",
       "           dtype='int64', length=278)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the seed if you want to\n",
    "np.random.seed(123)\n",
    "#\n",
    "shuf = docRanks.sample(frac=1).index\n",
    "shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitPoint = int(len(X) * .8)\n",
    "#train = docRanks.iloc[shuf[:splitPoint]]\n",
    "#test = docRanks.iloc[shuf[(splitPoint+1):]]\n",
    "splitPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[shuf[:splitPoint]]\n",
    "Y_train = Y[shuf[:splitPoint]]\n",
    "Y_cat_train = Y_cat[shuf[:splitPoint]]\n",
    "\n",
    "X_test = X[shuf[(splitPoint+1):]]\n",
    "Y_test = Y[shuf[(splitPoint+1):]]\n",
    "Y_cat_test = Y_cat[shuf[(splitPoint+1):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "#model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DSIacc(y_true, y_pred):\n",
    "    return float(len([i for i in range(len(y_pred)) if abs(y_true[i][0]-y_pred[i][0])<=1])/float(len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_cross_entropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Batch size mattered a lot on this one\n",
    "with `batch_size=1` we got huge numbers and 0 accuracy, with `batch_size=154` we got tiny numbers and 23% accuracy (basically all the 1's and maybe a few 2's). With `batch_size=32` we did a little better, but still not convincing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 10s - loss: 8.9617 - mean_absolute_error: 2.3292    \n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 8s - loss: 4.3812 - mean_absolute_error: 1.6054     \n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 8s - loss: 4.7966 - mean_absolute_error: 1.6206     \n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 8s - loss: 3.5471 - mean_absolute_error: 1.4514     \n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 9s - loss: 4.2213 - mean_absolute_error: 1.4901     \n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 8s - loss: 3.0853 - mean_absolute_error: 1.3194     \n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 6s - loss: 2.7038 - mean_absolute_error: 1.2665     \n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 6s - loss: 2.3011 - mean_absolute_error: 1.0553     \n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 7s - loss: 1.3865 - mean_absolute_error: 0.9274     \n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 6s - loss: 1.4834 - mean_absolute_error: 0.9287     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f6b9990>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size=1)\n",
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size= 154)\n",
    "model.fit(X_train, Y_train, nb_epoch=10, batch_size=32) # 32 did way better than 1 on regression (opposite of classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[31.636980807666919, 3.1302032774144952]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.65935779],\n",
       "       [  1.7533114 ],\n",
       "       [ 16.78481102],\n",
       "       [  2.62229609],\n",
       "       [ 23.63639259],\n",
       "       [  2.28001046],\n",
       "       [  2.55056596],\n",
       "       [  2.42521453],\n",
       "       [  2.13297009],\n",
       "       [  1.97678781]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34545454545454546"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 9s - loss: 1.8540 - mean_absolute_error: 0.5040 - acc: 0.0901     \n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 7s - loss: 1.7172 - mean_absolute_error: 0.4740 - acc: 0.4054     \n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 7s - loss: 1.5716 - mean_absolute_error: 0.4411 - acc: 0.5676     \n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 6s - loss: 1.4568 - mean_absolute_error: 0.4139 - acc: 0.6847     \n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 6s - loss: 1.3706 - mean_absolute_error: 0.3894 - acc: 0.7748     \n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 6s - loss: 1.3246 - mean_absolute_error: 0.3702 - acc: 0.8604     \n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 6s - loss: 1.3036 - mean_absolute_error: 0.3612 - acc: 0.8919     \n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 6s - loss: 1.2670 - mean_absolute_error: 0.3459 - acc: 0.9279     \n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 6s - loss: 1.2586 - mean_absolute_error: 0.3401 - acc: 0.9505     \n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 6s - loss: 1.2548 - mean_absolute_error: 0.3378 - acc: 0.9505     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133eb66d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(data, labels, nb_epoch=10, batch_size=32) ### generic call from documentation\n",
    "model.fit(X_train,Y_cat_train, nb_epoch=10, batch_size=32)\n",
    "#model.fit(X_train, Y_cat_train, nb_epoch=10, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/55 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8108420699834824, 0.49770034822550685, 0.14545454545454545]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [2], [2], [2], [2], [2], [2], [2], [2], [2]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41818181818181815"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DROPOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## regression model - WITH DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 11s - loss: 8.8932 - mean_absolute_error: 2.3117 - acc: 0.1351    \n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 8s - loss: 3.6514 - mean_absolute_error: 1.5562 - acc: 0.1802     \n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 8s - loss: 3.9243 - mean_absolute_error: 1.6134 - acc: 0.2027     \n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 7s - loss: 3.3670 - mean_absolute_error: 1.4861 - acc: 0.1937     \n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 7s - loss: 3.1560 - mean_absolute_error: 1.4248 - acc: 0.2027     \n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 7s - loss: 2.6895 - mean_absolute_error: 1.3138 - acc: 0.2477     \n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 7s - loss: 2.8525 - mean_absolute_error: 1.3155 - acc: 0.2432     \n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 7s - loss: 2.6366 - mean_absolute_error: 1.3213 - acc: 0.2162     \n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 7s - loss: 2.6732 - mean_absolute_error: 1.2881 - acc: 0.2523     \n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 7s - loss: 2.7211 - mean_absolute_error: 1.2937 - acc: 0.2477     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141c74e50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train, Y_train, nb_epoch=10, batch_size= 1) #just like without dropout, this produced crazy predictions\n",
    "model.fit(X_train,Y_train, nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/55 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.2526552242396232, 2.1935987277464433, 0.10909090909090909]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.21051598],\n",
       "       [ 0.39288539],\n",
       "       [ 1.45857155],\n",
       "       [ 1.41592383],\n",
       "       [ 1.87833953],\n",
       "       [ 1.77807879],\n",
       "       [ 1.76397121],\n",
       "       [ 1.67770183],\n",
       "       [ 1.86329281],\n",
       "       [ 1.75807273]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2909090909090909"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## classification model - WITH DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(128, 7, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(192, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n",
    "\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling1D(pool_length=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(4096, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "#model.add(Dense(4096, init='normal'))\n",
    "model.add(Dense(1000, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "#model.add(Dense(1000, init='normal'))\n",
    "model.add(Dense(200, init='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 52s - loss: 1.8437 - mean_absolute_error: 0.5022 - acc: 0.2928    \n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 49s - loss: 1.8423 - mean_absolute_error: 0.5019 - acc: 0.3018    \n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 49s - loss: 1.8409 - mean_absolute_error: 0.5016 - acc: 0.3018    \n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 49s - loss: 1.8395 - mean_absolute_error: 0.5013 - acc: 0.3018    \n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 50s - loss: 1.8379 - mean_absolute_error: 0.5009 - acc: 0.3018    \n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 49s - loss: 1.8363 - mean_absolute_error: 0.5005 - acc: 0.3018    \n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 50s - loss: 1.8347 - mean_absolute_error: 0.5002 - acc: 0.3018    \n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 50s - loss: 1.8330 - mean_absolute_error: 0.4997 - acc: 0.3018    \n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 46s - loss: 1.8312 - mean_absolute_error: 0.4993 - acc: 0.3018    \n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 44s - loss: 1.8293 - mean_absolute_error: 0.4988 - acc: 0.3018    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14becb850>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(data, labels, nb_epoch=10, batch_size=32) ### generic call from documentation\n",
    "#model.fit(X_train,Y_cat_train, nb_epoch=10, batch_size=32)\n",
    "model.fit(X_train, Y_cat_train, nb_epoch=10, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/55 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0020201897079293, 0.52323233837431127, 0.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7], [7], [7], [7], [7], [7], [7], [6], [7], [7]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10909090909090909"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with a larger batch size (spoiler, it does really badly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#THE FULL SETUP, compacted\n",
    "model = Sequential(); model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2]))); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(128, 7, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(192, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(256, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3))\n",
    "model.add(Flatten()); model.add(Dense(4096, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.5)); model.add(Dense(1000, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.25)); model.add(Dense(200, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu'))\n",
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "222/222 [==============================] - 7s - loss: 1.8719 - mean_absolute_error: 0.5051 - acc: 0.0405     \n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 3s - loss: 1.8505 - mean_absolute_error: 0.5000 - acc: 0.1261     \n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 2s - loss: 1.8365 - mean_absolute_error: 0.4972 - acc: 0.1622     \n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 2s - loss: 1.8325 - mean_absolute_error: 0.4966 - acc: 0.1622     \n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 2s - loss: 1.8082 - mean_absolute_error: 0.4902 - acc: 0.2297     \n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 3s - loss: 1.7914 - mean_absolute_error: 0.4869 - acc: 0.3153     \n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 3s - loss: 1.7974 - mean_absolute_error: 0.4886 - acc: 0.2973     \n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 2s - loss: 1.7752 - mean_absolute_error: 0.4822 - acc: 0.3423     \n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 2s - loss: 1.7503 - mean_absolute_error: 0.4767 - acc: 0.3874     \n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 3s - loss: 1.7156 - mean_absolute_error: 0.4670 - acc: 0.4820     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16fa0fc50>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_cat_train, nb_epoch=10, batch_size=154)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/55 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8173169836401939, 0.4995492853901603, 0.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7], [7], [7], [7], [7], [7], [7], [7], [7], [7]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10909090909090909"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: this looks a little encouraging, but it's not\n",
    "It just guesses 3 for everything, and since about half the examples are 2,3,4, it counts those are correct. Also, if you run this identical thing a few times, it will come out differently, but always picking the same number for every testing observation. Last time it pick 7 for everything and got 10% accuracy.\n",
    "\n",
    "I also tried batch size 32 and got about the same result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running for more epochs (back to batch size 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#THE FULL SETUP, compacted\n",
    "model = Sequential(); model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2]))); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(128, 7, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(192, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(256, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3))\n",
    "model.add(Flatten()); model.add(Dense(4096, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.5)); model.add(Dense(1000, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.25)); model.add(Dense(200, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu'))\n",
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "222/222 [==============================] - 28s - loss: 1.8437 - mean_absolute_error: 0.5022 - acc: 0.2793    \n",
      "Epoch 2/20\n",
      "222/222 [==============================] - 25s - loss: 1.8423 - mean_absolute_error: 0.5019 - acc: 0.3018    \n",
      "Epoch 3/20\n",
      "222/222 [==============================] - 24s - loss: 1.8409 - mean_absolute_error: 0.5016 - acc: 0.3018    \n",
      "Epoch 4/20\n",
      "222/222 [==============================] - 23s - loss: 1.8395 - mean_absolute_error: 0.5013 - acc: 0.3018    \n",
      "Epoch 5/20\n",
      "222/222 [==============================] - 23s - loss: 1.8379 - mean_absolute_error: 0.5009 - acc: 0.3018    \n",
      "Epoch 6/20\n",
      "222/222 [==============================] - 22s - loss: 1.8363 - mean_absolute_error: 0.5006 - acc: 0.3018    \n",
      "Epoch 7/20\n",
      "222/222 [==============================] - 22s - loss: 1.8347 - mean_absolute_error: 0.5002 - acc: 0.3018    \n",
      "Epoch 8/20\n",
      "222/222 [==============================] - 22s - loss: 1.8330 - mean_absolute_error: 0.4998 - acc: 0.3018    \n",
      "Epoch 9/20\n",
      "222/222 [==============================] - 22s - loss: 1.8312 - mean_absolute_error: 0.4993 - acc: 0.3018    \n",
      "Epoch 10/20\n",
      "222/222 [==============================] - 26s - loss: 1.8293 - mean_absolute_error: 0.4989 - acc: 0.3018    \n",
      "Epoch 11/20\n",
      "222/222 [==============================] - 27s - loss: 1.8274 - mean_absolute_error: 0.4984 - acc: 0.3018    \n",
      "Epoch 12/20\n",
      "222/222 [==============================] - 28s - loss: 1.8254 - mean_absolute_error: 0.4979 - acc: 0.3018    \n",
      "Epoch 13/20\n",
      "222/222 [==============================] - 23s - loss: 1.8233 - mean_absolute_error: 0.4973 - acc: 0.3018    \n",
      "Epoch 14/20\n",
      "222/222 [==============================] - 25s - loss: 1.8211 - mean_absolute_error: 0.4967 - acc: 0.3018    \n",
      "Epoch 15/20\n",
      "222/222 [==============================] - 29s - loss: 1.8189 - mean_absolute_error: 0.4961 - acc: 0.3018    \n",
      "Epoch 16/20\n",
      "222/222 [==============================] - 23s - loss: 1.8166 - mean_absolute_error: 0.4955 - acc: 0.3018    \n",
      "Epoch 17/20\n",
      "222/222 [==============================] - 25s - loss: 1.8142 - mean_absolute_error: 0.4948 - acc: 0.3018    \n",
      "Epoch 18/20\n",
      "222/222 [==============================] - 21s - loss: 1.8119 - mean_absolute_error: 0.4941 - acc: 0.3018    \n",
      "Epoch 19/20\n",
      "222/222 [==============================] - 22s - loss: 1.8094 - mean_absolute_error: 0.4934 - acc: 0.3018    \n",
      "Epoch 20/20\n",
      "222/222 [==============================] - 22s - loss: 1.8070 - mean_absolute_error: 0.4926 - acc: 0.3018    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e0c1d10>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_cat_train, nb_epoch=20, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/55 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8121212101795456, 0.48686870052055881, 0.16363636363636364]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8], [7], [8], [5], [8], [8], [8], [5], [5], [7]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2909090909090909"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454545454545453"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is weird, right?\n",
    "y_pred_class_low = [[(np.argmax(pred)-2)] for pred in y_pred]\n",
    "y_pred_class_low[:10]\n",
    "DSIacc(Y_test,y_pred_class_low) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with crossentropy instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#THE FULL SETUP, compacted\n",
    "model = Sequential(); model.add(Convolution1D(64, 3, border_mode='same', input_shape=(X.shape[1],X.shape[2]))); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(128, 7, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(192, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3)); model.add(Convolution1D(256, 3, border_mode='same')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(AveragePooling1D(pool_length=3))\n",
    "model.add(Flatten()); model.add(Dense(4096, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.5)); model.add(Dense(1000, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu')); model.add(Dropout(.25)); model.add(Dense(200, init='normal')); model.add(BatchNormalization()); model.add(Activation('relu'))\n",
    "#\n",
    "model.add(Dense(9, activation='softmax')) # for categorical_cross_entropy, below (classification)\n",
    "#model.add(Dense(1)) # for mse, below (regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['mean_absolute_error','accuracy'])\n",
    "#model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "222/222 [==============================] - 43s - loss: 8.1251 - mean_absolute_error: 0.5017 - acc: 0.2973    \n",
      "Epoch 2/20\n",
      "222/222 [==============================] - 41s - loss: 7.9460 - mean_absolute_error: 0.5006 - acc: 0.3018    \n",
      "Epoch 3/20\n",
      "222/222 [==============================] - 41s - loss: 7.7965 - mean_absolute_error: 0.4996 - acc: 0.3018    \n",
      "Epoch 4/20\n",
      "222/222 [==============================] - 41s - loss: 7.6692 - mean_absolute_error: 0.4986 - acc: 0.3018    \n",
      "Epoch 5/20\n",
      "222/222 [==============================] - 41s - loss: 7.5572 - mean_absolute_error: 0.4976 - acc: 0.3018    \n",
      "Epoch 6/20\n",
      "222/222 [==============================] - 41s - loss: 7.4666 - mean_absolute_error: 0.4967 - acc: 0.3018    \n",
      "Epoch 7/20\n",
      "222/222 [==============================] - 41s - loss: 7.3891 - mean_absolute_error: 0.4958 - acc: 0.3018    \n",
      "Epoch 8/20\n",
      "222/222 [==============================] - 41s - loss: 7.3280 - mean_absolute_error: 0.4949 - acc: 0.3018    \n",
      "Epoch 9/20\n",
      "222/222 [==============================] - 41s - loss: 7.2742 - mean_absolute_error: 0.4941 - acc: 0.3018    \n",
      "Epoch 10/20\n",
      "222/222 [==============================] - 41s - loss: 7.2375 - mean_absolute_error: 0.4933 - acc: 0.3018    \n",
      "Epoch 11/20\n",
      "222/222 [==============================] - 41s - loss: 7.2000 - mean_absolute_error: 0.4926 - acc: 0.3018    \n",
      "Epoch 12/20\n",
      "222/222 [==============================] - 41s - loss: 7.1729 - mean_absolute_error: 0.4921 - acc: 0.3018    \n",
      "Epoch 13/20\n",
      "222/222 [==============================] - 41s - loss: 7.1565 - mean_absolute_error: 0.4914 - acc: 0.3018    \n",
      "Epoch 14/20\n",
      "222/222 [==============================] - 41s - loss: 7.1334 - mean_absolute_error: 0.4911 - acc: 0.3018    \n",
      "Epoch 15/20\n",
      "222/222 [==============================] - 41s - loss: 7.1259 - mean_absolute_error: 0.4905 - acc: 0.3018    \n",
      "Epoch 16/20\n",
      "222/222 [==============================] - 41s - loss: 7.1146 - mean_absolute_error: 0.4902 - acc: 0.3018    \n",
      "Epoch 17/20\n",
      "222/222 [==============================] - 41s - loss: 7.1124 - mean_absolute_error: 0.4898 - acc: 0.3018    \n",
      "Epoch 18/20\n",
      "222/222 [==============================] - 41s - loss: 7.1061 - mean_absolute_error: 0.4894 - acc: 0.3018    \n",
      "Epoch 19/20\n",
      "222/222 [==============================] - 41s - loss: 7.1009 - mean_absolute_error: 0.4891 - acc: 0.3018    \n",
      "Epoch 20/20\n",
      "222/222 [==============================] - 41s - loss: 7.1040 - mean_absolute_error: 0.4887 - acc: 0.3018    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x187e1a850>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_cat_train, nb_epoch=20, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/55 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[51.870961750637399, 0.50303031788630914, 0.090909090909090912]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_cat_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7], [3], [8], [8], [5], [8], [3], [4], [8], [2]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [[(np.argmax(pred)+1)] for pred in y_pred]\n",
    "y_pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [8],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32727272727272727"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIacc(Y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [visLang2]",
   "language": "python",
   "name": "Python [visLang2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
