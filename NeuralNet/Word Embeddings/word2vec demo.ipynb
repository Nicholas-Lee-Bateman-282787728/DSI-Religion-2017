{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained Google word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model_name='GoogleNews-vectors-negative300.bin'\n",
    "embedding_model = Word2Vec.load_word2vec_format(model_name, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples:\n",
    "- word2vec representation of the word 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.25976562e-01,   2.97851562e-02,   8.60595703e-03,\n",
       "         1.39648438e-01,  -2.56347656e-02,  -3.61328125e-02,\n",
       "         1.11816406e-01,  -1.98242188e-01,   5.12695312e-02,\n",
       "         3.63281250e-01,  -2.42187500e-01,  -3.02734375e-01,\n",
       "        -1.77734375e-01,  -2.49023438e-02,  -1.67968750e-01,\n",
       "        -1.69921875e-01,   3.46679688e-02,   5.21850586e-03,\n",
       "         4.63867188e-02,   1.28906250e-01,   1.36718750e-01,\n",
       "         1.12792969e-01,   5.95703125e-02,   1.36718750e-01,\n",
       "         1.01074219e-01,  -1.76757812e-01,  -2.51953125e-01,\n",
       "         5.98144531e-02,   3.41796875e-01,  -3.11279297e-02,\n",
       "         1.04492188e-01,   6.17675781e-02,   1.24511719e-01,\n",
       "         4.00390625e-01,  -3.22265625e-01,   8.39843750e-02,\n",
       "         3.90625000e-02,   5.85937500e-03,   7.03125000e-02,\n",
       "         1.72851562e-01,   1.38671875e-01,  -2.31445312e-01,\n",
       "         2.83203125e-01,   1.42578125e-01,   3.41796875e-01,\n",
       "        -2.39257812e-02,  -1.09863281e-01,   3.32031250e-02,\n",
       "        -5.46875000e-02,   1.53198242e-02,  -1.62109375e-01,\n",
       "         1.58203125e-01,  -2.59765625e-01,   2.01416016e-02,\n",
       "        -1.63085938e-01,   1.35803223e-03,  -1.44531250e-01,\n",
       "        -5.68847656e-02,   4.29687500e-02,  -2.46582031e-02,\n",
       "         1.85546875e-01,   4.47265625e-01,   9.58251953e-03,\n",
       "         1.31835938e-01,   9.86328125e-02,  -1.85546875e-01,\n",
       "        -1.00097656e-01,  -1.33789062e-01,  -1.25000000e-01,\n",
       "         2.83203125e-01,   1.23046875e-01,   5.32226562e-02,\n",
       "        -1.77734375e-01,   8.59375000e-02,  -2.18505859e-02,\n",
       "         2.05078125e-02,  -1.39648438e-01,   2.51464844e-02,\n",
       "         1.38671875e-01,  -1.05468750e-01,   1.38671875e-01,\n",
       "         8.88671875e-02,  -7.51953125e-02,  -2.13623047e-02,\n",
       "         1.72851562e-01,   4.63867188e-02,  -2.65625000e-01,\n",
       "         8.91113281e-03,   1.49414062e-01,   3.78417969e-02,\n",
       "         2.38281250e-01,  -1.24511719e-01,  -2.17773438e-01,\n",
       "        -1.81640625e-01,   2.97851562e-02,   5.71289062e-02,\n",
       "        -2.89306641e-02,   1.24511719e-02,   9.66796875e-02,\n",
       "        -2.31445312e-01,   5.81054688e-02,   6.68945312e-02,\n",
       "         7.08007812e-02,  -3.08593750e-01,  -2.14843750e-01,\n",
       "         1.45507812e-01,  -4.27734375e-01,  -9.39941406e-03,\n",
       "         1.54296875e-01,  -7.66601562e-02,   2.89062500e-01,\n",
       "         2.77343750e-01,  -4.86373901e-04,  -1.36718750e-01,\n",
       "         3.24218750e-01,  -2.46093750e-01,  -3.03649902e-03,\n",
       "        -2.11914062e-01,   1.25000000e-01,   2.69531250e-01,\n",
       "         2.04101562e-01,   8.25195312e-02,  -2.01171875e-01,\n",
       "        -1.60156250e-01,  -3.78417969e-02,  -1.20117188e-01,\n",
       "         1.15234375e-01,  -4.10156250e-02,  -3.95507812e-02,\n",
       "        -8.98437500e-02,   6.34765625e-03,   2.03125000e-01,\n",
       "         1.86523438e-01,   2.73437500e-01,   6.29882812e-02,\n",
       "         1.41601562e-01,  -9.81445312e-02,   1.38671875e-01,\n",
       "         1.82617188e-01,   1.73828125e-01,   1.73828125e-01,\n",
       "        -2.37304688e-01,   1.78710938e-01,   6.34765625e-02,\n",
       "         2.36328125e-01,  -2.08984375e-01,   8.74023438e-02,\n",
       "        -1.66015625e-01,  -7.91015625e-02,   2.43164062e-01,\n",
       "        -8.88671875e-02,   1.26953125e-01,  -2.16796875e-01,\n",
       "        -1.73828125e-01,  -3.59375000e-01,  -8.25195312e-02,\n",
       "        -6.49414062e-02,   5.07812500e-02,   1.35742188e-01,\n",
       "        -7.47070312e-02,  -1.64062500e-01,   1.15356445e-02,\n",
       "         4.45312500e-01,  -2.15820312e-01,  -1.11328125e-01,\n",
       "        -1.92382812e-01,   1.70898438e-01,  -1.25000000e-01,\n",
       "         2.65502930e-03,   1.92382812e-01,  -1.74804688e-01,\n",
       "         1.39648438e-01,   2.92968750e-01,   1.13281250e-01,\n",
       "         5.95703125e-02,  -6.39648438e-02,   9.96093750e-02,\n",
       "        -2.72216797e-02,   1.96533203e-02,   4.27246094e-02,\n",
       "        -2.46093750e-01,   6.39648438e-02,  -2.25585938e-01,\n",
       "        -1.68945312e-01,   2.89916992e-03,   8.20312500e-02,\n",
       "         3.41796875e-01,   4.32128906e-02,   1.32812500e-01,\n",
       "         1.42578125e-01,   7.61718750e-02,   5.98144531e-02,\n",
       "        -1.19140625e-01,   2.74658203e-03,  -6.29882812e-02,\n",
       "        -2.72216797e-02,  -4.82177734e-03,  -8.20312500e-02,\n",
       "        -2.49023438e-02,  -4.00390625e-01,  -1.06933594e-01,\n",
       "         4.24804688e-02,   7.76367188e-02,  -1.16699219e-01,\n",
       "         7.37304688e-02,  -9.22851562e-02,   1.07910156e-01,\n",
       "         1.58203125e-01,   4.24804688e-02,   1.26953125e-01,\n",
       "         3.61328125e-02,   2.67578125e-01,  -1.01074219e-01,\n",
       "        -3.02734375e-01,  -5.76171875e-02,   5.05371094e-02,\n",
       "         5.26428223e-04,  -2.07031250e-01,  -1.38671875e-01,\n",
       "        -8.97216797e-03,  -2.78320312e-02,  -1.41601562e-01,\n",
       "         2.07031250e-01,  -1.58203125e-01,   1.27929688e-01,\n",
       "         1.49414062e-01,  -2.24609375e-02,  -8.44726562e-02,\n",
       "         1.22558594e-01,   2.15820312e-01,  -2.13867188e-01,\n",
       "        -3.12500000e-01,  -3.73046875e-01,   4.08935547e-03,\n",
       "         1.07421875e-01,   1.06933594e-01,   7.32421875e-02,\n",
       "         8.97216797e-03,  -3.88183594e-02,  -1.29882812e-01,\n",
       "         1.49414062e-01,  -2.14843750e-01,  -1.83868408e-03,\n",
       "         9.91210938e-02,   1.57226562e-01,  -1.14257812e-01,\n",
       "        -2.05078125e-01,   9.91210938e-02,   3.69140625e-01,\n",
       "        -1.97265625e-01,   3.54003906e-02,   1.09375000e-01,\n",
       "         1.31835938e-01,   1.66992188e-01,   2.35351562e-01,\n",
       "         1.04980469e-01,  -4.96093750e-01,  -1.64062500e-01,\n",
       "        -1.56250000e-01,  -5.22460938e-02,   1.03027344e-01,\n",
       "         2.43164062e-01,  -1.88476562e-01,   5.07812500e-02,\n",
       "        -9.37500000e-02,  -6.68945312e-02,   2.27050781e-02,\n",
       "         7.61718750e-02,   2.89062500e-01,   3.10546875e-01,\n",
       "        -5.37109375e-02,   2.28515625e-01,   2.51464844e-02,\n",
       "         6.78710938e-02,  -1.21093750e-01,  -2.15820312e-01,\n",
       "        -2.73437500e-01,  -3.07617188e-02,  -3.37890625e-01,\n",
       "         1.53320312e-01,   2.33398438e-01,  -2.08007812e-01,\n",
       "         3.73046875e-01,   8.20312500e-02,   2.51953125e-01,\n",
       "        -7.61718750e-02,  -4.66308594e-02,  -2.23388672e-02,\n",
       "         2.99072266e-02,  -5.93261719e-02,  -4.66918945e-03,\n",
       "        -2.44140625e-01,  -2.09960938e-01,  -2.87109375e-01,\n",
       "        -4.54101562e-02,  -1.77734375e-01,  -2.79296875e-01,\n",
       "        -8.59375000e-02,   9.13085938e-02,   2.51953125e-01], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.wv['king']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most 10 similar words to the word 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.8569014072418213),\n",
       " ('queen', 0.8255470395088196),\n",
       " ('monarch', 0.8206589818000793),\n",
       " ('crown_prince', 0.8102101683616638),\n",
       " ('prince', 0.8079988956451416),\n",
       " ('sultan', 0.7932403683662415),\n",
       " ('ruler', 0.7898775935173035),\n",
       " ('princes', 0.782326877117157),\n",
       " ('Prince_Paras', 0.7716464996337891),\n",
       " ('throne', 0.7711045742034912)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('king',topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'king' - 'man' + 'woman' = 'queen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.9314123392105103)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul(positive=['woman', 'king'], negative=['man'], topn=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most 10 similar words to the word 'book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tome', 0.8742907047271729),\n",
       " ('books', 0.868958055973053),\n",
       " ('memoir', 0.8651455640792847),\n",
       " ('paperback_edition', 0.8434174656867981),\n",
       " ('autobiography', 0.8370755910873413),\n",
       " ('memoirs', 0.825256884098053),\n",
       " ('Book', 0.8239633440971375),\n",
       " ('paperback', 0.8235605359077454),\n",
       " ('novels', 0.8170721530914307),\n",
       " ('hardback', 0.8141531944274902)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings on Christian news articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 texts.\n",
      "Training Word2Vec model...\n",
      "Saving Word2Vec model 'religion.misc'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "import data_helpers\n",
    "# Set values for various parameters\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_features=300\n",
    "min_word_count=5\n",
    "context=4\n",
    "\n",
    "TEXT_DATA_DIR='20_newsgroup\\\\talk.religion.misc'\n",
    "sentences = []  # list of text articles\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    if fname.isdigit():\n",
    "        fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "        f = open(fpath)\n",
    "        sentences.append(f.read())\n",
    "        f.close()\n",
    "sentences = [s.strip() for s in sentences]\n",
    "x_text = [data_helpers.clean_str(sent) for sent in sentences]\n",
    "x_text = [s.split(\" \") for s in x_text]\n",
    "    \n",
    "print('Found %s texts.' % len(x_text))\n",
    "\n",
    "# Initialize and train the model\n",
    "print(\"Training Word2Vec model...\")\n",
    "x,  vocabulary, vocabulary_inv =data_helpers.load_data(x_text)\n",
    "sentences = [[vocabulary_inv[w] for w in s] for s in x]\n",
    "embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                    size=num_features, min_count = min_word_count, \\\n",
    "                    window = context, sample = downsampling)\n",
    "\n",
    "# If we don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "embedding_model.init_sims(replace=True)\n",
    "\n",
    "model_name='religion.misc'\n",
    "# Saving the model for later use. You can load it later using Word2Vec.load()\n",
    "print('Saving Word2Vec model \\'%s\\'' % model_name)\n",
    "embedding_model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nagasiva': <gensim.models.word2vec.Vocab at 0xe591ec0780>,\n",
       " 'woe': <gensim.models.word2vec.Vocab at 0xe5917c2c88>,\n",
       " 'long': <gensim.models.word2vec.Vocab at 0xe593fc2cf8>,\n",
       " 'whose': <gensim.models.word2vec.Vocab at 0xe591f180b8>,\n",
       " 'v2110a': <gensim.models.word2vec.Vocab at 0xe591f18fd0>,\n",
       " 'jefferson': <gensim.models.word2vec.Vocab at 0xe591d14240>,\n",
       " 'ridiculous': <gensim.models.word2vec.Vocab at 0xe591ec0668>,\n",
       " 'restriction': <gensim.models.word2vec.Vocab at 0xe5929cf4a8>,\n",
       " 'shotgun': <gensim.models.word2vec.Vocab at 0xe591fa6ba8>,\n",
       " 'trodwell': <gensim.models.word2vec.Vocab at 0xe591fc7b70>,\n",
       " 'paradox': <gensim.models.word2vec.Vocab at 0xe591d14278>,\n",
       " 'press': <gensim.models.word2vec.Vocab at 0xe5919a4dd8>,\n",
       " 'power': <gensim.models.word2vec.Vocab at 0xe5929cfa90>,\n",
       " 'feet': <gensim.models.word2vec.Vocab at 0xe592acb198>,\n",
       " 'insist': <gensim.models.word2vec.Vocab at 0xe591bd0550>,\n",
       " 'jxw': <gensim.models.word2vec.Vocab at 0xe591cd9f28>,\n",
       " 'faced': <gensim.models.word2vec.Vocab at 0xe5919a4f28>,\n",
       " 'arrogant': <gensim.models.word2vec.Vocab at 0xe5919a47f0>,\n",
       " 'conservative': <gensim.models.word2vec.Vocab at 0xe5919ae438>,\n",
       " 'follow': <gensim.models.word2vec.Vocab at 0xe5921bc898>,\n",
       " 'dennis': <gensim.models.word2vec.Vocab at 0xe591d14978>,\n",
       " 'strive': <gensim.models.word2vec.Vocab at 0xe5919ae2b0>,\n",
       " 'aurora': <gensim.models.word2vec.Vocab at 0xe591f33eb8>,\n",
       " 'doubts': <gensim.models.word2vec.Vocab at 0xe5919ae208>,\n",
       " 'turning': <gensim.models.word2vec.Vocab at 0xe592c04128>,\n",
       " 'keywords': <gensim.models.word2vec.Vocab at 0xe591d14390>,\n",
       " 'twelve': <gensim.models.word2vec.Vocab at 0xe5919aed68>,\n",
       " 'nm0w': <gensim.models.word2vec.Vocab at 0xe591ac15c0>,\n",
       " 'reaching': <gensim.models.word2vec.Vocab at 0xe591d142b0>,\n",
       " 'mwilson': <gensim.models.word2vec.Vocab at 0xe5919a48d0>,\n",
       " 'c5y93b': <gensim.models.word2vec.Vocab at 0xe591ac1550>,\n",
       " 'larson': <gensim.models.word2vec.Vocab at 0xe591ac1588>,\n",
       " 'halat': <gensim.models.word2vec.Vocab at 0xe5919aeda0>,\n",
       " 'adds': <gensim.models.word2vec.Vocab at 0xe591b412e8>,\n",
       " 't': <gensim.models.word2vec.Vocab at 0xe591d14208>,\n",
       " 'm': <gensim.models.word2vec.Vocab at 0xe5918a6438>,\n",
       " 'lack': <gensim.models.word2vec.Vocab at 0xe591955278>,\n",
       " 'cote': <gensim.models.word2vec.Vocab at 0xe5918a6240>,\n",
       " 'supernatural': <gensim.models.word2vec.Vocab at 0xe591de44e0>,\n",
       " 'concert': <gensim.models.word2vec.Vocab at 0xe5918a8dd8>,\n",
       " 'fiery': <gensim.models.word2vec.Vocab at 0xe5927db240>,\n",
       " 'constitute': <gensim.models.word2vec.Vocab at 0xe591ac1668>,\n",
       " 'fundamentalist': <gensim.models.word2vec.Vocab at 0xe591a15710>,\n",
       " 'ignorance': <gensim.models.word2vec.Vocab at 0xe591a15860>,\n",
       " '02': <gensim.models.word2vec.Vocab at 0xe5944467f0>,\n",
       " '214843': <gensim.models.word2vec.Vocab at 0xe591dc2080>,\n",
       " 'conservatives': <gensim.models.word2vec.Vocab at 0xe591ac1cc0>,\n",
       " '165717': <gensim.models.word2vec.Vocab at 0xe591ac16a0>,\n",
       " 'resort': <gensim.models.word2vec.Vocab at 0xe593ee4ac8>,\n",
       " 'informed': <gensim.models.word2vec.Vocab at 0xe5927db278>,\n",
       " 'prophet': <gensim.models.word2vec.Vocab at 0xe591ac16d8>,\n",
       " 'verifiable': <gensim.models.word2vec.Vocab at 0xe591a157b8>,\n",
       " 'definitions': <gensim.models.word2vec.Vocab at 0xe593ee4710>,\n",
       " 'kendigianism': <gensim.models.word2vec.Vocab at 0xe5942016a0>,\n",
       " 'friendly': <gensim.models.word2vec.Vocab at 0xe591a156d8>,\n",
       " 'unto': <gensim.models.word2vec.Vocab at 0xe591a15828>,\n",
       " 'mythology': <gensim.models.word2vec.Vocab at 0xe59186f7b8>,\n",
       " 'humble': <gensim.models.word2vec.Vocab at 0xe591ac1630>,\n",
       " 'devotees': <gensim.models.word2vec.Vocab at 0xe591a15630>,\n",
       " 'systems': <gensim.models.word2vec.Vocab at 0xe59187e8d0>,\n",
       " 'deeply': <gensim.models.word2vec.Vocab at 0xe591b36358>,\n",
       " 'stroke': <gensim.models.word2vec.Vocab at 0xe591ac1e10>,\n",
       " 'encourage': <gensim.models.word2vec.Vocab at 0xe5918b6160>,\n",
       " 'sons': <gensim.models.word2vec.Vocab at 0xe592dbb240>,\n",
       " 'insulting': <gensim.models.word2vec.Vocab at 0xe591832ba8>,\n",
       " 'patients': <gensim.models.word2vec.Vocab at 0xe593f9aac8>,\n",
       " 'apparent': <gensim.models.word2vec.Vocab at 0xe591832198>,\n",
       " 'minds': <gensim.models.word2vec.Vocab at 0xe59187e048>,\n",
       " 'denote': <gensim.models.word2vec.Vocab at 0xe59187e9b0>,\n",
       " '1qkndq': <gensim.models.word2vec.Vocab at 0xe593f9a908>,\n",
       " 'davidian': <gensim.models.word2vec.Vocab at 0xe5918fef98>,\n",
       " 'best': <gensim.models.word2vec.Vocab at 0xe591fa6b70>,\n",
       " 'asuvax': <gensim.models.word2vec.Vocab at 0xe591bfec18>,\n",
       " 'extermination': <gensim.models.word2vec.Vocab at 0xe591832470>,\n",
       " 'stretching': <gensim.models.word2vec.Vocab at 0xe591850b70>,\n",
       " 'affirmation': <gensim.models.word2vec.Vocab at 0xe591850860>,\n",
       " 'mil': <gensim.models.word2vec.Vocab at 0xe593f9a390>,\n",
       " 'focus': <gensim.models.word2vec.Vocab at 0xe593f9a3c8>,\n",
       " 'torture': <gensim.models.word2vec.Vocab at 0xe591832048>,\n",
       " 'regret': <gensim.models.word2vec.Vocab at 0xe591ef51d0>,\n",
       " 'inferior': <gensim.models.word2vec.Vocab at 0xe591851fd0>,\n",
       " 'military': <gensim.models.word2vec.Vocab at 0xe591832908>,\n",
       " 'rocky': <gensim.models.word2vec.Vocab at 0xe591862668>,\n",
       " 'anyway': <gensim.models.word2vec.Vocab at 0xe592a88fd0>,\n",
       " 'john': <gensim.models.word2vec.Vocab at 0xe591835390>,\n",
       " 'stan': <gensim.models.word2vec.Vocab at 0xe591835128>,\n",
       " 'till': <gensim.models.word2vec.Vocab at 0xe59190dd30>,\n",
       " 'bs': <gensim.models.word2vec.Vocab at 0xe591a44d30>,\n",
       " 'formed': <gensim.models.word2vec.Vocab at 0xe591835978>,\n",
       " 'root': <gensim.models.word2vec.Vocab at 0xe591b53208>,\n",
       " 'lie': <gensim.models.word2vec.Vocab at 0xe593f56e48>,\n",
       " 'same': <gensim.models.word2vec.Vocab at 0xe591835400>,\n",
       " 'historical': <gensim.models.word2vec.Vocab at 0xe591b53be0>,\n",
       " 'vesta': <gensim.models.word2vec.Vocab at 0xe591835ac8>,\n",
       " '1r9mflinnak4': <gensim.models.word2vec.Vocab at 0xe593f538d0>,\n",
       " 'san': <gensim.models.word2vec.Vocab at 0xe591bd0cc0>,\n",
       " 'elizabeth': <gensim.models.word2vec.Vocab at 0xe591b53b38>,\n",
       " 'ehsn17': <gensim.models.word2vec.Vocab at 0xe592816588>,\n",
       " 'them': <gensim.models.word2vec.Vocab at 0xe591bd04e0>,\n",
       " 'wanting': <gensim.models.word2vec.Vocab at 0xe592c96048>,\n",
       " 'facilities': <gensim.models.word2vec.Vocab at 0xe5940be748>,\n",
       " 'misunderstood': <gensim.models.word2vec.Vocab at 0xe5940be6d8>,\n",
       " 'opposite': <gensim.models.word2vec.Vocab at 0xe591eb2518>,\n",
       " 'bei': <gensim.models.word2vec.Vocab at 0xe591b53c88>,\n",
       " 'troops': <gensim.models.word2vec.Vocab at 0xe591b53c50>,\n",
       " 'emotionally': <gensim.models.word2vec.Vocab at 0xe5918fe6d8>,\n",
       " 'had': <gensim.models.word2vec.Vocab at 0xe591bd0da0>,\n",
       " 'front': <gensim.models.word2vec.Vocab at 0xe59180c2b0>,\n",
       " 'moreover': <gensim.models.word2vec.Vocab at 0xe592009a58>,\n",
       " '30136': <gensim.models.word2vec.Vocab at 0xe59180c358>,\n",
       " 'heart': <gensim.models.word2vec.Vocab at 0xe591b53a58>,\n",
       " 'rational': <gensim.models.word2vec.Vocab at 0xe5917c2780>,\n",
       " 'kleros': <gensim.models.word2vec.Vocab at 0xe591b5f1d0>,\n",
       " 'sinning': <gensim.models.word2vec.Vocab at 0xe592009c50>,\n",
       " 'southwestern': <gensim.models.word2vec.Vocab at 0xe592d759b0>,\n",
       " 'specifics': <gensim.models.word2vec.Vocab at 0xe591bd0d68>,\n",
       " 'holes': <gensim.models.word2vec.Vocab at 0xe592d75d30>,\n",
       " '173720': <gensim.models.word2vec.Vocab at 0xe59186cc18>,\n",
       " 'se': <gensim.models.word2vec.Vocab at 0xe593f14c88>,\n",
       " 'contexts': <gensim.models.word2vec.Vocab at 0xe591b5f208>,\n",
       " 'exod': <gensim.models.word2vec.Vocab at 0xe592b63320>,\n",
       " 'ra': <gensim.models.word2vec.Vocab at 0xe592b063c8>,\n",
       " 'shelley': <gensim.models.word2vec.Vocab at 0xe5921f2cf8>,\n",
       " 'planet': <gensim.models.word2vec.Vocab at 0xe591b8f438>,\n",
       " 'smoking': <gensim.models.word2vec.Vocab at 0xe591ad57b8>,\n",
       " 'captive': <gensim.models.word2vec.Vocab at 0xe5921f26d8>,\n",
       " 'accordingly': <gensim.models.word2vec.Vocab at 0xe591bd0f98>,\n",
       " 'across': <gensim.models.word2vec.Vocab at 0xe592ec95f8>,\n",
       " 'vote': <gensim.models.word2vec.Vocab at 0xe591a8e4e0>,\n",
       " 'luther': <gensim.models.word2vec.Vocab at 0xe591a6af98>,\n",
       " 'happen': <gensim.models.word2vec.Vocab at 0xe59410db70>,\n",
       " 'keith': <gensim.models.word2vec.Vocab at 0xe591bd04a8>,\n",
       " '1r0m89': <gensim.models.word2vec.Vocab at 0xe592979e48>,\n",
       " 'reduced': <gensim.models.word2vec.Vocab at 0xe592b63b00>,\n",
       " 'sarver': <gensim.models.word2vec.Vocab at 0xe591ae6dd8>,\n",
       " 'incompatible': <gensim.models.word2vec.Vocab at 0xe591b1a048>,\n",
       " 'documents': <gensim.models.word2vec.Vocab at 0xe591b1ab38>,\n",
       " 'constitutional': <gensim.models.word2vec.Vocab at 0xe592979f98>,\n",
       " 'barring': <gensim.models.word2vec.Vocab at 0xe5918eb940>,\n",
       " 'uchicago': <gensim.models.word2vec.Vocab at 0xe592bdd630>,\n",
       " 'hallam': <gensim.models.word2vec.Vocab at 0xe59190fcc0>,\n",
       " 'involved': <gensim.models.word2vec.Vocab at 0xe592979fd0>,\n",
       " 'brian': <gensim.models.word2vec.Vocab at 0xe5929a2e10>,\n",
       " '930426': <gensim.models.word2vec.Vocab at 0xe5940db438>,\n",
       " 'wealthy': <gensim.models.word2vec.Vocab at 0xe592bddef0>,\n",
       " 'linking': <gensim.models.word2vec.Vocab at 0xe591a6a908>,\n",
       " 'gjh': <gensim.models.word2vec.Vocab at 0xe591b1ab70>,\n",
       " 'kinds': <gensim.models.word2vec.Vocab at 0xe591a6a8d0>,\n",
       " 'be': <gensim.models.word2vec.Vocab at 0xe5928b6ef0>,\n",
       " 'dobson': <gensim.models.word2vec.Vocab at 0xe5920f1cf8>,\n",
       " 'refer': <gensim.models.word2vec.Vocab at 0xe591b10860>,\n",
       " 'descartes': <gensim.models.word2vec.Vocab at 0xe59196bcc0>,\n",
       " 'vary': <gensim.models.word2vec.Vocab at 0xe5919a4a20>,\n",
       " 'bed': <gensim.models.word2vec.Vocab at 0xe59196bac8>,\n",
       " 'skiba': <gensim.models.word2vec.Vocab at 0xe5944addd8>,\n",
       " 'care': <gensim.models.word2vec.Vocab at 0xe592205b00>,\n",
       " 'acknowledge': <gensim.models.word2vec.Vocab at 0xe592ccc320>,\n",
       " 'denies': <gensim.models.word2vec.Vocab at 0xe591b69048>,\n",
       " 'conflict': <gensim.models.word2vec.Vocab at 0xe592ccc940>,\n",
       " 'selves': <gensim.models.word2vec.Vocab at 0xe592ccc470>,\n",
       " 'constructed': <gensim.models.word2vec.Vocab at 0xe592dd7198>,\n",
       " '1993apr25': <gensim.models.word2vec.Vocab at 0xe5919ec1d0>,\n",
       " 'twisto': <gensim.models.word2vec.Vocab at 0xe59208ef60>,\n",
       " 'takes': <gensim.models.word2vec.Vocab at 0xe59196b5f8>,\n",
       " '1qgouk': <gensim.models.word2vec.Vocab at 0xe5919752b0>,\n",
       " 'request': <gensim.models.word2vec.Vocab at 0xe591975198>,\n",
       " 'dies': <gensim.models.word2vec.Vocab at 0xe59208e748>,\n",
       " 'attributed': <gensim.models.word2vec.Vocab at 0xe5945488d0>,\n",
       " 'doctor': <gensim.models.word2vec.Vocab at 0xe5919ecd68>,\n",
       " 'persian': <gensim.models.word2vec.Vocab at 0xe5919ec588>,\n",
       " 'meanings': <gensim.models.word2vec.Vocab at 0xe5919ec470>,\n",
       " 'depth': <gensim.models.word2vec.Vocab at 0xe591a49d30>,\n",
       " 'mercy': <gensim.models.word2vec.Vocab at 0xe592d74940>,\n",
       " 'structures': <gensim.models.word2vec.Vocab at 0xe591b48208>,\n",
       " 'want': <gensim.models.word2vec.Vocab at 0xe592d743c8>,\n",
       " 'merciful': <gensim.models.word2vec.Vocab at 0xe591c92780>,\n",
       " '000': <gensim.models.word2vec.Vocab at 0xe592d74400>,\n",
       " 'rick': <gensim.models.word2vec.Vocab at 0xe591f56630>,\n",
       " 'munnari': <gensim.models.word2vec.Vocab at 0xe591975588>,\n",
       " 'rationalism': <gensim.models.word2vec.Vocab at 0xe592b79da0>,\n",
       " 'a2r': <gensim.models.word2vec.Vocab at 0xe591975160>,\n",
       " 'etc': <gensim.models.word2vec.Vocab at 0xe591cfea90>,\n",
       " 'as': <gensim.models.word2vec.Vocab at 0xe591892438>,\n",
       " 'law': <gensim.models.word2vec.Vocab at 0xe592b79978>,\n",
       " '190493200420': <gensim.models.word2vec.Vocab at 0xe594374518>,\n",
       " 'covenant': <gensim.models.word2vec.Vocab at 0xe59186d358>,\n",
       " '6gs': <gensim.models.word2vec.Vocab at 0xe591ed7080>,\n",
       " 'va': <gensim.models.word2vec.Vocab at 0xe59186df28>,\n",
       " 'conclusions': <gensim.models.word2vec.Vocab at 0xe59186da90>,\n",
       " 'asks': <gensim.models.word2vec.Vocab at 0xe591a49630>,\n",
       " 'demonstrated': <gensim.models.word2vec.Vocab at 0xe5929b7b00>,\n",
       " 'lynn': <gensim.models.word2vec.Vocab at 0xe5918e66a0>,\n",
       " 'to': <gensim.models.word2vec.Vocab at 0xe5918e6630>,\n",
       " 'convictions': <gensim.models.word2vec.Vocab at 0xe5918b6dd8>,\n",
       " 'trust': <gensim.models.word2vec.Vocab at 0xe591a49d68>,\n",
       " 'eight': <gensim.models.word2vec.Vocab at 0xe592d025f8>,\n",
       " 'agr00': <gensim.models.word2vec.Vocab at 0xe5917cd0b8>,\n",
       " 'legends': <gensim.models.word2vec.Vocab at 0xe592153d30>,\n",
       " 'ah': <gensim.models.word2vec.Vocab at 0xe592153cf8>,\n",
       " 'devout': <gensim.models.word2vec.Vocab at 0xe5928464e0>,\n",
       " 'media': <gensim.models.word2vec.Vocab at 0xe592db36a0>,\n",
       " 'pure': <gensim.models.word2vec.Vocab at 0xe5918a4c88>,\n",
       " 'easter': <gensim.models.word2vec.Vocab at 0xe594374470>,\n",
       " 'bring': <gensim.models.word2vec.Vocab at 0xe594514a58>,\n",
       " 'cochrane': <gensim.models.word2vec.Vocab at 0xe592a634e0>,\n",
       " 'botched': <gensim.models.word2vec.Vocab at 0xe5918a4da0>,\n",
       " '093914': <gensim.models.word2vec.Vocab at 0xe592d5ac50>,\n",
       " 'next': <gensim.models.word2vec.Vocab at 0xe5918f75c0>,\n",
       " 'moral': <gensim.models.word2vec.Vocab at 0xe592a63748>,\n",
       " 'decayed': <gensim.models.word2vec.Vocab at 0xe591decba8>,\n",
       " 'twinkle': <gensim.models.word2vec.Vocab at 0xe5918f7668>,\n",
       " 'dk': <gensim.models.word2vec.Vocab at 0xe592153a20>,\n",
       " 'computing': <gensim.models.word2vec.Vocab at 0xe5919896a0>,\n",
       " 'ontario': <gensim.models.word2vec.Vocab at 0xe593f64f98>,\n",
       " 'huge': <gensim.models.word2vec.Vocab at 0xe593f02240>,\n",
       " 'condemn': <gensim.models.word2vec.Vocab at 0xe5919b47f0>,\n",
       " 'addresses': <gensim.models.word2vec.Vocab at 0xe591f55438>,\n",
       " '494': <gensim.models.word2vec.Vocab at 0xe5918f97b8>,\n",
       " 'mnemosyne': <gensim.models.word2vec.Vocab at 0xe5919897f0>,\n",
       " 'building': <gensim.models.word2vec.Vocab at 0xe592a63828>,\n",
       " 'trustworthy': <gensim.models.word2vec.Vocab at 0xe5919b47b8>,\n",
       " 'dispute': <gensim.models.word2vec.Vocab at 0xe5918f9710>,\n",
       " '82': <gensim.models.word2vec.Vocab at 0xe592d582e8>,\n",
       " 'application': <gensim.models.word2vec.Vocab at 0xe592a63198>,\n",
       " 'moving': <gensim.models.word2vec.Vocab at 0xe591e665c0>,\n",
       " 'personality': <gensim.models.word2vec.Vocab at 0xe592ef45c0>,\n",
       " 'islam': <gensim.models.word2vec.Vocab at 0xe5919955c0>,\n",
       " 'sacrifice': <gensim.models.word2vec.Vocab at 0xe5919ee208>,\n",
       " 'rc': <gensim.models.word2vec.Vocab at 0xe592bfd390>,\n",
       " 'moses': <gensim.models.word2vec.Vocab at 0xe5919b4b00>,\n",
       " '6dx': <gensim.models.word2vec.Vocab at 0xe591ac1c88>,\n",
       " \"y'know\": <gensim.models.word2vec.Vocab at 0xe591f10128>,\n",
       " 'ms': <gensim.models.word2vec.Vocab at 0xe591d2ec50>,\n",
       " 'accusing': <gensim.models.word2vec.Vocab at 0xe5921d40b8>,\n",
       " 'programs': <gensim.models.word2vec.Vocab at 0xe591a97cc0>,\n",
       " 'aspect': <gensim.models.word2vec.Vocab at 0xe5919b4c88>,\n",
       " 'sects': <gensim.models.word2vec.Vocab at 0xe592a63588>,\n",
       " 'c5ud1u': <gensim.models.word2vec.Vocab at 0xe5921d4e80>,\n",
       " 'schools': <gensim.models.word2vec.Vocab at 0xe59289cb38>,\n",
       " 'davis': <gensim.models.word2vec.Vocab at 0xe5919b4c50>,\n",
       " 'useless': <gensim.models.word2vec.Vocab at 0xe5917e35c0>,\n",
       " '1587': <gensim.models.word2vec.Vocab at 0xe5919b46a0>,\n",
       " 'atomic': <gensim.models.word2vec.Vocab at 0xe591d2ed68>,\n",
       " 'reliable': <gensim.models.word2vec.Vocab at 0xe5919c1748>,\n",
       " 'gone': <gensim.models.word2vec.Vocab at 0xe592a638d0>,\n",
       " 'uvic': <gensim.models.word2vec.Vocab at 0xe592a63a90>,\n",
       " 'opposites': <gensim.models.word2vec.Vocab at 0xe5919b4f98>,\n",
       " '110': <gensim.models.word2vec.Vocab at 0xe5944099e8>,\n",
       " 'ties': <gensim.models.word2vec.Vocab at 0xe594179080>,\n",
       " 'phill': <gensim.models.word2vec.Vocab at 0xe590b9b4a8>,\n",
       " 'sorry': <gensim.models.word2vec.Vocab at 0xe591c5c358>,\n",
       " 'xian': <gensim.models.word2vec.Vocab at 0xe592c14c18>,\n",
       " 'gf4': <gensim.models.word2vec.Vocab at 0xe591d2edd8>,\n",
       " 'explicitly': <gensim.models.word2vec.Vocab at 0xe59189e550>,\n",
       " 'bdi': <gensim.models.word2vec.Vocab at 0xe591d2ec88>,\n",
       " 'ftp': <gensim.models.word2vec.Vocab at 0xe591d2e860>,\n",
       " 'gospel': <gensim.models.word2vec.Vocab at 0xe591a63fd0>,\n",
       " 'parys': <gensim.models.word2vec.Vocab at 0xe59180b160>,\n",
       " 'beside': <gensim.models.word2vec.Vocab at 0xe591d141d0>,\n",
       " 'alexia': <gensim.models.word2vec.Vocab at 0xe591b82e48>,\n",
       " 'physik': <gensim.models.word2vec.Vocab at 0xe5919b4748>,\n",
       " '201': <gensim.models.word2vec.Vocab at 0xe591b1e550>,\n",
       " 'protestant': <gensim.models.word2vec.Vocab at 0xe5919b4780>,\n",
       " 'telepathy': <gensim.models.word2vec.Vocab at 0xe5919b45c0>,\n",
       " 'there': <gensim.models.word2vec.Vocab at 0xe591985208>,\n",
       " 'jews': <gensim.models.word2vec.Vocab at 0xe593fbc390>,\n",
       " 'atlas': <gensim.models.word2vec.Vocab at 0xe592c14b00>,\n",
       " 'referred': <gensim.models.word2vec.Vocab at 0xe591a63f98>,\n",
       " 'east': <gensim.models.word2vec.Vocab at 0xe591a56748>,\n",
       " 'anthony': <gensim.models.word2vec.Vocab at 0xe591a56d30>,\n",
       " 'philosopher': <gensim.models.word2vec.Vocab at 0xe5927b6860>,\n",
       " 'savior': <gensim.models.word2vec.Vocab at 0xe592178208>,\n",
       " 'll': <gensim.models.word2vec.Vocab at 0xe59191d5c0>,\n",
       " 'peaceful': <gensim.models.word2vec.Vocab at 0xe593fbc438>,\n",
       " 'use': <gensim.models.word2vec.Vocab at 0xe59414ebe0>,\n",
       " 'gt6511a': <gensim.models.word2vec.Vocab at 0xe591e75e10>,\n",
       " 'missouri': <gensim.models.word2vec.Vocab at 0xe5918fd438>,\n",
       " 'merit': <gensim.models.word2vec.Vocab at 0xe5942adcf8>,\n",
       " 'silly': <gensim.models.word2vec.Vocab at 0xe5920699b0>,\n",
       " 'po': <gensim.models.word2vec.Vocab at 0xe592c960f0>,\n",
       " 'reached': <gensim.models.word2vec.Vocab at 0xe591856358>,\n",
       " 'disclaimer': <gensim.models.word2vec.Vocab at 0xe5929d47f0>,\n",
       " 'brothers': <gensim.models.word2vec.Vocab at 0xe5920695f8>,\n",
       " 'letters': <gensim.models.word2vec.Vocab at 0xe592929898>,\n",
       " 'tecsun1': <gensim.models.word2vec.Vocab at 0xe5917df208>,\n",
       " 'cf': <gensim.models.word2vec.Vocab at 0xe591c2a6a0>,\n",
       " 'slaves': <gensim.models.word2vec.Vocab at 0xe5918fd9e8>,\n",
       " 'met': <gensim.models.word2vec.Vocab at 0xe591c2a668>,\n",
       " 'valuation': <gensim.models.word2vec.Vocab at 0xe5919dd5c0>,\n",
       " 'disinterested': <gensim.models.word2vec.Vocab at 0xe592c5b400>,\n",
       " '18345': <gensim.models.word2vec.Vocab at 0xe591970ef0>,\n",
       " 'deliberate': <gensim.models.word2vec.Vocab at 0xe591b349e8>,\n",
       " 'adams': <gensim.models.word2vec.Vocab at 0xe591ec72b0>,\n",
       " 'hand': <gensim.models.word2vec.Vocab at 0xe592e51b38>,\n",
       " 'iran': <gensim.models.word2vec.Vocab at 0xe5918ef5c0>,\n",
       " 'published': <gensim.models.word2vec.Vocab at 0xe5929d19e8>,\n",
       " 'liking': <gensim.models.word2vec.Vocab at 0xe592e8a9b0>,\n",
       " 'hits': <gensim.models.word2vec.Vocab at 0xe5919707b8>,\n",
       " '510': <gensim.models.word2vec.Vocab at 0xe5919707f0>,\n",
       " 'helpful': <gensim.models.word2vec.Vocab at 0xe591970518>,\n",
       " 'necessity': <gensim.models.word2vec.Vocab at 0xe592c96198>,\n",
       " 'concerned': <gensim.models.word2vec.Vocab at 0xe592c96358>,\n",
       " 'firearms': <gensim.models.word2vec.Vocab at 0xe591b34a20>,\n",
       " 'bbs': <gensim.models.word2vec.Vocab at 0xe5919706a0>,\n",
       " 'sometimes': <gensim.models.word2vec.Vocab at 0xe591d07208>,\n",
       " 'saic': <gensim.models.word2vec.Vocab at 0xe5919700f0>,\n",
       " 'evasion': <gensim.models.word2vec.Vocab at 0xe592cd20b8>,\n",
       " 'hypothesis': <gensim.models.word2vec.Vocab at 0xe593fd31d0>,\n",
       " 'onto': <gensim.models.word2vec.Vocab at 0xe591970550>,\n",
       " 'psuvm': <gensim.models.word2vec.Vocab at 0xe592cd2080>,\n",
       " 'documented': <gensim.models.word2vec.Vocab at 0xe591970668>,\n",
       " 'quote': <gensim.models.word2vec.Vocab at 0xe592c96828>,\n",
       " 'points': <gensim.models.word2vec.Vocab at 0xe591fb1588>,\n",
       " 'desired': <gensim.models.word2vec.Vocab at 0xe590b9b828>,\n",
       " 'cambridge': <gensim.models.word2vec.Vocab at 0xe591ca30f0>,\n",
       " 'ultimately': <gensim.models.word2vec.Vocab at 0xe591ca3128>,\n",
       " 'mcsun': <gensim.models.word2vec.Vocab at 0xe5917eadd8>,\n",
       " 'descended': <gensim.models.word2vec.Vocab at 0xe591f4f4e0>,\n",
       " 'rob': <gensim.models.word2vec.Vocab at 0xe5917dffd0>,\n",
       " 'zeus': <gensim.models.word2vec.Vocab at 0xe592c96f98>,\n",
       " 'existing': <gensim.models.word2vec.Vocab at 0xe591f4fda0>,\n",
       " 'action': <gensim.models.word2vec.Vocab at 0xe5942e1ac8>,\n",
       " 'psychological': <gensim.models.word2vec.Vocab at 0xe591f23c18>,\n",
       " 'toleration': <gensim.models.word2vec.Vocab at 0xe592cdb2b0>,\n",
       " 'disturbs': <gensim.models.word2vec.Vocab at 0xe591f4f668>,\n",
       " 'bullinger': <gensim.models.word2vec.Vocab at 0xe592cdb860>,\n",
       " 'independent': <gensim.models.word2vec.Vocab at 0xe592089f98>,\n",
       " 'pope': <gensim.models.word2vec.Vocab at 0xe592cdb278>,\n",
       " 'report': <gensim.models.word2vec.Vocab at 0xe5928d9e48>,\n",
       " 'ksu': <gensim.models.word2vec.Vocab at 0xe591a7b940>,\n",
       " 'potter': <gensim.models.word2vec.Vocab at 0xe5942e1a20>,\n",
       " 'ethic': <gensim.models.word2vec.Vocab at 0xe594142da0>,\n",
       " 'packet': <gensim.models.word2vec.Vocab at 0xe591c9e8d0>,\n",
       " 'accepting': <gensim.models.word2vec.Vocab at 0xe594142ef0>,\n",
       " 'hertz': <gensim.models.word2vec.Vocab at 0xe593ee4240>,\n",
       " 'clem': <gensim.models.word2vec.Vocab at 0xe591a35518>,\n",
       " 'wpr': <gensim.models.word2vec.Vocab at 0xe592082ba8>,\n",
       " 'yeah': <gensim.models.word2vec.Vocab at 0xe593ee4550>,\n",
       " 'benefit': <gensim.models.word2vec.Vocab at 0xe591dd4fd0>,\n",
       " 'pending': <gensim.models.word2vec.Vocab at 0xe5921f3518>,\n",
       " 'represent': <gensim.models.word2vec.Vocab at 0xe5928d6208>,\n",
       " 'plan': <gensim.models.word2vec.Vocab at 0xe5928d62b0>,\n",
       " 'jensen': <gensim.models.word2vec.Vocab at 0xe5918ffe48>,\n",
       " 'hkv': <gensim.models.word2vec.Vocab at 0xe5919957b8>,\n",
       " 'physicists': <gensim.models.word2vec.Vocab at 0xe5927ad240>,\n",
       " 'ashes': <gensim.models.word2vec.Vocab at 0xe591fdc748>,\n",
       " 'hela': <gensim.models.word2vec.Vocab at 0xe593ee4da0>,\n",
       " 's1': <gensim.models.word2vec.Vocab at 0xe593ee4518>,\n",
       " 'house': <gensim.models.word2vec.Vocab at 0xe5918ffb38>,\n",
       " 'clothing': <gensim.models.word2vec.Vocab at 0xe5917e9400>,\n",
       " 'singularity': <gensim.models.word2vec.Vocab at 0xe5919eb390>,\n",
       " 'herrings': <gensim.models.word2vec.Vocab at 0xe5918ff208>,\n",
       " 'sake': <gensim.models.word2vec.Vocab at 0xe594152898>,\n",
       " 'described': <gensim.models.word2vec.Vocab at 0xe5928d6748>,\n",
       " 'good': <gensim.models.word2vec.Vocab at 0xe591a62cc0>,\n",
       " 'apostle': <gensim.models.word2vec.Vocab at 0xe5919eb4e0>,\n",
       " '1qk1md': <gensim.models.word2vec.Vocab at 0xe592bf9fd0>,\n",
       " 'firey': <gensim.models.word2vec.Vocab at 0xe592833390>,\n",
       " 'c5w7ca': <gensim.models.word2vec.Vocab at 0xe592ec6278>,\n",
       " 'examined': <gensim.models.word2vec.Vocab at 0xe594152828>,\n",
       " 'violated': <gensim.models.word2vec.Vocab at 0xe591955f98>,\n",
       " 'ce': <gensim.models.word2vec.Vocab at 0xe5928d6710>,\n",
       " 'barney': <gensim.models.word2vec.Vocab at 0xe5917e9860>,\n",
       " 'dakota': <gensim.models.word2vec.Vocab at 0xe591d4fda0>,\n",
       " '025426': <gensim.models.word2vec.Vocab at 0xe592204c88>,\n",
       " 'resulting': <gensim.models.word2vec.Vocab at 0xe591d624e0>,\n",
       " 'robert': <gensim.models.word2vec.Vocab at 0xe591a76978>,\n",
       " 'indeed': <gensim.models.word2vec.Vocab at 0xe5943f17f0>,\n",
       " 'search': <gensim.models.word2vec.Vocab at 0xe591d5a080>,\n",
       " 'concept': <gensim.models.word2vec.Vocab at 0xe591a7ee80>,\n",
       " 'fruit': <gensim.models.word2vec.Vocab at 0xe591f15e10>,\n",
       " 'reality': <gensim.models.word2vec.Vocab at 0xe591ac17b8>,\n",
       " 'arguement': <gensim.models.word2vec.Vocab at 0xe592c1eba8>,\n",
       " 'got': <gensim.models.word2vec.Vocab at 0xe592134c50>,\n",
       " 'behave': <gensim.models.word2vec.Vocab at 0xe59451f5f8>,\n",
       " 'hall': <gensim.models.word2vec.Vocab at 0xe591fa6a90>,\n",
       " 'wait': <gensim.models.word2vec.Vocab at 0xe5928ed160>,\n",
       " 'concluded': <gensim.models.word2vec.Vocab at 0xe591acfd30>,\n",
       " 'commandments': <gensim.models.word2vec.Vocab at 0xe59451f320>,\n",
       " 'loether': <gensim.models.word2vec.Vocab at 0xe591a4ba58>,\n",
       " 'parallel': <gensim.models.word2vec.Vocab at 0xe591d62e48>,\n",
       " 'contradictions': <gensim.models.word2vec.Vocab at 0xe59451f9b0>,\n",
       " 'criminal': <gensim.models.word2vec.Vocab at 0xe591f55ac8>,\n",
       " 'hands': <gensim.models.word2vec.Vocab at 0xe591a4b6d8>,\n",
       " 'nuscc': <gensim.models.word2vec.Vocab at 0xe591906208>,\n",
       " 'evaluate': <gensim.models.word2vec.Vocab at 0xe592ddc320>,\n",
       " 'riggs': <gensim.models.word2vec.Vocab at 0xe591d62e10>,\n",
       " 'witness': <gensim.models.word2vec.Vocab at 0xe592ddc6a0>,\n",
       " 'meal': <gensim.models.word2vec.Vocab at 0xe592bc66d8>,\n",
       " 'sets': <gensim.models.word2vec.Vocab at 0xe592ddcc88>,\n",
       " 'unconditional': <gensim.models.word2vec.Vocab at 0xe5928c2d30>,\n",
       " 'wound': <gensim.models.word2vec.Vocab at 0xe592be7898>,\n",
       " 'existed': <gensim.models.word2vec.Vocab at 0xe594190dd8>,\n",
       " 'hey': <gensim.models.word2vec.Vocab at 0xe591b7d400>,\n",
       " 'nanci': <gensim.models.word2vec.Vocab at 0xe591b7d5c0>,\n",
       " 'putting': <gensim.models.word2vec.Vocab at 0xe591b7d518>,\n",
       " 'dealing': <gensim.models.word2vec.Vocab at 0xe591d92240>,\n",
       " 'table': <gensim.models.word2vec.Vocab at 0xe59222d908>,\n",
       " 'exists': <gensim.models.word2vec.Vocab at 0xe59440b4a8>,\n",
       " 'leprss': <gensim.models.word2vec.Vocab at 0xe591b7d4e0>,\n",
       " 'goes': <gensim.models.word2vec.Vocab at 0xe591a6f550>,\n",
       " 'eden': <gensim.models.word2vec.Vocab at 0xe59180e7f0>,\n",
       " 'ended': <gensim.models.word2vec.Vocab at 0xe59440bf60>,\n",
       " 'me': <gensim.models.word2vec.Vocab at 0xe591cbdc50>,\n",
       " 'normal': <gensim.models.word2vec.Vocab at 0xe591a1c1d0>,\n",
       " 'rintintin': <gensim.models.word2vec.Vocab at 0xe59440ba20>,\n",
       " 'basically': <gensim.models.word2vec.Vocab at 0xe591a6fe48>,\n",
       " 'already': <gensim.models.word2vec.Vocab at 0xe591a1c198>,\n",
       " 'happy': <gensim.models.word2vec.Vocab at 0xe591a1c160>,\n",
       " 'pardon': <gensim.models.word2vec.Vocab at 0xe5921f8630>,\n",
       " 'sender': <gensim.models.word2vec.Vocab at 0xe591f9a438>,\n",
       " 'tune': <gensim.models.word2vec.Vocab at 0xe591cbda20>,\n",
       " 'specific': <gensim.models.word2vec.Vocab at 0xe591a6feb8>,\n",
       " 'require': <gensim.models.word2vec.Vocab at 0xe591a6f390>,\n",
       " 'indication': <gensim.models.word2vec.Vocab at 0xe5919fad68>,\n",
       " 'hil': <gensim.models.word2vec.Vocab at 0xe5917b5c18>,\n",
       " 'surrounding': <gensim.models.word2vec.Vocab at 0xe591a1c2b0>,\n",
       " 'thyat': <gensim.models.word2vec.Vocab at 0xe591cbdac8>,\n",
       " '235420': <gensim.models.word2vec.Vocab at 0xe591c48d68>,\n",
       " 'pagan': <gensim.models.word2vec.Vocab at 0xe591a6f5f8>,\n",
       " '258': <gensim.models.word2vec.Vocab at 0xe591eae550>,\n",
       " '140493214334': <gensim.models.word2vec.Vocab at 0xe5941a3be0>,\n",
       " 'margoli': <gensim.models.word2vec.Vocab at 0xe5941a3240>,\n",
       " 'demonstration': <gensim.models.word2vec.Vocab at 0xe591cbdda0>,\n",
       " 'outward': <gensim.models.word2vec.Vocab at 0xe591cbde10>,\n",
       " 'quasars': <gensim.models.word2vec.Vocab at 0xe5929e69e8>,\n",
       " 'mat': <gensim.models.word2vec.Vocab at 0xe5929e69b0>,\n",
       " 'grows': <gensim.models.word2vec.Vocab at 0xe591ca0978>,\n",
       " 'cosmic': <gensim.models.word2vec.Vocab at 0xe591c48eb8>,\n",
       " 'having': <gensim.models.word2vec.Vocab at 0xe5927b8518>,\n",
       " 'assimilated': <gensim.models.word2vec.Vocab at 0xe5929627f0>,\n",
       " '79899': <gensim.models.word2vec.Vocab at 0xe5918f2278>,\n",
       " 'translations': <gensim.models.word2vec.Vocab at 0xe5918f2c50>,\n",
       " 'fundamental': <gensim.models.word2vec.Vocab at 0xe591bda518>,\n",
       " 'view': <gensim.models.word2vec.Vocab at 0xe591bda2b0>,\n",
       " 'thread': <gensim.models.word2vec.Vocab at 0xe592c97eb8>,\n",
       " 'dont': <gensim.models.word2vec.Vocab at 0xe591bda278>,\n",
       " 'another': <gensim.models.word2vec.Vocab at 0xe594257550>,\n",
       " 'motives': <gensim.models.word2vec.Vocab at 0xe592ecb278>,\n",
       " '15072': <gensim.models.word2vec.Vocab at 0xe591db1240>,\n",
       " 'a21': <gensim.models.word2vec.Vocab at 0xe5918f2eb8>,\n",
       " 'rotten': <gensim.models.word2vec.Vocab at 0xe592ecb240>,\n",
       " '23': <gensim.models.word2vec.Vocab at 0xe5918f2f98>,\n",
       " 'hellenistic': <gensim.models.word2vec.Vocab at 0xe59181acf8>,\n",
       " 'increased': <gensim.models.word2vec.Vocab at 0xe591fae5c0>,\n",
       " 'tentative': <gensim.models.word2vec.Vocab at 0xe5920ab9b0>,\n",
       " 'membership': <gensim.models.word2vec.Vocab at 0xe592861320>,\n",
       " 'louis': <gensim.models.word2vec.Vocab at 0xe5920526a0>,\n",
       " 'statement': <gensim.models.word2vec.Vocab at 0xe5920ab978>,\n",
       " 'kelly': <gensim.models.word2vec.Vocab at 0xe591f3a390>,\n",
       " 'controlled': <gensim.models.word2vec.Vocab at 0xe5944532e8>,\n",
       " 'd012s658': <gensim.models.word2vec.Vocab at 0xe592962898>,\n",
       " 'srl03': <gensim.models.word2vec.Vocab at 0xe5941b8710>,\n",
       " 'b68': <gensim.models.word2vec.Vocab at 0xe594066240>,\n",
       " 'destroying': <gensim.models.word2vec.Vocab at 0xe592e323c8>,\n",
       " '\\\\)': <gensim.models.word2vec.Vocab at 0xe593fb2da0>,\n",
       " 'poor': <gensim.models.word2vec.Vocab at 0xe592e32400>,\n",
       " 'myth': <gensim.models.word2vec.Vocab at 0xe591e1e8d0>,\n",
       " '1993apr1': <gensim.models.word2vec.Vocab at 0xe592e327b8>,\n",
       " 'bobsarv': <gensim.models.word2vec.Vocab at 0xe591b3b550>,\n",
       " 'fan': <gensim.models.word2vec.Vocab at 0xe591c35f98>,\n",
       " 'tt3r2b5w165w': <gensim.models.word2vec.Vocab at 0xe591f3a358>,\n",
       " 'hopper': <gensim.models.word2vec.Vocab at 0xe591fe5e80>,\n",
       " 'burial': <gensim.models.word2vec.Vocab at 0xe591bf2e80>,\n",
       " 'noticed': <gensim.models.word2vec.Vocab at 0xe591f99518>,\n",
       " 'reports': <gensim.models.word2vec.Vocab at 0xe591f99438>,\n",
       " 'smoke': <gensim.models.word2vec.Vocab at 0xe59287c978>,\n",
       " 'ufl': <gensim.models.word2vec.Vocab at 0xe591fe5b38>,\n",
       " '1qtsmc': <gensim.models.word2vec.Vocab at 0xe591a61518>,\n",
       " 'invariant': <gensim.models.word2vec.Vocab at 0xe5927c62e8>,\n",
       " 'one': <gensim.models.word2vec.Vocab at 0xe591862400>,\n",
       " 'requirements': <gensim.models.word2vec.Vocab at 0xe591942550>,\n",
       " 'begun': <gensim.models.word2vec.Vocab at 0xe592a9fe48>,\n",
       " 'religous': <gensim.models.word2vec.Vocab at 0xe592a9fe80>,\n",
       " 'quack': <gensim.models.word2vec.Vocab at 0xe592117470>,\n",
       " 'multiple': <gensim.models.word2vec.Vocab at 0xe5943f8ac8>,\n",
       " 'implying': <gensim.models.word2vec.Vocab at 0xe592117c18>,\n",
       " 'beautiful': <gensim.models.word2vec.Vocab at 0xe5921a7550>,\n",
       " 'jew': <gensim.models.word2vec.Vocab at 0xe592c35128>,\n",
       " 'reminded': <gensim.models.word2vec.Vocab at 0xe592117be0>,\n",
       " 'creed': <gensim.models.word2vec.Vocab at 0xe5943f8240>,\n",
       " 'author': <gensim.models.word2vec.Vocab at 0xe592117588>,\n",
       " 'autre': <gensim.models.word2vec.Vocab at 0xe591f3ceb8>,\n",
       " 'end': <gensim.models.word2vec.Vocab at 0xe592c35940>,\n",
       " 'levels': <gensim.models.word2vec.Vocab at 0xe592117780>,\n",
       " 'responsibility': <gensim.models.word2vec.Vocab at 0xe591c5f780>,\n",
       " 'c5vgyd': <gensim.models.word2vec.Vocab at 0xe59207bac8>,\n",
       " 'leading': <gensim.models.word2vec.Vocab at 0xe592c35ac8>,\n",
       " 'pasadena': <gensim.models.word2vec.Vocab at 0xe593f86e48>,\n",
       " 'dartmouth': <gensim.models.word2vec.Vocab at 0xe592a413c8>,\n",
       " 'rogers': <gensim.models.word2vec.Vocab at 0xe592c35278>,\n",
       " 'at1': <gensim.models.word2vec.Vocab at 0xe592c35080>,\n",
       " '1qkj31': <gensim.models.word2vec.Vocab at 0xe59286fc88>,\n",
       " 'yes': <gensim.models.word2vec.Vocab at 0xe592117400>,\n",
       " 'defined': <gensim.models.word2vec.Vocab at 0xe591f6fd68>,\n",
       " 'mark': <gensim.models.word2vec.Vocab at 0xe591a442e8>,\n",
       " 'known': <gensim.models.word2vec.Vocab at 0xe591855160>,\n",
       " 'regard': <gensim.models.word2vec.Vocab at 0xe591855550>,\n",
       " 'conner': <gensim.models.word2vec.Vocab at 0xe592117f60>,\n",
       " 'flesh': <gensim.models.word2vec.Vocab at 0xe591b51cf8>,\n",
       " 'paradise': <gensim.models.word2vec.Vocab at 0xe591a44be0>,\n",
       " 'confidence': <gensim.models.word2vec.Vocab at 0xe591c6bac8>,\n",
       " 'surprised': <gensim.models.word2vec.Vocab at 0xe591b53278>,\n",
       " 'usceast': <gensim.models.word2vec.Vocab at 0xe591d2cfd0>,\n",
       " 'posters': <gensim.models.word2vec.Vocab at 0xe591c60518>,\n",
       " 'beyond': <gensim.models.word2vec.Vocab at 0xe591b533c8>,\n",
       " 'establish': <gensim.models.word2vec.Vocab at 0xe5918f1ba8>,\n",
       " 'skinner': <gensim.models.word2vec.Vocab at 0xe591d2cf98>,\n",
       " 'title': <gensim.models.word2vec.Vocab at 0xe591d2cf28>,\n",
       " 'opponents': <gensim.models.word2vec.Vocab at 0xe591e35f60>,\n",
       " 'higher': <gensim.models.word2vec.Vocab at 0xe591e35978>,\n",
       " '194144': <gensim.models.word2vec.Vocab at 0xe591c6eb70>,\n",
       " 'ericsson': <gensim.models.word2vec.Vocab at 0xe591f199b0>,\n",
       " 'dollar': <gensim.models.word2vec.Vocab at 0xe5921100b8>,\n",
       " 'assess': <gensim.models.word2vec.Vocab at 0xe591c6e668>,\n",
       " 'thirty': <gensim.models.word2vec.Vocab at 0xe5921100f0>,\n",
       " 'primary': <gensim.models.word2vec.Vocab at 0xe5929577f0>,\n",
       " '001102': <gensim.models.word2vec.Vocab at 0xe591c6bdd8>,\n",
       " 'fails': <gensim.models.word2vec.Vocab at 0xe591f39dd8>,\n",
       " 'inherently': <gensim.models.word2vec.Vocab at 0xe591c6ba90>,\n",
       " 'rom': <gensim.models.word2vec.Vocab at 0xe591bd0588>,\n",
       " 'mary': <gensim.models.word2vec.Vocab at 0xe591c6b1d0>,\n",
       " 'pl9': <gensim.models.word2vec.Vocab at 0xe5929577b8>,\n",
       " 'painful': <gensim.models.word2vec.Vocab at 0xe591c7c9e8>,\n",
       " 'largely': <gensim.models.word2vec.Vocab at 0xe5929760f0>,\n",
       " 'terrorism': <gensim.models.word2vec.Vocab at 0xe591b0d4e0>,\n",
       " 'result': <gensim.models.word2vec.Vocab at 0xe591c6ec18>,\n",
       " 'relate': <gensim.models.word2vec.Vocab at 0xe591b0d518>,\n",
       " 'ditto': <gensim.models.word2vec.Vocab at 0xe5927ef208>,\n",
       " 'hosts': <gensim.models.word2vec.Vocab at 0xe592ab90b8>,\n",
       " 'granted': <gensim.models.word2vec.Vocab at 0xe5927efd30>,\n",
       " 'tactics': <gensim.models.word2vec.Vocab at 0xe5927ef400>,\n",
       " 'sitting': <gensim.models.word2vec.Vocab at 0xe591d34668>,\n",
       " 'not': <gensim.models.word2vec.Vocab at 0xe591c6eef0>,\n",
       " 'voice': <gensim.models.word2vec.Vocab at 0xe591d346a0>,\n",
       " 'practice': <gensim.models.word2vec.Vocab at 0xe591b0dcc0>,\n",
       " 'council': <gensim.models.word2vec.Vocab at 0xe591d34b00>,\n",
       " 'simon': <gensim.models.word2vec.Vocab at 0xe59206bd68>,\n",
       " 'skippy': <gensim.models.word2vec.Vocab at 0xe59185ed68>,\n",
       " '463': <gensim.models.word2vec.Vocab at 0xe591a28198>,\n",
       " 'going': <gensim.models.word2vec.Vocab at 0xe59206b748>,\n",
       " 'participate': <gensim.models.word2vec.Vocab at 0xe59206bdd8>,\n",
       " 'experiment': <gensim.models.word2vec.Vocab at 0xe591c6e080>,\n",
       " 'popular': <gensim.models.word2vec.Vocab at 0xe5919ac828>,\n",
       " 'presents': <gensim.models.word2vec.Vocab at 0xe591d34da0>,\n",
       " 'straight': <gensim.models.word2vec.Vocab at 0xe591d34e10>,\n",
       " 'bhagavad': <gensim.models.word2vec.Vocab at 0xe591eb1588>,\n",
       " 'compared': <gensim.models.word2vec.Vocab at 0xe591a28a20>,\n",
       " 'assertion': <gensim.models.word2vec.Vocab at 0xe591a47d30>,\n",
       " 'jesus': <gensim.models.word2vec.Vocab at 0xe593faf128>,\n",
       " '002509': <gensim.models.word2vec.Vocab at 0xe591d34898>,\n",
       " 'speaking': <gensim.models.word2vec.Vocab at 0xe591c6e198>,\n",
       " 'notwithstanding': <gensim.models.word2vec.Vocab at 0xe5921fc908>,\n",
       " 'program': <gensim.models.word2vec.Vocab at 0xe59206b9b0>,\n",
       " 'green': <gensim.models.word2vec.Vocab at 0xe59409e7f0>,\n",
       " 'rodan': <gensim.models.word2vec.Vocab at 0xe591a28b00>,\n",
       " 'testimonies': <gensim.models.word2vec.Vocab at 0xe59451a9e8>,\n",
       " '113530': <gensim.models.word2vec.Vocab at 0xe591a28860>,\n",
       " 'formation': <gensim.models.word2vec.Vocab at 0xe592a0ee80>,\n",
       " 'thee': <gensim.models.word2vec.Vocab at 0xe5918ee198>,\n",
       " 'board': <gensim.models.word2vec.Vocab at 0xe5918eed30>,\n",
       " 'sat': <gensim.models.word2vec.Vocab at 0xe592a0ee10>,\n",
       " 'fallen': <gensim.models.word2vec.Vocab at 0xe5918eef98>,\n",
       " 'lis450bw': <gensim.models.word2vec.Vocab at 0xe591a28a90>,\n",
       " '\\\\(': <gensim.models.word2vec.Vocab at 0xe591cb2240>,\n",
       " '1qvtk4': <gensim.models.word2vec.Vocab at 0xe592a0ed30>,\n",
       " 'genocide': <gensim.models.word2vec.Vocab at 0xe591cb2cc0>,\n",
       " 'nsc': <gensim.models.word2vec.Vocab at 0xe591d42048>,\n",
       " 'ann': <gensim.models.word2vec.Vocab at 0xe591d425c0>,\n",
       " 'logically': <gensim.models.word2vec.Vocab at 0xe592dd65c0>,\n",
       " 'learned': <gensim.models.word2vec.Vocab at 0xe592dd65f8>,\n",
       " 'orientis': <gensim.models.word2vec.Vocab at 0xe591d42588>,\n",
       " 'remove': <gensim.models.word2vec.Vocab at 0xe591e67f98>,\n",
       " 'forgiving': <gensim.models.word2vec.Vocab at 0xe591e9c3c8>,\n",
       " 'c5ymir': <gensim.models.word2vec.Vocab at 0xe591e67b00>,\n",
       " 'determining': <gensim.models.word2vec.Vocab at 0xe5918dc9e8>,\n",
       " 'lose': <gensim.models.word2vec.Vocab at 0xe592a8a160>,\n",
       " 'files': <gensim.models.word2vec.Vocab at 0xe591e67940>,\n",
       " 'witch': <gensim.models.word2vec.Vocab at 0xe5918f1a58>,\n",
       " 'noone': <gensim.models.word2vec.Vocab at 0xe592a8acf8>,\n",
       " 'mathew': <gensim.models.word2vec.Vocab at 0xe592a8a470>,\n",
       " 'iscsvax': <gensim.models.word2vec.Vocab at 0xe5929ba160>,\n",
       " 'abortions': <gensim.models.word2vec.Vocab at 0xe5921ad9b0>,\n",
       " 'neither': <gensim.models.word2vec.Vocab at 0xe592df9dd8>,\n",
       " 'sell': <gensim.models.word2vec.Vocab at 0xe592a8a048>,\n",
       " 'iron': <gensim.models.word2vec.Vocab at 0xe5921ad908>,\n",
       " '1qvk8sinn9vo': <gensim.models.word2vec.Vocab at 0xe591e72470>,\n",
       " 'vague': <gensim.models.word2vec.Vocab at 0xe592a8a630>,\n",
       " 'andrew': <gensim.models.word2vec.Vocab at 0xe5918dc278>,\n",
       " 'convincing': <gensim.models.word2vec.Vocab at 0xe59413e8d0>,\n",
       " 'assuming': <gensim.models.word2vec.Vocab at 0xe59284ce48>,\n",
       " 'applicable': <gensim.models.word2vec.Vocab at 0xe5918dc6a0>,\n",
       " 'sincerely': <gensim.models.word2vec.Vocab at 0xe5918dceb8>,\n",
       " 'parent': <gensim.models.word2vec.Vocab at 0xe592a8a2e8>,\n",
       " 'showing': <gensim.models.word2vec.Vocab at 0xe5918dc208>,\n",
       " 'hereafter': <gensim.models.word2vec.Vocab at 0xe591dafef0>,\n",
       " 'varying': <gensim.models.word2vec.Vocab at 0xe5941ff7b8>,\n",
       " 'deletions': <gensim.models.word2vec.Vocab at 0xe59187d9e8>,\n",
       " 'dialogue': <gensim.models.word2vec.Vocab at 0xe5927b64a8>,\n",
       " 'yea': <gensim.models.word2vec.Vocab at 0xe591a3dac8>,\n",
       " 'disobedience': <gensim.models.word2vec.Vocab at 0xe592a8a3c8>,\n",
       " 'figure': <gensim.models.word2vec.Vocab at 0xe591a3d080>,\n",
       " 'cold': <gensim.models.word2vec.Vocab at 0xe591effa20>,\n",
       " 'ba': <gensim.models.word2vec.Vocab at 0xe591c7cb70>,\n",
       " 'show': <gensim.models.word2vec.Vocab at 0xe591d9d3c8>,\n",
       " 'feb': <gensim.models.word2vec.Vocab at 0xe592066828>,\n",
       " 'scholars': <gensim.models.word2vec.Vocab at 0xe591d9d400>,\n",
       " 'keep': <gensim.models.word2vec.Vocab at 0xe591d9dc88>,\n",
       " 'happiness': <gensim.models.word2vec.Vocab at 0xe591eff9b0>,\n",
       " 'firing': <gensim.models.word2vec.Vocab at 0xe591a4de10>,\n",
       " 'places': <gensim.models.word2vec.Vocab at 0xe5920665f8>,\n",
       " 'kem': <gensim.models.word2vec.Vocab at 0xe591a4de48>,\n",
       " '1r1u5t': <gensim.models.word2vec.Vocab at 0xe592bc6f60>,\n",
       " 'scriptures': <gensim.models.word2vec.Vocab at 0xe591a4df28>,\n",
       " 'mrs': <gensim.models.word2vec.Vocab at 0xe5920666d8>,\n",
       " 'bold': <gensim.models.word2vec.Vocab at 0xe592c09390>,\n",
       " 'medical': <gensim.models.word2vec.Vocab at 0xe591a3d400>,\n",
       " 'automatically': <gensim.models.word2vec.Vocab at 0xe591c338d0>,\n",
       " 'members': <gensim.models.word2vec.Vocab at 0xe591bc5b00>,\n",
       " 'james': <gensim.models.word2vec.Vocab at 0xe591c33438>,\n",
       " 'pile': <gensim.models.word2vec.Vocab at 0xe5917b37f0>,\n",
       " 'partly': <gensim.models.word2vec.Vocab at 0xe591eff8d0>,\n",
       " 'grenades': <gensim.models.word2vec.Vocab at 0xe591eff080>,\n",
       " 'old': <gensim.models.word2vec.Vocab at 0xe591fc5a90>,\n",
       " 'rain': <gensim.models.word2vec.Vocab at 0xe591960710>,\n",
       " '143754': <gensim.models.word2vec.Vocab at 0xe591a3d7f0>,\n",
       " 'companion': <gensim.models.word2vec.Vocab at 0xe591960550>,\n",
       " 'executioner': <gensim.models.word2vec.Vocab at 0xe5918ab3c8>,\n",
       " 'showed': <gensim.models.word2vec.Vocab at 0xe592e14780>,\n",
       " '210109': <gensim.models.word2vec.Vocab at 0xe591c18748>,\n",
       " 'nonexistent': <gensim.models.word2vec.Vocab at 0xe59186cbe0>,\n",
       " 'norman': <gensim.models.word2vec.Vocab at 0xe591bec9b0>,\n",
       " '2': <gensim.models.word2vec.Vocab at 0xe5919605f8>,\n",
       " 'gap': <gensim.models.word2vec.Vocab at 0xe5919607f0>,\n",
       " 'holocaust': <gensim.models.word2vec.Vocab at 0xe591a3d240>,\n",
       " 'act': <gensim.models.word2vec.Vocab at 0xe59186c358>,\n",
       " 'c5hr14': <gensim.models.word2vec.Vocab at 0xe59186c908>,\n",
       " 'profit': <gensim.models.word2vec.Vocab at 0xe592cae908>,\n",
       " 'celebrated': <gensim.models.word2vec.Vocab at 0xe591a3d3c8>,\n",
       " 'equally': <gensim.models.word2vec.Vocab at 0xe592caefd0>,\n",
       " 'survived': <gensim.models.word2vec.Vocab at 0xe591be9be0>,\n",
       " 'pick': <gensim.models.word2vec.Vocab at 0xe591a3d518>,\n",
       " 'entering': <gensim.models.word2vec.Vocab at 0xe592bd83c8>,\n",
       " 'repeated': <gensim.models.word2vec.Vocab at 0xe591ad5c18>,\n",
       " '170493161548': <gensim.models.word2vec.Vocab at 0xe59186cd68>,\n",
       " 'dna': <gensim.models.word2vec.Vocab at 0xe591ad5c50>,\n",
       " 'motive': <gensim.models.word2vec.Vocab at 0xe592bd8400>,\n",
       " 'speculative': <gensim.models.word2vec.Vocab at 0xe591e19d68>,\n",
       " 'behaviour': <gensim.models.word2vec.Vocab at 0xe591d11748>,\n",
       " 'ccsvax': <gensim.models.word2vec.Vocab at 0xe592025cc0>,\n",
       " 'contract': <gensim.models.word2vec.Vocab at 0xe592025c88>,\n",
       " 'witnesses': <gensim.models.word2vec.Vocab at 0xe591d11b00>,\n",
       " 'antiquity': <gensim.models.word2vec.Vocab at 0xe5920257b8>,\n",
       " 'status': <gensim.models.word2vec.Vocab at 0xe59440c128>,\n",
       " 'exciting': <gensim.models.word2vec.Vocab at 0xe5919f2be0>,\n",
       " 'albrecht': <gensim.models.word2vec.Vocab at 0xe591ad5ba8>,\n",
       " 'four': <gensim.models.word2vec.Vocab at 0xe591ad5be0>,\n",
       " '045548': <gensim.models.word2vec.Vocab at 0xe5919f2c50>,\n",
       " 'nineteenth': <gensim.models.word2vec.Vocab at 0xe591d11780>,\n",
       " 'tend': <gensim.models.word2vec.Vocab at 0xe592856e48>,\n",
       " 'lunar': <gensim.models.word2vec.Vocab at 0xe5918dc5f8>,\n",
       " 'agnostics': <gensim.models.word2vec.Vocab at 0xe592025780>,\n",
       " 'through': <gensim.models.word2vec.Vocab at 0xe5940a4fd0>,\n",
       " '2055': <gensim.models.word2vec.Vocab at 0xe592856748>,\n",
       " 'imperfect': <gensim.models.word2vec.Vocab at 0xe5940a4f98>,\n",
       " 'champaign': <gensim.models.word2vec.Vocab at 0xe591d75ef0>,\n",
       " 'chicago': <gensim.models.word2vec.Vocab at 0xe591b2e2e8>,\n",
       " 'competition': <gensim.models.word2vec.Vocab at 0xe5940a4e10>,\n",
       " 'could': <gensim.models.word2vec.Vocab at 0xe592ad7cf8>,\n",
       " 'freedoms': <gensim.models.word2vec.Vocab at 0xe5940f8f60>,\n",
       " 'wolfe': <gensim.models.word2vec.Vocab at 0xe5919e87f0>,\n",
       " 'impressed': <gensim.models.word2vec.Vocab at 0xe592e75828>,\n",
       " 'dial': <gensim.models.word2vec.Vocab at 0xe592e75320>,\n",
       " 'jk3': <gensim.models.word2vec.Vocab at 0xe59180bb00>,\n",
       " 'knowledge': <gensim.models.word2vec.Vocab at 0xe5940a4f60>,\n",
       " 'broken': <gensim.models.word2vec.Vocab at 0xe591bc7d68>,\n",
       " 'parks': <gensim.models.word2vec.Vocab at 0xe592bee7b8>,\n",
       " 'infernal': <gensim.models.word2vec.Vocab at 0xe5940a4e48>,\n",
       " 'study': <gensim.models.word2vec.Vocab at 0xe592e757f0>,\n",
       " 'warwick': <gensim.models.word2vec.Vocab at 0xe592d68d30>,\n",
       " 'sacred': <gensim.models.word2vec.Vocab at 0xe592025ac8>,\n",
       " 'abstract': <gensim.models.word2vec.Vocab at 0xe592932630>,\n",
       " 'hours': <gensim.models.word2vec.Vocab at 0xe592bee780>,\n",
       " 'worse': <gensim.models.word2vec.Vocab at 0xe592d18e80>,\n",
       " 'lfoard': <gensim.models.word2vec.Vocab at 0xe5940a4240>,\n",
       " 'herb': <gensim.models.word2vec.Vocab at 0xe591ac4940>,\n",
       " 'couple': <gensim.models.word2vec.Vocab at 0xe591998dd8>,\n",
       " 'wisconsin': <gensim.models.word2vec.Vocab at 0xe59183be48>,\n",
       " 'lowell': <gensim.models.word2vec.Vocab at 0xe592d31eb8>,\n",
       " 'substance': <gensim.models.word2vec.Vocab at 0xe5918599b0>,\n",
       " 'ic': <gensim.models.word2vec.Vocab at 0xe5927b67b8>,\n",
       " 'corpse': <gensim.models.word2vec.Vocab at 0xe591ef61d0>,\n",
       " 'opinions': <gensim.models.word2vec.Vocab at 0xe591859dd8>,\n",
       " 'certainty': <gensim.models.word2vec.Vocab at 0xe5929956d8>,\n",
       " \"don't\": <gensim.models.word2vec.Vocab at 0xe591a81cf8>,\n",
       " '26': <gensim.models.word2vec.Vocab at 0xe591bd0518>,\n",
       " 'otherwise': <gensim.models.word2vec.Vocab at 0xe591ac40b8>,\n",
       " 'traditions': <gensim.models.word2vec.Vocab at 0xe591c74be0>,\n",
       " '930423': <gensim.models.word2vec.Vocab at 0xe591ac4748>,\n",
       " 'murder': <gensim.models.word2vec.Vocab at 0xe591c742e8>,\n",
       " 'consult': <gensim.models.word2vec.Vocab at 0xe5917c8160>,\n",
       " 'memory': <gensim.models.word2vec.Vocab at 0xe590b9bb70>,\n",
       " 'mob': <gensim.models.word2vec.Vocab at 0xe591ac4e48>,\n",
       " 'behaved': <gensim.models.word2vec.Vocab at 0xe5919c2240>,\n",
       " 'cares': <gensim.models.word2vec.Vocab at 0xe591ac4d68>,\n",
       " 'atone': <gensim.models.word2vec.Vocab at 0xe591ac4b70>,\n",
       " 'spontaneous': <gensim.models.word2vec.Vocab at 0xe59278d710>,\n",
       " 'say': <gensim.models.word2vec.Vocab at 0xe59278db70>,\n",
       " 'implicitly': <gensim.models.word2vec.Vocab at 0xe592805c88>,\n",
       " 'fast': <gensim.models.word2vec.Vocab at 0xe5917c88d0>,\n",
       " 'jokke': <gensim.models.word2vec.Vocab at 0xe5917c86a0>,\n",
       " 'charges': <gensim.models.word2vec.Vocab at 0xe5917c8860>,\n",
       " 'relative': <gensim.models.word2vec.Vocab at 0xe5919c2898>,\n",
       " 'watson': <gensim.models.word2vec.Vocab at 0xe5921b36a0>,\n",
       " 'poster': <gensim.models.word2vec.Vocab at 0xe5917c8f98>,\n",
       " 'luckily': <gensim.models.word2vec.Vocab at 0xe591804f28>,\n",
       " 'cranford': <gensim.models.word2vec.Vocab at 0xe5919c2b00>,\n",
       " 'instruction': <gensim.models.word2vec.Vocab at 0xe5919c2a20>,\n",
       " 'hour': <gensim.models.word2vec.Vocab at 0xe591a36e48>,\n",
       " '1qsili': <gensim.models.word2vec.Vocab at 0xe592804c88>,\n",
       " 'produce': <gensim.models.word2vec.Vocab at 0xe5917c8128>,\n",
       " 'guy': <gensim.models.word2vec.Vocab at 0xe592804860>,\n",
       " 'propane': <gensim.models.word2vec.Vocab at 0xe591a36438>,\n",
       " 'ways': <gensim.models.word2vec.Vocab at 0xe592804ba8>,\n",
       " 'mentioning': <gensim.models.word2vec.Vocab at 0xe5917c8cc0>,\n",
       " 'experiences': <gensim.models.word2vec.Vocab at 0xe591a36518>,\n",
       " '1993apr7': <gensim.models.word2vec.Vocab at 0xe591f73978>,\n",
       " 'travel': <gensim.models.word2vec.Vocab at 0xe5940fe550>,\n",
       " 'modes': <gensim.models.word2vec.Vocab at 0xe5940fe4a8>,\n",
       " 'athena': <gensim.models.word2vec.Vocab at 0xe59207e2e8>,\n",
       " 'allelou': <gensim.models.word2vec.Vocab at 0xe593fc0198>,\n",
       " 'naked': <gensim.models.word2vec.Vocab at 0xe591bf65f8>,\n",
       " 'chip': <gensim.models.word2vec.Vocab at 0xe591bf6320>,\n",
       " 'boi': <gensim.models.word2vec.Vocab at 0xe592a3ad68>,\n",
       " 'invisible': <gensim.models.word2vec.Vocab at 0xe5927a69e8>,\n",
       " 'duffy': <gensim.models.word2vec.Vocab at 0xe591bf6828>,\n",
       " 'grotesquely': <gensim.models.word2vec.Vocab at 0xe5927a64e0>,\n",
       " 'studying': <gensim.models.word2vec.Vocab at 0xe5917c8be0>,\n",
       " 'getting': <gensim.models.word2vec.Vocab at 0xe5927a6f98>,\n",
       " 'wmich': <gensim.models.word2vec.Vocab at 0xe591d45a20>,\n",
       " 'trinity': <gensim.models.word2vec.Vocab at 0xe591be7978>,\n",
       " 'jmd': <gensim.models.word2vec.Vocab at 0xe5927b6f98>,\n",
       " 'mother': <gensim.models.word2vec.Vocab at 0xe59180cef0>,\n",
       " 'efforts': <gensim.models.word2vec.Vocab at 0xe591bfecc0>,\n",
       " 'taylor': <gensim.models.word2vec.Vocab at 0xe5917c8da0>,\n",
       " 'gm': <gensim.models.word2vec.Vocab at 0xe5941771d0>,\n",
       " 'extensive': <gensim.models.word2vec.Vocab at 0xe5917c8240>,\n",
       " 'reserved': <gensim.models.word2vec.Vocab at 0xe5917c8c88>,\n",
       " 'b64635': <gensim.models.word2vec.Vocab at 0xe593ed4630>,\n",
       " 'campus': <gensim.models.word2vec.Vocab at 0xe592a36eb8>,\n",
       " 'burden': <gensim.models.word2vec.Vocab at 0xe591d732b0>,\n",
       " 'whichever': <gensim.models.word2vec.Vocab at 0xe592a36e10>,\n",
       " 'tensmeyer': <gensim.models.word2vec.Vocab at 0xe591829048>,\n",
       " 'lpl': <gensim.models.word2vec.Vocab at 0xe591d732e8>,\n",
       " 'unwilling': <gensim.models.word2vec.Vocab at 0xe5917c84e0>,\n",
       " 'eh': <gensim.models.word2vec.Vocab at 0xe593ed4898>,\n",
       " '93': <gensim.models.word2vec.Vocab at 0xe592a36dd8>,\n",
       " 'properly': <gensim.models.word2vec.Vocab at 0xe592201cf8>,\n",
       " 'glean': <gensim.models.word2vec.Vocab at 0xe592879828>,\n",
       " 'jurisdiction': <gensim.models.word2vec.Vocab at 0xe5917c8940>,\n",
       " 'carrying': <gensim.models.word2vec.Vocab at 0xe593ed4c18>,\n",
       " 'register': <gensim.models.word2vec.Vocab at 0xe594240b00>,\n",
       " 'greater': <gensim.models.word2vec.Vocab at 0xe59190f518>,\n",
       " 'virtually': <gensim.models.word2vec.Vocab at 0xe5917c84a8>,\n",
       " 'lightning': <gensim.models.word2vec.Vocab at 0xe593ed4c50>,\n",
       " 'remaining': <gensim.models.word2vec.Vocab at 0xe5929ee7f0>,\n",
       " 'sit': <gensim.models.word2vec.Vocab at 0xe5929ee668>,\n",
       " 'templars': <gensim.models.word2vec.Vocab at 0xe5929ee278>,\n",
       " 'meaningful': <gensim.models.word2vec.Vocab at 0xe5917c8518>,\n",
       " 'sigh': <gensim.models.word2vec.Vocab at 0xe592979438>,\n",
       " 'headwall': <gensim.models.word2vec.Vocab at 0xe59190f0b8>,\n",
       " '8oz': <gensim.models.word2vec.Vocab at 0xe592a17278>,\n",
       " 'rite': <gensim.models.word2vec.Vocab at 0xe5921c5cc0>,\n",
       " 'provide': <gensim.models.word2vec.Vocab at 0xe594318fd0>,\n",
       " 'dzoo': <gensim.models.word2vec.Vocab at 0xe59190f390>,\n",
       " 'proven': <gensim.models.word2vec.Vocab at 0xe5929ee2b0>,\n",
       " 'problems': <gensim.models.word2vec.Vocab at 0xe594088a58>,\n",
       " 'soviet': <gensim.models.word2vec.Vocab at 0xe5917c8080>,\n",
       " 'grant': <gensim.models.word2vec.Vocab at 0xe591c04550>,\n",
       " 'mmm': <gensim.models.word2vec.Vocab at 0xe592a174a8>,\n",
       " 'radiation': <gensim.models.word2vec.Vocab at 0xe592b80278>,\n",
       " 'rutherford': <gensim.models.word2vec.Vocab at 0xe591c04668>,\n",
       " 'recall': <gensim.models.word2vec.Vocab at 0xe591f718d0>,\n",
       " 'investigation': <gensim.models.word2vec.Vocab at 0xe592b804e0>,\n",
       " 'movement': <gensim.models.word2vec.Vocab at 0xe592b80ef0>,\n",
       " 'penis': <gensim.models.word2vec.Vocab at 0xe591f71c50>,\n",
       " 'judaism': <gensim.models.word2vec.Vocab at 0xe591a9cfd0>,\n",
       " 'shake': <gensim.models.word2vec.Vocab at 0xe591a9ca20>,\n",
       " '5nx': <gensim.models.word2vec.Vocab at 0xe592b99048>,\n",
       " 'interest': <gensim.models.word2vec.Vocab at 0xe592b6c0b8>,\n",
       " 'fmsrl7': <gensim.models.word2vec.Vocab at 0xe592b6c080>,\n",
       " 'naive': <gensim.models.word2vec.Vocab at 0xe59279e8d0>,\n",
       " 'records': <gensim.models.word2vec.Vocab at 0xe591c04d68>,\n",
       " '476': <gensim.models.word2vec.Vocab at 0xe5917b6ef0>,\n",
       " '87': <gensim.models.word2vec.Vocab at 0xe591c045f8>,\n",
       " 'responsible': <gensim.models.word2vec.Vocab at 0xe59279e470>,\n",
       " 'match': <gensim.models.word2vec.Vocab at 0xe59403b6a0>,\n",
       " 'yadlowsky': <gensim.models.word2vec.Vocab at 0xe591f88588>,\n",
       " 'oulu': <gensim.models.word2vec.Vocab at 0xe592037e10>,\n",
       " 'ps': <gensim.models.word2vec.Vocab at 0xe591f88a58>,\n",
       " 'expert': <gensim.models.word2vec.Vocab at 0xe5919c7ac8>,\n",
       " 'nc': <gensim.models.word2vec.Vocab at 0xe591c04ac8>,\n",
       " 'violent': <gensim.models.word2vec.Vocab at 0xe5919c74a8>,\n",
       " 'hope': <gensim.models.word2vec.Vocab at 0xe59209e908>,\n",
       " 'previous': <gensim.models.word2vec.Vocab at 0xe59279ec18>,\n",
       " 'judges': <gensim.models.word2vec.Vocab at 0xe59222c0f0>,\n",
       " 'lord': <gensim.models.word2vec.Vocab at 0xe592862dd8>,\n",
       " 'expected': <gensim.models.word2vec.Vocab at 0xe592c222e8>,\n",
       " 'perish': <gensim.models.word2vec.Vocab at 0xe5919c7c18>,\n",
       " 'similarly': <gensim.models.word2vec.Vocab at 0xe59279e4a8>,\n",
       " 'k0e': <gensim.models.word2vec.Vocab at 0xe59192f390>,\n",
       " 'je': <gensim.models.word2vec.Vocab at 0xe591c047f0>,\n",
       " 'cried': <gensim.models.word2vec.Vocab at 0xe591c049e8>,\n",
       " 'views': <gensim.models.word2vec.Vocab at 0xe5919c7e48>,\n",
       " 'biology': <gensim.models.word2vec.Vocab at 0xe59192f908>,\n",
       " 'compare': <gensim.models.word2vec.Vocab at 0xe5918de048>,\n",
       " 'accepted': <gensim.models.word2vec.Vocab at 0xe5919c74e0>,\n",
       " 'caldwell': <gensim.models.word2vec.Vocab at 0xe59279e278>,\n",
       " '1993apr27': <gensim.models.word2vec.Vocab at 0xe592a89c50>,\n",
       " 'considers': <gensim.models.word2vec.Vocab at 0xe59279e978>,\n",
       " 'standard': <gensim.models.word2vec.Vocab at 0xe591e73240>,\n",
       " 'apollo': <gensim.models.word2vec.Vocab at 0xe591c0a2e8>,\n",
       " 'hut': <gensim.models.word2vec.Vocab at 0xe5917b3ac8>,\n",
       " 'fair': <gensim.models.word2vec.Vocab at 0xe592a894a8>,\n",
       " '1r0v5uinnfea': <gensim.models.word2vec.Vocab at 0xe5929a2c88>,\n",
       " 'cost': <gensim.models.word2vec.Vocab at 0xe5928bd550>,\n",
       " 'canon': <gensim.models.word2vec.Vocab at 0xe59198ecc0>,\n",
       " 'gilligan': <gensim.models.word2vec.Vocab at 0xe592a89a90>,\n",
       " 'cacs': <gensim.models.word2vec.Vocab at 0xe592b2d320>,\n",
       " 'ad': <gensim.models.word2vec.Vocab at 0xe59183b860>,\n",
       " 'natural': <gensim.models.word2vec.Vocab at 0xe592e5d828>,\n",
       " 'deane': <gensim.models.word2vec.Vocab at 0xe592a89c88>,\n",
       " 'terrorist': <gensim.models.word2vec.Vocab at 0xe591b10a90>,\n",
       " 'random': <gensim.models.word2vec.Vocab at 0xe59202a898>,\n",
       " 'striving': <gensim.models.word2vec.Vocab at 0xe592a89ac8>,\n",
       " 'drieux': <gensim.models.word2vec.Vocab at 0xe592a89cf8>,\n",
       " 'ubvmsb': <gensim.models.word2vec.Vocab at 0xe591816d30>,\n",
       " 'compromise': <gensim.models.word2vec.Vocab at 0xe592b2ddd8>,\n",
       " 'division': <gensim.models.word2vec.Vocab at 0xe5929006d8>,\n",
       " 'zazen': <gensim.models.word2vec.Vocab at 0xe5918e98d0>,\n",
       " 'george': <gensim.models.word2vec.Vocab at 0xe592a89eb8>,\n",
       " 'organization': <gensim.models.word2vec.Vocab at 0xe5918a15c0>,\n",
       " 'walls': <gensim.models.word2vec.Vocab at 0xe592dd7240>,\n",
       " 'metaphysical': <gensim.models.word2vec.Vocab at 0xe592b2de80>,\n",
       " 'weaver': <gensim.models.word2vec.Vocab at 0xe5928edd68>,\n",
       " 'appreciated': <gensim.models.word2vec.Vocab at 0xe5918e9c88>,\n",
       " 'inference': <gensim.models.word2vec.Vocab at 0xe591a21f28>,\n",
       " 'adult': <gensim.models.word2vec.Vocab at 0xe592da9518>,\n",
       " 'mr': <gensim.models.word2vec.Vocab at 0xe591a8c860>,\n",
       " 'alleged': <gensim.models.word2vec.Vocab at 0xe593f5f860>,\n",
       " 'ie': <gensim.models.word2vec.Vocab at 0xe59189c0b8>,\n",
       " 'poll': <gensim.models.word2vec.Vocab at 0xe5942f7710>,\n",
       " 'noted': <gensim.models.word2vec.Vocab at 0xe5942f7748>,\n",
       " 'net': <gensim.models.word2vec.Vocab at 0xe592a1f748>,\n",
       " 'warren': <gensim.models.word2vec.Vocab at 0xe592da94e0>,\n",
       " 'wilson': <gensim.models.word2vec.Vocab at 0xe591a8c6a0>,\n",
       " 'auto': <gensim.models.word2vec.Vocab at 0xe592da9b00>,\n",
       " 'uw': <gensim.models.word2vec.Vocab at 0xe5920641d0>,\n",
       " 'owner': <gensim.models.word2vec.Vocab at 0xe591908710>,\n",
       " 'irresponsible': <gensim.models.word2vec.Vocab at 0xe592064198>,\n",
       " 'af664': <gensim.models.word2vec.Vocab at 0xe5918168d0>,\n",
       " '160493205451': <gensim.models.word2vec.Vocab at 0xe591d44828>,\n",
       " 'gps': <gensim.models.word2vec.Vocab at 0xe591816cc0>,\n",
       " 'niv': <gensim.models.word2vec.Vocab at 0xe591816da0>,\n",
       " 'ag': <gensim.models.word2vec.Vocab at 0xe59218ab70>,\n",
       " 'march': <gensim.models.word2vec.Vocab at 0xe59189c7f0>,\n",
       " 'nor': <gensim.models.word2vec.Vocab at 0xe5928c38d0>,\n",
       " 'biased': <gensim.models.word2vec.Vocab at 0xe591f70cf8>,\n",
       " 'cj195': <gensim.models.word2vec.Vocab at 0xe5919087f0>,\n",
       " 'nr': <gensim.models.word2vec.Vocab at 0xe591f70cc0>,\n",
       " 'christopher': <gensim.models.word2vec.Vocab at 0xe5927aedd8>,\n",
       " 'wolfram': <gensim.models.word2vec.Vocab at 0xe5919088d0>,\n",
       " 'carrier': <gensim.models.word2vec.Vocab at 0xe591816710>,\n",
       " 'govern': <gensim.models.word2vec.Vocab at 0xe591816438>,\n",
       " 'candidate': <gensim.models.word2vec.Vocab at 0xe591f70c18>,\n",
       " 'sciences': <gensim.models.word2vec.Vocab at 0xe594522048>,\n",
       " 'madison': <gensim.models.word2vec.Vocab at 0xe591f70b70>,\n",
       " 'f': <gensim.models.word2vec.Vocab at 0xe5919c8b70>,\n",
       " 'thereof': <gensim.models.word2vec.Vocab at 0xe591f70ba8>,\n",
       " 'hate': <gensim.models.word2vec.Vocab at 0xe59196cda0>,\n",
       " 'c5sqya': <gensim.models.word2vec.Vocab at 0xe591908390>,\n",
       " 'theozone': <gensim.models.word2vec.Vocab at 0xe5919b5908>,\n",
       " 'neighbor': <gensim.models.word2vec.Vocab at 0xe592a9b9e8>,\n",
       " 'colby': <gensim.models.word2vec.Vocab at 0xe5929ce390>,\n",
       " 'since': <gensim.models.word2vec.Vocab at 0xe591eb1940>,\n",
       " 'masada': <gensim.models.word2vec.Vocab at 0xe592192978>,\n",
       " 'mot': <gensim.models.word2vec.Vocab at 0xe59196cba8>,\n",
       " 'occured': <gensim.models.word2vec.Vocab at 0xe5917c0358>,\n",
       " 'human': <gensim.models.word2vec.Vocab at 0xe594489438>,\n",
       " 'extremely': <gensim.models.word2vec.Vocab at 0xe59196cdd8>,\n",
       " 'uses': <gensim.models.word2vec.Vocab at 0xe5928c0080>,\n",
       " 'pihatie': <gensim.models.word2vec.Vocab at 0xe591e05b38>,\n",
       " 'kibology': <gensim.models.word2vec.Vocab at 0xe592bdc358>,\n",
       " 'data': <gensim.models.word2vec.Vocab at 0xe59446d5c0>,\n",
       " 'rich': <gensim.models.word2vec.Vocab at 0xe592d24400>,\n",
       " 'lost': <gensim.models.word2vec.Vocab at 0xe591a8e240>,\n",
       " 'c5jrde': <gensim.models.word2vec.Vocab at 0xe5928f1320>,\n",
       " 'seeks': <gensim.models.word2vec.Vocab at 0xe592166128>,\n",
       " 'straw': <gensim.models.word2vec.Vocab at 0xe591bdf8d0>,\n",
       " '4z5wqc': <gensim.models.word2vec.Vocab at 0xe5917d8c88>,\n",
       " 'noose': <gensim.models.word2vec.Vocab at 0xe591e9f5f8>,\n",
       " 'tossed': <gensim.models.word2vec.Vocab at 0xe591e9f748>,\n",
       " '891': <gensim.models.word2vec.Vocab at 0xe5917d85f8>,\n",
       " 'pharisees': <gensim.models.word2vec.Vocab at 0xe5917d8f28>,\n",
       " 'smokers': <gensim.models.word2vec.Vocab at 0xe5941c0320>,\n",
       " 'switching': <gensim.models.word2vec.Vocab at 0xe5917d8978>,\n",
       " 'huh': <gensim.models.word2vec.Vocab at 0xe591973978>,\n",
       " 'luke': <gensim.models.word2vec.Vocab at 0xe5940f4358>,\n",
       " 'guns': <gensim.models.word2vec.Vocab at 0xe5919ac470>,\n",
       " 'arguments': <gensim.models.word2vec.Vocab at 0xe592c2db00>,\n",
       " '53': <gensim.models.word2vec.Vocab at 0xe591e69f28>,\n",
       " 'guided': <gensim.models.word2vec.Vocab at 0xe591a47668>,\n",
       " 'peter': <gensim.models.word2vec.Vocab at 0xe5919ac080>,\n",
       " 'avoid': <gensim.models.word2vec.Vocab at 0xe5941c0470>,\n",
       " 'owl': <gensim.models.word2vec.Vocab at 0xe591a442b0>,\n",
       " 'statistics': <gensim.models.word2vec.Vocab at 0xe5917e9cf8>,\n",
       " 'relation': <gensim.models.word2vec.Vocab at 0xe594377128>,\n",
       " 'achieved': <gensim.models.word2vec.Vocab at 0xe59183bd30>,\n",
       " 'scientific': <gensim.models.word2vec.Vocab at 0xe5919ac390>,\n",
       " 'selfish': <gensim.models.word2vec.Vocab at 0xe591a2b780>,\n",
       " 'v1': <gensim.models.word2vec.Vocab at 0xe5917d8128>,\n",
       " 'novak': <gensim.models.word2vec.Vocab at 0xe592a94cc0>,\n",
       " 'legend': <gensim.models.word2vec.Vocab at 0xe592a80710>,\n",
       " 'admit': <gensim.models.word2vec.Vocab at 0xe591f41438>,\n",
       " 'banned': <gensim.models.word2vec.Vocab at 0xe594341908>,\n",
       " 'stated': <gensim.models.word2vec.Vocab at 0xe5944506a0>,\n",
       " \"'correct'\": <gensim.models.word2vec.Vocab at 0xe591f5a780>,\n",
       " 'cb': <gensim.models.word2vec.Vocab at 0xe592c8fb70>,\n",
       " 'judgment': <gensim.models.word2vec.Vocab at 0xe59204a6d8>,\n",
       " 'protection': <gensim.models.word2vec.Vocab at 0xe5919ac0f0>,\n",
       " 'predict': <gensim.models.word2vec.Vocab at 0xe592176630>,\n",
       " 'integrating': <gensim.models.word2vec.Vocab at 0xe592b5b320>,\n",
       " 'forget': <gensim.models.word2vec.Vocab at 0xe5917f6908>,\n",
       " 'which': <gensim.models.word2vec.Vocab at 0xe591c21160>,\n",
       " 'rose': <gensim.models.word2vec.Vocab at 0xe5919ace48>,\n",
       " 'word': <gensim.models.word2vec.Vocab at 0xe5917d8898>,\n",
       " 'fallacy': <gensim.models.word2vec.Vocab at 0xe5917f6da0>,\n",
       " 'plot': <gensim.models.word2vec.Vocab at 0xe5919ac898>,\n",
       " 'ghost': <gensim.models.word2vec.Vocab at 0xe5917d84e0>,\n",
       " 'pointless': <gensim.models.word2vec.Vocab at 0xe5918135c0>,\n",
       " 'token': <gensim.models.word2vec.Vocab at 0xe592176668>,\n",
       " 'bang': <gensim.models.word2vec.Vocab at 0xe5919ac860>,\n",
       " 'aside': <gensim.models.word2vec.Vocab at 0xe5917fd630>,\n",
       " 'lodge': <gensim.models.word2vec.Vocab at 0xe5917d8828>,\n",
       " 'newsgate': <gensim.models.word2vec.Vocab at 0xe5917d8f98>,\n",
       " '171256': <gensim.models.word2vec.Vocab at 0xe591e189b0>,\n",
       " 'cco': <gensim.models.word2vec.Vocab at 0xe591846208>,\n",
       " 'gifts': <gensim.models.word2vec.Vocab at 0xe5918136a0>,\n",
       " 'hernes': <gensim.models.word2vec.Vocab at 0xe5918130b8>,\n",
       " 'objection': <gensim.models.word2vec.Vocab at 0xe592cf5780>,\n",
       " 'patience': <gensim.models.word2vec.Vocab at 0xe592cf5c88>,\n",
       " 'sent': <gensim.models.word2vec.Vocab at 0xe5917d87b8>,\n",
       " '0700': <gensim.models.word2vec.Vocab at 0xe591813358>,\n",
       " 'harding': <gensim.models.word2vec.Vocab at 0xe5917d81d0>,\n",
       " 'frater': <gensim.models.word2vec.Vocab at 0xe591e70710>,\n",
       " '99': <gensim.models.word2vec.Vocab at 0xe591deb1d0>,\n",
       " 'shared': <gensim.models.word2vec.Vocab at 0xe591c123c8>,\n",
       " 'edu': <gensim.models.word2vec.Vocab at 0xe591c12f60>,\n",
       " 'keng': <gensim.models.word2vec.Vocab at 0xe591813780>,\n",
       " 'define': <gensim.models.word2vec.Vocab at 0xe591b3b588>,\n",
       " 'c5u5nv': <gensim.models.word2vec.Vocab at 0xe591813710>,\n",
       " 'suffering': <gensim.models.word2vec.Vocab at 0xe5943f8198>,\n",
       " 'sad': <gensim.models.word2vec.Vocab at 0xe591e70400>,\n",
       " 'bskendigc5rcbg': <gensim.models.word2vec.Vocab at 0xe591c12f28>,\n",
       " 'tu': <gensim.models.word2vec.Vocab at 0xe592bb3898>,\n",
       " 'covering': <gensim.models.word2vec.Vocab at 0xe5917d85c0>,\n",
       " 'carry': <gensim.models.word2vec.Vocab at 0xe59192ef98>,\n",
       " 'subscribe': <gensim.models.word2vec.Vocab at 0xe594262b70>,\n",
       " 'therapy': <gensim.models.word2vec.Vocab at 0xe59183f518>,\n",
       " 'inerrant': <gensim.models.word2vec.Vocab at 0xe591c121d0>,\n",
       " 'implications': <gensim.models.word2vec.Vocab at 0xe59183f3c8>,\n",
       " 'major': <gensim.models.word2vec.Vocab at 0xe591f939b0>,\n",
       " 'purse': <gensim.models.word2vec.Vocab at 0xe591e70898>,\n",
       " 'alexandria': <gensim.models.word2vec.Vocab at 0xe591813ac8>,\n",
       " 'water': <gensim.models.word2vec.Vocab at 0xe59192ed68>,\n",
       " 'galaxy': <gensim.models.word2vec.Vocab at 0xe593fd8898>,\n",
       " 'noise': <gensim.models.word2vec.Vocab at 0xe59192eb38>,\n",
       " 'lutheran': <gensim.models.word2vec.Vocab at 0xe591c21eb8>,\n",
       " 'youth': <gensim.models.word2vec.Vocab at 0xe592c3b940>,\n",
       " 'carried': <gensim.models.word2vec.Vocab at 0xe59192e080>,\n",
       " 'sbradley': <gensim.models.word2vec.Vocab at 0xe591a08d30>,\n",
       " 'urban': <gensim.models.word2vec.Vocab at 0xe591a084e0>,\n",
       " 'original': <gensim.models.word2vec.Vocab at 0xe5917c1cc0>,\n",
       " 'jpl': <gensim.models.word2vec.Vocab at 0xe591a08ba8>,\n",
       " 'howland': <gensim.models.word2vec.Vocab at 0xe5918410b8>,\n",
       " 'sunnyvale': <gensim.models.word2vec.Vocab at 0xe59192eb00>,\n",
       " 'nh7': <gensim.models.word2vec.Vocab at 0xe591a08c18>,\n",
       " 'parable': <gensim.models.word2vec.Vocab at 0xe5942a0668>,\n",
       " 'cunyvm': <gensim.models.word2vec.Vocab at 0xe592055be0>,\n",
       " 'c5x7j8': <gensim.models.word2vec.Vocab at 0xe591a71748>,\n",
       " 'postulating': <gensim.models.word2vec.Vocab at 0xe5942a05c0>,\n",
       " 'swastika': <gensim.models.word2vec.Vocab at 0xe5919daeb8>,\n",
       " 'news2me': <gensim.models.word2vec.Vocab at 0xe591a71e10>,\n",
       " 'possession': <gensim.models.word2vec.Vocab at 0xe591b50c50>,\n",
       " 'heresy': <gensim.models.word2vec.Vocab at 0xe591a71a58>,\n",
       " 'abraham': <gensim.models.word2vec.Vocab at 0xe591b057b8>,\n",
       " 'violation': <gensim.models.word2vec.Vocab at 0xe591a718d0>,\n",
       " 'unl': <gensim.models.word2vec.Vocab at 0xe591b50390>,\n",
       " 'revealed': <gensim.models.word2vec.Vocab at 0xe591b059e8>,\n",
       " 'powerful': <gensim.models.word2vec.Vocab at 0xe591e70438>,\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most 10 similar words to the word 'book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('element', 0.9719886183738708),\n",
       " ('powers', 0.9699809551239014),\n",
       " ('church', 0.9677160382270813),\n",
       " ('son', 0.967503011226654),\n",
       " ('attack', 0.9674603939056396),\n",
       " ('parts', 0.9664692878723145),\n",
       " ('self', 0.9659683704376221),\n",
       " ('tradition', 0.9646417498588562),\n",
       " ('current', 0.9640681743621826),\n",
       " ('priesthood', 0.9605560302734375)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings on Computer-related news articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 texts.\n",
      "Training Word2Vec model...\n",
      "Saving Word2Vec model 'windows.misc'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "import data_helpers\n",
    "# Set values for various parameters\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_features=300\n",
    "min_word_count=5\n",
    "context=4\n",
    "\n",
    "TEXT_DATA_DIR='20_newsgroup\\\\comp.os.ms-windows.misc'\n",
    "sentences = []  # list of text articles\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    if fname.isdigit():\n",
    "        fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "        f = open(fpath)\n",
    "        sentences.append(f.read())\n",
    "        f.close()\n",
    "sentences = [s.strip() for s in sentences]\n",
    "x_text = [data_helpers.clean_str(sent) for sent in sentences]\n",
    "x_text = [s.split(\" \") for s in x_text]\n",
    "    \n",
    "print('Found %s texts.' % len(x_text))\n",
    "\n",
    "# Initialize and train the model\n",
    "print(\"Training Word2Vec model...\")\n",
    "x,  vocabulary, vocabulary_inv =data_helpers.load_data(x_text)\n",
    "sentences = [[vocabulary_inv[w] for w in s] for s in x]\n",
    "embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                    size=num_features, min_count = min_word_count, \\\n",
    "                    window = context, sample = downsampling)\n",
    "\n",
    "# If we don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "embedding_model.init_sims(replace=True)\n",
    "\n",
    "model_name='windows.misc'\n",
    "# Saving the model for later use. You can load it later using Word2Vec.load()\n",
    "print('Saving Word2Vec model \\'%s\\'' % model_name)\n",
    "embedding_model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most 10 similar words to the word 'book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adjusted', 0.9946157932281494),\n",
       " ('4mb', 0.9943787455558777),\n",
       " ('harddisk', 0.9934042096138),\n",
       " ('cpu', 0.9921078681945801),\n",
       " ('specifically', 0.9917465448379517),\n",
       " ('reports', 0.9915753602981567),\n",
       " ('necessary', 0.990689218044281),\n",
       " ('cheaper', 0.9904521703720093),\n",
       " ('including', 0.9904208779335022),\n",
       " ('limited', 0.9892256855964661)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Google: \n",
    "tome,books,memoir,paperback_edition,autobiography,memoirs,Book,paperback,novels,hardback\t\t\t\n",
    "- Religion:\n",
    "element,powers,church,son,attack,parts,self,tradition,current,priesthood\n",
    "- Computer:\n",
    "adjusted,4mb,harddisk,cpu,specifically,reports,necessary,cheaper,including,limited\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Classlification using CNN with word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "{'soc.religion.christian': 0, 'talk.religion.misc': 1}\n",
      "Found 1997 texts.\n",
      "Found 33651 unique tokens.\n",
      "[66, 39, 31, 23, 16, 4, 194, 31, 23, 16, 4, 247, 235, 16, 4, 212, 161, 211, 21, 262, 14, 125, 14, 4, 72, 14, 4, 24, 22, 5736, 1188, 21, 5619, 8408, 67, 88, 28, 24, 57, 77, 509, 1750, 55, 69, 51, 296, 219, 467, 630, 58, 14905, 72, 14, 4, 64, 308, 51, 91, 278, 467, 779, 76, 86, 123, 72, 14, 4, 74, 1188, 1590, 65, 748, 120, 24, 126, 14, 4, 9, 85, 5183, 310, 197, 723, 310, 58, 72, 14, 4, 17788, 19679, 3266, 4, 1652, 15132, 75, 9, 85, 5183, 242, 197, 938, 1041, 58, 9662, 72, 14, 4, 3444, 869, 23, 805, 4, 5687, 3444, 75, 89, 10, 44, 1131, 10, 1932, 60, 1454, 1, 135, 678, 60, 10, 230, 6, 167, 71, 45, 1129, 3, 509, 1750, 376, 1129, 3, 1, 915, 300, 98, 116, 5, 6, 4179, 7, 101, 20, 6676, 20, 104, 678, 60, 252, 163, 468, 1, 2531, 6, 167, 509, 1753, 19876, 5, 36, 3364, 8096, 376, 1129, 3, 618, 92, 103, 116, 8, 2860, 641, 3, 3261, 10776, 3, 1932, 135, 104, 30, 1, 8923, 2278, 9, 1, 509, 1753, 3205, 2, 1, 852, 919, 750, 341, 10, 1009, 9, 6625, 11, 27, 5645, 6, 1, 104, 1758, 1742, 143, 3, 13, 186, 4588, 27, 3, 13, 25, 509, 98, 2894, 2, 12738, 84, 1503, 9, 1, 7660, 2, 8, 11464, 78, 2677, 257, 1, 2406, 2184, 2380, 4211, 3622, 62, 2106, 5, 1, 1244, 2184, 2380, 515, 30, 820, 2532, 2, 1, 11464, 27, 204, 106, 18, 1964, 2406, 1244, 2184, 2380, 2184, 2380, 3261, 1371, 1371, 5, 1119, 803, 5389, 27, 30, 1, 2791, 1, 3292, 131, 166, 304, 117, 80, 2871, 345, 73, 6, 37, 352, 252, 300, 15, 1123, 1245, 115, 1279, 367, 164, 34, 484, 13, 823, 5, 484, 8, 6183, 367, 1, 2532, 2, 1, 720, 7, 70, 13, 1, 2791, 131, 34, 484, 13, 369, 1, 2532, 2, 1, 720, 7, 14375, 419, 18, 27, 8, 519, 919, 5, 159, 1255, 5149, 3261, 252, 8, 506, 30, 1, 9637, 2, 1608, 5619, 1063, 11751, 5736, 1188, 21, 10314, 4249]\n",
      "Shape of data tensor: (1997, 1000)\n",
      "Shape of label tensor: (1997, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "import sys\n",
    "\n",
    "\n",
    "TEXT_DATA_DIR =  '20_newsgroup.reg/'\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                if sys.version_info < (3,):\n",
    "                    f = open(fpath)\n",
    "                else:\n",
    "                    f = open(fpath, encoding='latin-1')\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "print(labels_index)\n",
    "print('Found %s texts.' % len(texts))\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Train on 1598 samples, validate on 399 samples\n",
      "Epoch 1/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.4706 - acc: 0.7247 - val_loss: 0.2399 - val_acc: 0.9724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.0855 - acc: 0.9725 - val_loss: 0.0455 - val_acc: 0.9850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.0211 - acc: 0.9925 - val_loss: 0.0442 - val_acc: 0.9799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0499 - val_acc: 0.9799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "1598/1598 [==============================] - 4s - loss: 8.7014e-04 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('movement', 0.6429674625396729),\n",
       " ('clh', 0.6362773776054382),\n",
       " ('scribes', 0.6289868354797363),\n",
       " ('sinned', 0.6255764365196228),\n",
       " ('congregation', 0.6216408014297485),\n",
       " ('rutgers', 0.6205594539642334),\n",
       " ('performance', 0.6179541945457458),\n",
       " ('services', 0.6179179549217224),\n",
       " ('zoerasterism', 0.6166352033615112),\n",
       " ('listens', 0.6152451634407043)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,weights=None)\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "nb_epoch=5, batch_size=128)\n",
    "\n",
    "# save embeddings\n",
    "embedding_matrix=embedding_layer.get_weights()\n",
    "gensim_first_line = \"{} {}\".format(len(word_index), EMBEDDING_DIM)\n",
    "outfile='rand.word2vec'\n",
    "with open(outfile, 'w', encoding=\"utf-8\") as fout:\n",
    "    fout.write(gensim_first_line + \"\\n\")\n",
    "    for word, i in word_index.items():\n",
    "        fout.write(word)\n",
    "        for j in range(0,EMBEDDING_DIM):\n",
    "            fout.write(' %s' % embedding_matrix[0][i][j])\n",
    "        fout.write(\"\\n\")\n",
    "#load embeddings            \n",
    "from gensim.models import Word2Vec\n",
    "embedding_model = Word2Vec.load_word2vec_format(outfile, binary=False)\n",
    "# most 10 similar words to the word 'book'\n",
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Static Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pre-trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model_name='GoogleNews-vectors-negative300.bin'\n",
    "embedding_model = Word2Vec.load_word2vec_format(model_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Train on 1598 samples, validate on 399 samples\n",
      "Epoch 1/5\n",
      "1598/1598 [==============================] - 3s - loss: 0.5660 - acc: 0.7378 - val_loss: 0.1358 - val_acc: 0.9724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "1598/1598 [==============================] - 2s - loss: 0.1175 - acc: 0.9712 - val_loss: 0.0888 - val_acc: 0.9724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "1598/1598 [==============================] - 2s - loss: 0.0667 - acc: 0.9731 - val_loss: 0.0480 - val_acc: 0.9749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "1598/1598 [==============================] - 2s - loss: 0.0516 - acc: 0.9725 - val_loss: 0.0398 - val_acc: 0.9749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "1598/1598 [==============================] - 2s - loss: 0.0447 - acc: 0.9775 - val_loss: 1.2806 - val_acc: 0.4987\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammad\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py:580: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.syn0norm = (self.syn0 / sqrt((self.syn0 ** 2).sum(-1))[..., newaxis]).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('books', 0.868958055973053),\n",
       " ('autobiography', 0.8370756506919861),\n",
       " ('paperback', 0.8235605359077454),\n",
       " ('novels', 0.8170720934867859),\n",
       " ('biography', 0.8077912926673889),\n",
       " ('novel', 0.8060959577560425),\n",
       " ('nonfiction', 0.7967409491539001),\n",
       " ('hardcover', 0.7966055870056152),\n",
       " ('novella', 0.7910082936286926),\n",
       " ('manuscript', 0.7879250645637512)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare embeddings\n",
    "embedding_matrix = np.zeros((len(word_index)+1 , EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in embedding_model.vocab:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_model.wv[word]\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "nb_epoch=5, batch_size=128)\n",
    "\n",
    "# save embeddings\n",
    "embedding_matrix=embedding_layer.get_weights()\n",
    "gensim_first_line = \"{} {}\".format(len(word_index), EMBEDDING_DIM)\n",
    "outfile='static.word2vec'\n",
    "with open(outfile, 'w', encoding=\"utf-8\") as fout:\n",
    "    fout.write(gensim_first_line + \"\\n\")\n",
    "    for word, i in word_index.items():\n",
    "        fout.write(word)\n",
    "        for j in range(0,EMBEDDING_DIM):\n",
    "            fout.write(' %s' % embedding_matrix[0][i][j])\n",
    "        fout.write(\"\\n\")\n",
    "#load embeddings            \n",
    "from gensim.models import Word2Vec\n",
    "embedding_model = Word2Vec.load_word2vec_format(outfile, binary=False)\n",
    "# most 10 similar words to the word 'book'\n",
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Dynamic Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Train on 1598 samples, validate on 399 samples\n",
      "Epoch 1/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.5351 - acc: 0.7516 - val_loss: 0.0852 - val_acc: 0.9724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.0679 - acc: 0.9712 - val_loss: 0.0451 - val_acc: 0.9699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.0334 - acc: 0.9850 - val_loss: 0.0394 - val_acc: 0.9749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.1368 - acc: 0.9399 - val_loss: 0.0461 - val_acc: 0.9799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "1598/1598 [==============================] - 4s - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0451 - val_acc: 0.9825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammad\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py:580: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.syn0norm = (self.syn0 / sqrt((self.syn0 ** 2).sum(-1))[..., newaxis]).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('books', 0.868929386138916),\n",
       " ('autobiography', 0.8340421319007874),\n",
       " ('paperback', 0.82172030210495),\n",
       " ('novels', 0.8105382323265076),\n",
       " ('novel', 0.806250274181366),\n",
       " ('biography', 0.804276168346405),\n",
       " ('hardcover', 0.7959304451942444),\n",
       " ('nonfiction', 0.7913392186164856),\n",
       " ('novella', 0.7887855768203735),\n",
       " ('manuscript', 0.7881438136100769)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare embeddings\n",
    "embedding_matrix = np.zeros((len(word_index)+1 , EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in embedding_model.vocab:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_model.wv[word]\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "nb_epoch=5, batch_size=128)\n",
    "\n",
    "# save embeddings\n",
    "embedding_matrix=embedding_layer.get_weights()\n",
    "gensim_first_line = \"{} {}\".format(len(word_index), EMBEDDING_DIM)\n",
    "outfile='daynamic.word2vec'\n",
    "with open(outfile, 'w', encoding=\"utf-8\") as fout:\n",
    "    fout.write(gensim_first_line + \"\\n\")\n",
    "    for word, i in word_index.items():\n",
    "        fout.write(word)\n",
    "        for j in range(0,EMBEDDING_DIM):\n",
    "            fout.write(' %s' % embedding_matrix[0][i][j])\n",
    "        fout.write(\"\\n\")\n",
    "#load embeddings            \n",
    "from gensim.models import Word2Vec\n",
    "embedding_model = Word2Vec.load_word2vec_format(outfile, binary=False)\n",
    "# most 10 similar words to the word 'book'\n",
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
