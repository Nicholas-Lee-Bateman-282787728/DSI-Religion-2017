{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "2016-10-27 15:02:21.653510\n",
      "finished loading packages after 1.99105405807 seconds\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul 19 16:14:43 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun  2 15:23:11 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "import time\n",
    "start=time.time()\n",
    "import sys, os\n",
    "\n",
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017')\n",
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing as mp\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "sys.path.append('./prototype_python/')\n",
    "#import lingual as la\n",
    "import lingualPrinting as la\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "#sys.stdout = open(\"output.txt\", \"a\")\n",
    "print(str(datetime.now()))\n",
    "print('finished loading packages after '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#\n",
    "import getNewDocs as gnd\n",
    "\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "59\n",
      "20\n",
      "[['IntegralYoga', 'test11'], ['SeaShepherds', 'test1'], ['IntegralYoga', 'test1'], ['Bahai', 'test7'], ['IntegralYoga', 'test8'], ['Bahai', 'test3'], ['IntegralYoga', 'test4'], ['IntegralYoga', 'test10'], ['SeaShepherds', 'test2'], ['IntegralYoga', 'test0'], ['Bahai', 'test6'], ['Bahai', 'test2'], ['IntegralYoga', 'test7'], ['Bahai', 'test9'], ['SeaShepherds', 'test3'], ['IntegralYoga', 'test3'], ['Bahai', 'test5'], ['Bahai', 'test1'], ['IntegralYoga', 'test6'], ['Bahai', 'test8'], ['IntegralYoga', 'test2'], ['Bahai', 'test4'], ['SeaShepherds', 'test0'], ['Bahai', 'test0'], ['IntegralYoga', 'test9'], ['IntegralYoga', 'test5']]\n",
      "%%%%%\n",
      "length of subgroupList is 26\n"
     ]
    }
   ],
   "source": [
    "fileDF=gnd.newDocsToDF('./data_dsicap/', bin=5) ################################### WHERE THE NEW FILES ARE\n",
    "\n",
    "fileList=fileDF.values.tolist()\n",
    "\n",
    "fileList=[[fileList[i][0],fileList[i][1],fileList[i][2]] for i in range(len(fileList))]\n",
    "\n",
    "\n",
    "#Get set of subgroups\n",
    "subgroupList=[ list(y) for y in set((x[0],x[2]) for x in fileList) ]\n",
    "print(subgroupList)\n",
    "print('%%%%%\\nlength of subgroupList is ' + str(len(subgroupList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawPath = './data_dsicap/' ###############change this eventually\n",
    "runDirectory='./modelOutput/'\n",
    "#groupList=['DorothyDay','JohnPiper','MehrBaba','NaumanKhan','PastorAnderson',\n",
    "#   'Rabbinic','Shepherd','Unitarian','WBC']\n",
    "groupList=['DorothyDay','NaumanKhan','Rabbinic','NawDawg','SeaShepherds','IntegralYoga','Bahai']\n",
    "#cocoWindow=int(sys.argv[1])\n",
    "#cvWindow=int(sys.argv[2])\n",
    "#startCount=int(sys.argv[3])\n",
    "#netAngle=int(sys.argv[4])\n",
    "cocoWindow=3\n",
    "cvWindow=3\n",
    "startCount=0\n",
    "netAngle=30\n",
    "groupSize=10\n",
    "#testSplit=.3\n",
    "targetWordCount=10\n",
    "svdInt=50\n",
    "simCount=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "#Create paramList\n",
    "paramList=[[x,fileList,targetWordCount,cocoWindow,svdInt,cvWindow,simCount,startCount,netAngle] for x in subgroupList]\n",
    "print(len(paramList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run calculation \n",
    "#masterOutput=[textAnalysis(x) for x in paramList]  ### INSTEAD OF THIS, WE MAKE THE OBJECT\n",
    "paramPick = paramList[0] ### instead of looping through, we just pick one\n",
    "#print(paramPick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IntegralYoga', 'test11']\n"
     ]
    }
   ],
   "source": [
    "#def textAnalysis(paramPick):\n",
    "startTime=time.time()\n",
    "groupId=paramPick[0]\n",
    "fileList=paramPick[1]\n",
    "targetWordCount=paramPick[2]\n",
    "cocoWindow=paramPick[3]\n",
    "svdInt=paramPick[4]\n",
    "cvWindow=paramPick[5]\n",
    "simCount=paramPick[6]\n",
    "startCount=paramPick[7]\n",
    "netAngle=paramPick[8]    \n",
    "\n",
    "print(groupId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['./data_dsicap/IntegralYoga/raw/YV05.txt', './data_dsicap/IntegralYoga/raw/YV48.txt', './data_dsicap/IntegralYoga/raw/YV54.txt', './data_dsicap/IntegralYoga/raw/YV58.txt']\n"
     ]
    }
   ],
   "source": [
    "#Get list of subfiles\n",
    "subFileList=[x[1] for x in fileList if x[0]==groupId[0] and x[2]==groupId[1]]\n",
    "print(len(subFileList))\n",
    "print(subFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#Create lingual object\n",
    "loTest=la.lingualObject(subFileList)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LOOK AT LIST OF TOKENS FOR FILE\n",
    "#print(subFileList[0])\n",
    "#loTest.tokens[subFileList[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING COCOOOOOO!!!\n",
      "%%%%\n",
      "cocoDict, length 847\n",
      "---the first ten keys:\n",
      "[u'all', u'forget', u'illustr', u'forbidden', u'both', u'focus', u'sleep', 'go', u'follow', u'chair']\n",
      "---the first entry:\n",
      "all\n",
      "{u'codecerror': 5, u'just': 1, u'bad': 1, u'faith': 1, u'queen': 1, u'littl': 3, u'should': 1, 'to': 2, 'do': 2, u'good': 1, u'know': 2, u'they': 3, u'not': 2, u'anyth': 1, u'drop': 1, u'separ': 1, u'benefit': 1, u'necessari': 1, u'right': 1, u'habit': 1, u'creation': 1, u'are': 5, u'our': 6, u'happen': 1, u'even': 1, u'awar': 1, u'for': 1, u'god': 2, u'selfanalysi': 1, u'use': 2, u'bless': 1, u'experi': 1, 'be': 3, 'we': 2, u'who': 2, u'themselv': 1, 'of': 4, u'aspir': 1, u'ultim': 1, u'reason': 1, u'solv': 1, u'teach': 1, 'by': 4, 'on': 1, u'great': 1, u'chant': 1, 'am': 1, u'thing': 5, u'yourself': 1, u'wit': 2, u'theoret': 1, u'your': 1, u'boat': 1, u'differ': 1, u'from': 1, u'silent': 1, u'expound': 1, u'that': 4, u'peopl': 1, u'imag': 1, u'understand': 1, u'with': 1, u'those': 3, u'word': 1, u'these': 3, 'up': 1, u'will': 1, u'can': 2, u'abov': 1, u'learn': 1, u'fun': 1, u'problem': 1, u'and': 7, u'have': 1, 'is': 5, u'mind': 2, u'it': 1, 'at': 2, u'want': 1, 'in': 5, u'attract': 1, u'grown': 1, u'selfish': 1, u'yoga': 1, u'harmoni': 1, u'you': 5, u'toddler': 1, u'play': 1, u'after': 1, u'philosophi': 2, 'a': 1, u'suprem': 1, 'i': 4, u'thought': 1, 'so': 1, u'time': 1, u'the': 8}\n"
     ]
    }
   ],
   "source": [
    "#Get coco\n",
    "loTest.getCoco(cocoWindow)\n",
    "\n",
    "#        self.cocoWindow=k\n",
    "#        self.cocoDict={}\n",
    "#        self.TF={}\n",
    "#        self.docTF={}\n",
    "\n",
    "print('%%%%\\ncocoDict, length ' + str(len(loTest.cocoDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cocoDict.keys()[:10])\n",
    "print('---the first entry:')\n",
    "key1 = loTest.cocoDict.keys()[0]\n",
    "print(key1)\n",
    "print(loTest.cocoDict[key1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.svdK: 50\n",
      "%%%%\n",
      "DSM, length 847\n",
      "---the first ten keys:\n",
      "[u'all', u'undisturb', u'forget', u'whatev', u'illustr', u'forbidden', u'hatr', u'focus', u'sleep', 'go']\n",
      "---the first entry:\n",
      "{0: 0.94440020364127053, 1: 0.02451027698215363, 2: 0.39783247423658841, 3: 0.20458261536913455, 4: 0.6347208045316387, 5: 0.85940238502148558, 6: 0.46246435451587192, 7: -0.019630832092543307, 8: 0.33513715696431529, 9: 0.36016998713618575, 10: 0.087910168864851687, 11: -0.030679615831168794, 12: 0.0060195893664723365, 13: 0.061079730413757478, 14: 0.3135469497747308, 15: 0.32919953715442191, 16: 0.36161577909176373, 17: -0.0045442152439387146, 18: 0.26000693400987768, 19: 0.16648635699811234, 20: 0.41494262088855283, 21: -0.26170637583242867, 22: 0.31208233491873943, 23: -0.57240923288547707, 24: -0.10237673240509952, 25: -0.15152325646238565, 26: 0.18793245249168139, 27: 0.45810271717869527, 28: -0.0095813446173004142, 29: -0.24946312539160265, 30: -0.16627246760569611, 31: 0.054980502679703398, 32: 0.31740448975160845, 33: 0.075962610425620219, 34: 0.1248770496217033, 35: -0.63681342730505941, 36: -0.15844613153169179, 37: -0.10168738763421016, 38: -0.019709568510564785, 39: -0.30548322524051341, 40: -0.1371964832499146, 41: -0.18791171340171234, 42: 0.24189376689276135, 43: 0.029421941071878337, 44: 0.15864887537596953, 45: 0.34578396686974977, 46: 0.2531528199685037, 47: -0.21003265883011568, 48: -0.31082227929824124, 49: 0.55066548774830937}\n"
     ]
    }
   ],
   "source": [
    "#Get DSM\n",
    "loTest.getDSM(svdInt)\n",
    "print('loTest.svdK: ' + str(loTest.svdK))\n",
    "\n",
    "print('%%%%\\nDSM, length ' + str(len(loTest.DSM)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.DSM.keys()[:10])\n",
    "print('---the first entry:')\n",
    "print(loTest.DSM[loTest.DSM.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'good', 'then', 'even', 'when', 'so', 'here', 'other', 'also', 'different']\n",
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n",
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./prototype_python/lingualPrinting.py:474: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  targetDF.sort(['count'],inplace=True,ascending=False)\n"
     ]
    }
   ],
   "source": [
    "#Set keywords\n",
    "loTest.setKeywords('adjAdv',targetWordCount,startCount)\n",
    "print(loTest.keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n",
    "stemkeywords=[stemmer.stem(word) for word in loTest.keywords]\n",
    "print(stemkeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%\n",
      "not\n",
      "{u'all': 2, u'distanc': 1, u'they': 2, u'just': 2, u'queen': 1, u'sage': 1, u'becaus': 3, u'violent': 1, u'go': 1, u'chair': 1, u'still': 1, u'find': 1, u'help': 1, u'fit': 1, u'readabl': 1, u'should': 2, 'to': 11, u'book': 1, u'factor': 1, u'sens': 2, u'delici': 1, u'has': 1, u'might': 1, u'real': 1, 'do': 3, u'good': 1, u'everi': 1, u'read': 2, u'dessert': 1, u'somebodi': 1, u'know': 1, u'codecerror': 11, u'veri': 1, u'one': 1, u'school': 1, u'anyth': 5, u'smell': 1, u'drop': 1, u'these': 1, u'bad': 2, u'contain': 1, u'plank': 1, u'enjoy': 1, u'the': 23, u'right': 2, u'mental': 1, u'natur': 1, u'mind': 3, u'realli': 1, u'see': 1, u'are': 16, u'seeabl': 1, u'cold': 1, u'infinit': 1, u'serv': 1, u'what': 1, u'said': 1, u'for': 3, u'bhagavad': 1, u'someth': 1, u'abl': 2, u'uniform': 1, u'doer': 1, u'experi': 1, 'be': 6, 'we': 3, u'who': 1, u'led': 1, u'isol': 1, u'here': 1, u'bodi': 3, u'ask': 1, u'eye': 1, u'come': 1, 'by': 2, u'faith': 2, 'of': 2, u'could': 1, u'vidyalayam': 1, u'thing': 1, u'outsid': 1, u'share': 1, 'or': 4, u'gita': 1, u'feel': 1, u'guidelin': 2, u'yourself': 1, u'open': 1, u'your': 5, u'use': 2, u'from': 2, u'log': 1, u'there': 5, u'happi': 2, u'start': 1, u'live': 1, u'way': 2, u'spring': 1, u'scope': 1, u'was': 1, u'that': 7, u'forc': 1, u'peopl': 2, u'but': 8, u'drown': 1, u'hear': 2, u'compani': 1, u'with': 2, u'eat': 2, 'he': 2, 'me': 1, u'made': 1, u'word': 1, u'look': 1, u'perceiv': 1, u'this': 3, u'work': 1, 'us': 1, u'can': 13, u'problem': 1, u'everyon': 1, u'expect': 2, u'and': 8, u'give': 2, u'certain': 1, 'is': 12, 'am': 2, 'it': 6, 'an': 1, u'say': 1, u'his': 1, u'exist': 2, 'at': 1, u'have': 4, 'in': 5, u'disappear': 1, 'if': 3, u'result': 1, u'selfish': 1, u'sit': 1, u'anoth': 1, u'when': 1, u'same': 4, u'intellect': 1, u'alway': 1, u'other': 1, u'rememb': 1, u'you': 19, u'simpl': 1, u'shall': 1, u'may': 1, u'object': 3, u'moment': 1, u'fruit': 1, u'whether': 1, u'water': 1, u'extern': 1, u'peac': 1, u'man': 1, 'a': 5, u'essenti': 1, 'i': 3, u'bind': 1, u'proud': 1, u'doe': 3, u'thought': 1, u'part': 1, u'adam': 1, u'allow': 1, u'everyth': 4}\n",
      "%%%%%\n",
      "good\n",
      "{u'and': 2, u'all': 1, u'have': 2, u'creat': 1, u'they': 1, u'feel': 1, u'natur': 1, 'is': 5, u'hard': 1, u'disciplin': 2, u'not': 1, 'as': 1, u'are': 4, u'want': 1, 'in': 1, u'proper': 1, u'home': 1, u'find': 1, u'might': 1, u'what': 3, u'nonsmok': 1, u'televis': 1, u'get': 1, u'yogi': 1, u'been': 1, 'to': 3, u'program': 1, u'call': 1, u'build': 1, u'environ': 1, u'you': 4, 'if': 1, u'codecerror': 3, u'noth': 1, 'do': 1, u'good': 2, u'that': 2, u'some': 1, u'after': 1, u'pave': 1, u'befor': 1, u'know': 1, u'satsang': 2, u'veri': 1, u'yoga': 1, u'compani': 9, u'grow': 1, u'those': 1, u'must': 1, 'a': 1, 'on': 2, u'join': 3, u'this': 1, 'of': 1, 'up': 1, u'charact': 3, u'will': 1, u'thing': 2, u'place': 1, u'the': 11, u'manner': 2}\n",
      "%%%%%\n",
      "then\n",
      "{u'and': 7, u'codecerror': 1, u'guidelin': 1, 'is': 4, u'becaus': 1, u'yourself': 2, u'alway': 1, 'as': 1, u'are': 4, u'tabl': 2, u'ship': 1, u'yes': 1, u'even': 1, u'decid': 1, u'ash': 1, u'depend': 1, u'guest': 1, u'suprem': 1, 'to': 1, u'relax': 1, u'sometim': 1, u'been': 1, u'plank': 3, u'their': 1, u'wood': 3, u'call': 1, u'sens': 1, u'you': 4, u'immedi': 1, u'until': 1, 'be': 1, u'finish': 1, u'see': 1, u'though': 2, u'may': 1, u'tree': 1, u'time': 1, u'piec': 1, 'it': 2, u'how': 1, u'chair': 1, u'made': 1, u'they': 1, u'delici': 1, u'now': 1, u'burnt': 1, u'the': 9, u'log': 2, 'a': 1, u'experi': 1, u'practic': 1, u'never': 1, u'conscious': 1, u'whether': 1, 'of': 3, u'into': 1, u'sit': 1, u'alon': 1, u'remain': 2, 'us': 1, u'benefit': 1, u'were': 1, u'chang': 1, u'principl': 1, 'my': 1, 'or': 1, u'for': 1}\n",
      "%%%%%\n",
      "even\n",
      "{u'blind': 1, u'vedanta': 1, u'all': 1, u'help': 1, 'be': 1, u'give': 2, u'natur': 1, 'it': 2, u'down': 1, u'perpetu': 1, u'dazzl': 1, u'want': 1, 'in': 5, u'go': 1, u'our': 1, u'ship': 1, u'faith': 1, u'your': 3, 'if': 2, u'awar': 1, u'use': 1, u'spiritu': 1, u'daytoday': 1, u'with': 1, u'sometim': 1, u'littl': 1, 'to': 2, u'again': 1, u'seeker': 1, u'lot': 1, u'you': 3, u'codecerror': 1, u'more': 1, u'then': 1, u'them': 1, u'which': 1, u'though': 3, u'may': 1, u'shallow': 2, u'here': 1, u'hand': 1, u'water': 2, u'fruit': 1, u'they': 1, u'compani': 1, u'nobodi': 1, u'effort': 1, u'longer': 1, 'a': 3, u'also': 1, u'room': 1, u'anyth': 1, u'this': 1, 'of': 1, u'bother': 1, 'no': 1, 'up': 1, 'or': 1, u'will': 3, u'without': 1, u'grain': 1, u'smoke': 1, u'push': 1, u'field': 1, u'the': 3, u'think': 1, u'daili': 1, 'at': 1}\n",
      "%%%%%\n",
      "when\n",
      "{u'and': 2, u'old': 1, u'help': 1, u'activ': 1, 'is': 4, u'emot': 1, u'one': 2, u'say': 1, u'are': 3, u'slip': 1, 'in': 1, 'go': 1, u'forget': 1, u'your': 2, u'stage': 1, u'fill': 1, u'selfish': 1, u'onli': 2, u'ear': 1, u'built': 1, u'daytoday': 1, u'someth': 2, u'there': 1, u'seat': 1, u'young': 1, u'eat': 1, 'to': 2, u'other': 2, u'analyz': 1, u'you': 10, u'deafen': 1, u'codecerror': 2, 'be': 1, u'that': 2, u'forc': 1, u'absorb': 1, u'never': 1, u'reach': 1, u'use': 1, u'but': 1, u'bodi': 1, u'know': 1, u'they': 1, u'not': 1, u'affect': 1, u'now': 1, u'with': 1, u'day': 1, u'like': 1, 'on': 1, u'went': 1, u'avoid': 1, 'i': 2, 'of': 1, u'thing': 1, u'each': 1, u'the': 2, u'think': 1, u'expect': 1}\n",
      "%%%%%\n",
      "so\n",
      "{u'our': 2, u'and': 1, u'all': 1, u'they': 3, 'be': 1, u'feel': 1, u'guidelin': 1, 'is': 2, 'in': 2, u'mind': 1, u'becaus': 1, u'capac': 1, u'see': 1, u'are': 5, u'want': 1, u'someth': 1, u'seen': 1, u'your': 1, 'as': 2, 'if': 1, u'caus': 1, u'differ': 1, u'said': 1, u'end': 1, 'i': 1, u'also': 1, u'section': 1, u'there': 2, u'bowl': 1, u'thank': 1, u'long': 1, u'should': 1, 'to': 6, u'other': 1, u'health': 1, u'too': 1, u'natur': 2, u'sens': 1, u'you': 5, u'man': 1, u'gave': 1, 'do': 3, 'we': 1, u'his': 1, u'return': 1, u'truth': 1, u'that': 4, u'mess': 1, u'peopl': 1, u'who': 1, u'watch': 1, u'hand': 1, u'vomit': 1, u'codecerror': 2, u'share': 1, u'shun': 1, u'compani': 1, u'with': 1, u'chang': 1, u'physic': 1, u'must': 1, 'a': 2, u'experienc': 1, u'this': 1, 'of': 1, 'up': 1, u'separ': 1, u'collect': 1, u'achiev': 1, u'can': 1, u'smoke': 1, u'mani': 1, u'the': 5, u'purpos': 1, 'or': 1, u'say': 1}\n",
      "%%%%%\n",
      "here\n",
      "{u'and': 3, u'old': 1, u'guidelin': 2, u'over': 1, 'it': 1, u'born': 2, 'as': 2, u'are': 2, u'have': 1, 'in': 3, u'our': 1, u'your': 1, u'communiti': 1, 'if': 2, u'even': 1, u'yogavill': 2, u'harmoni': 1, 'no': 2, u'ruin': 1, u'littl': 1, u'should': 1, 'to': 1, u'live': 1, u'you': 5, u'main': 1, 'is': 2, u'more': 1, 'be': 4, u'vibrat': 1, u'that': 1, u'shallow': 1, u'but': 1, u'codecerror': 3, u'refin': 1, u'not': 1, u'come': 2, 'by': 1, 'a': 1, 'i': 1, 'of': 2, u'benefit': 1, u'follow': 3, u'can': 1, u'wild': 1, u'mani': 1, u'the': 6, u'purpos': 1, u'similar': 1}\n",
      "%%%%%\n",
      "other\n",
      "{u'and': 2, u'right': 1, u'help': 2, u'ten': 1, u'speci': 1, 'is': 1, u'share': 1, u'becaus': 1, u'one': 2, u'offer': 1, u'kill': 1, u'are': 3, u'slip': 1, u'find': 1, 'if': 1, u'said': 1, u'group': 1, u'appear': 1, u'for': 1, u'also': 1, u'with': 1, u'there': 2, u'when': 2, u'same': 1, u'should': 1, 'to': 4, u'live': 1, u'chamber': 1, 'it': 2, 'so': 1, u'you': 2, u'codecerror': 1, 'be': 1, 'we': 1, u'that': 1, u'may': 1, u'peopl': 1, u'innermost': 1, u'hand': 3, u'somebodi': 1, u'togeth': 2, u'they': 3, u'not': 1, u'from': 2, 'on': 4, u'come': 1, u'peac': 1, u'gregorian': 1, 'a': 2, u'pull': 1, u'protect': 1, u'lead': 1, u'chant': 1, 'no': 1, u'well': 1, 'as': 1, u'know': 1, u'thing': 1, u'environ': 1, u'can': 2, u'each': 4, 'at': 1, u'the': 10, u'view': 2, u'silver': 1, u'ourselv': 1}\n",
      "%%%%%\n",
      "also\n",
      "{u'and': 2, u'natur': 1, 'is': 1, u'accord': 1, u'annihil': 1, u'are': 4, u'children': 1, u'even': 1, u'spiritu': 2, u'realm': 1, u'for': 1, 'to': 1, u'highest': 1, u'there': 1, u'same': 1, u'field': 1, u'book': 1, u'you': 2, u'experi': 2, 'we': 2, u'truth': 1, u'that': 2, u'but': 1, u'bodi': 1, u'part': 1, u'know': 1, u'ash': 1, u'ident': 1, 'of': 1, 'so': 1, u'can': 3, u'though': 1, u'the': 9, u'other': 1, u'adult': 1}\n",
      "%%%%%\n",
      "differ\n",
      "{u'and': 3, u'all': 1, u'identifi': 1, u'feel': 1, 'is': 3, u'mind': 1, u'are': 3, u'have': 2, 'in': 2, u'total': 1, u'your': 3, u'given': 1, u'from': 2, u'etc': 1, u'there': 2, u'capac': 2, 'to': 2, u'seeker': 1, u'suppos': 1, u'suit': 1, u'got': 2, u'you': 2, u'therefor': 1, u'method': 1, u'real': 1, u'that': 3, u'peopl': 3, u'men': 2, u'differ': 2, u'but': 1, u'bodi': 2, u'reason': 1, u'understand': 1, u'know': 1, u'codecerror': 1, u'such': 1, 'by': 1, u'present': 1, 'a': 1, u'these': 1, 'of': 6, u'facet': 1, 'i': 1, 'so': 1, u'she': 1, u'abov': 1, u'grasp': 1, u'opinion': 1, u'the': 5, u'view': 1}\n",
      "{u'respond': 2, u'faith': 1, u'ultim': 1, 'is': 1, 'to': 2, u'codecerror': 1, u'the': 3, u'essenc': 1}\n"
     ]
    }
   ],
   "source": [
    "for key in loTest.keywords: ### get context vectors for keywords...\n",
    "    print('%%%%%\\n' + key)\n",
    "    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n",
    "#print(loTest.cocoDict['spiritual'])\n",
    "print(loTest.cocoDict['spirit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for key in stemkeywords: ### get context vectors for keywords...\n",
    "#    print('%%%%%\\n' + key)\n",
    "#    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in loTest.keywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "#    if 'spirtual' in filetokens:\n",
    "#        print(\"UAL!\")\n",
    "#    if 'spirit' in filetokens:\n",
    "#        print(\"SPIRIT!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## STEM keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in stemkeywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.cvWindow: 3\n",
      "%%%%\n",
      "cvDict, length 4\n",
      "---the first ten keys:\n",
      "['./data_dsicap/IntegralYoga/raw/YV58.txt', './data_dsicap/IntegralYoga/raw/YV48.txt', './data_dsicap/IntegralYoga/raw/YV54.txt', './data_dsicap/IntegralYoga/raw/YV05.txt']\n",
      "---the keywords each file:\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt: [u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "%%%%%%%\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 5 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 10 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "---------length of thisfile[then][7]: 50\n",
      "---------length of thisfile[then][8]: 50\n",
      "---------length of thisfile[then][9]: 50\n",
      "---------length of thisfile[then][10]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 9 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "---------length of thisfile[differ][6]: 50\n",
      "---------length of thisfile[differ][7]: 50\n",
      "---------length of thisfile[differ][8]: 50\n",
      "---------length of thisfile[differ][9]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 3 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 5 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "---------length of thisfile[also][3]: 50\n",
      "---------length of thisfile[also][4]: 50\n",
      "---------length of thisfile[also][5]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 4 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 6 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 24 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n",
      "---------length of thisfile[not][21]: 50\n",
      "---------length of thisfile[not][22]: 50\n",
      "---------length of thisfile[not][23]: 50\n",
      "---------length of thisfile[not][24]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 1 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 5 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 4 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 2 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 11 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt (5 keys):\n",
      "---keys: [u'not', u'even', u'when', u'other', 'so']\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 8 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 1 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 3 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt (9 keys):\n",
      "---keys: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 8 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "---------length of thisfile[even][6]: 50\n",
      "---------length of thisfile[even][7]: 50\n",
      "---------length of thisfile[even][8]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 6 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "------thisfile[good]:\n",
      "-------length: \"good\" appears 18 times in this file.\n",
      "---------length of thisfile[good][1]: 50\n",
      "---------length of thisfile[good][2]: 50\n",
      "---------length of thisfile[good][3]: 50\n",
      "---------length of thisfile[good][4]: 50\n",
      "---------length of thisfile[good][5]: 50\n",
      "---------length of thisfile[good][6]: 50\n",
      "---------length of thisfile[good][7]: 50\n",
      "---------length of thisfile[good][8]: 50\n",
      "---------length of thisfile[good][9]: 50\n",
      "---------length of thisfile[good][10]: 50\n",
      "---------length of thisfile[good][11]: 50\n",
      "---------length of thisfile[good][12]: 50\n",
      "---------length of thisfile[good][13]: 50\n",
      "---------length of thisfile[good][14]: 50\n",
      "---------length of thisfile[good][15]: 50\n",
      "---------length of thisfile[good][16]: 50\n",
      "---------length of thisfile[good][17]: 50\n",
      "---------length of thisfile[good][18]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 6 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "---------length of thisfile[when][5]: 50\n",
      "---------length of thisfile[when][6]: 50\n",
      "------thisfile[here]:\n",
      "-------length: \"here\" appears 13 times in this file.\n",
      "---------length of thisfile[here][1]: 50\n",
      "---------length of thisfile[here][2]: 50\n",
      "---------length of thisfile[here][3]: 50\n",
      "---------length of thisfile[here][4]: 50\n",
      "---------length of thisfile[here][5]: 50\n",
      "---------length of thisfile[here][6]: 50\n",
      "---------length of thisfile[here][7]: 50\n",
      "---------length of thisfile[here][8]: 50\n",
      "---------length of thisfile[here][9]: 50\n",
      "---------length of thisfile[here][10]: 50\n",
      "---------length of thisfile[here][11]: 50\n",
      "---------length of thisfile[here][12]: 50\n",
      "---------length of thisfile[here][13]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 8 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "---------length of thisfile[other][5]: 50\n",
      "---------length of thisfile[other][6]: 50\n",
      "---------length of thisfile[other][7]: 50\n",
      "---------length of thisfile[other][8]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 8 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "---------length of thisfile[so][7]: 50\n",
      "---------length of thisfile[so][8]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 20 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n"
     ]
    }
   ],
   "source": [
    "#######################            \n",
    "###Semantic analysis###\n",
    "#######################\n",
    "\n",
    "#Get context vectors\n",
    "loTest.getContextVectors(cvWindow)\n",
    "print('loTest.cvWindow: ' + str(loTest.cvWindow))\n",
    "\n",
    "#        self.cvWindow=k\n",
    "#        self.cvDict={}\n",
    "\n",
    "print('%%%%\\ncvDict, length ' + str(len(loTest.cvDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cvDict.keys()[:10])\n",
    "print('---the keywords each file:')\n",
    "for key in loTest.cvDict.keys():\n",
    "    print(key + ': ' + str(loTest.cvDict[key].keys()))\n",
    "print('%%%%%%%')\n",
    "#file1 = loTest.cvDict.keys()[0] #'./data_dsicap/IntegralYoga/raw/YV38.txt'\n",
    "    \n",
    "for file1 in loTest.cvDict.keys():    \n",
    "    first = loTest.cvDict[file1]\n",
    "    #print('---the first entry (length ' + str(len(first[first.keys()[0]])) + '):')\n",
    "    print('%%%%%\\n' + file1 + ' (' + str(len(first.keys())) + ' keys):')\n",
    "    print('---keys: ' + str(first.keys()))\n",
    "    for wordkey in first.keys():\n",
    "        print('------thisfile[' + wordkey + ']:')\n",
    "        tftk = first[wordkey]\n",
    "        print('-------length: \"' + wordkey + '\" appears ' + str(len(tftk.keys())) + ' times in this file.')\n",
    "        for numkey in tftk.keys():\n",
    "            print('---------length of thisfile[' + wordkey +'][' + str(numkey) + ']: ' + str(len(tftk[numkey])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "[u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "[u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "10\n",
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n",
      "[0.72404735956380151, 0.70700627327625354, 0.71615225785121706, 0.69572043045266363, 0.75862725558225175, 0.72200533701172254, 0.75878819429898337, 0.67993472478851136, 0.77246014024129339, 0.76795665602778718]\n"
     ]
    }
   ],
   "source": [
    "#Get average semantic density\n",
    "#avgSD=np.mean([x[1] for x in loTest.getSD(simCount)])\n",
    "#print(avgSD)\n",
    "\n",
    "SD = [x[1] for x in loTest.getSD(simCount)]\n",
    "print(len(SD))\n",
    "print(loTest.keywords)\n",
    "print(SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "###POS Tagging and Judgement Analysis###\n",
    "########################################\n",
    "judgementAvg=list(np.mean(np.array([[x[1],x[2]] for x in loTest.getJudgements()]),axis=0))\n",
    "\n",
    "########################\n",
    "###Sentiment Analysis###\n",
    "########################\n",
    "\n",
    "sentimentList=loTest.sentimentLookup()\n",
    "\n",
    "############################\n",
    "###Network Quantification###\n",
    "############################\n",
    "loTest.setNetwork(netAngle)\n",
    "\n",
    "avgEVC=loTest.evc()\n",
    "\n",
    "endTime=time.time()\n",
    "timeRun=endTime-startTime\n",
    "print('finished running'+'_'.join(groupId)+' in '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#Append outputs to masterOutput\n",
    "return(['_'.join(groupId)]+[len(subFileList),timeRun]+sentimentList+judgementAvg+[avgSD]+[avgEVC])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tandh–bm\n"
     ]
    }
   ],
   "source": [
    "#thisToken = u'tandh\\u012bm'\n",
    "thisToken = u'tandh\\u2013bm'\n",
    "print(thisToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tandhbm\n"
     ]
    }
   ],
   "source": [
    "print(thisToken.replace(u'\\u2013',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdash = '\\u2013'\n",
    "thisToken = u'tandh\\u2013bm'\n",
    "useless = ['\\u2013', '\\u201d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdash not in useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisToken not in useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
