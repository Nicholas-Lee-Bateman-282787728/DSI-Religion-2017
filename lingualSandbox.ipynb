{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "2016-10-26 07:19:04.898574\n",
      "finished loading packages after 0.00240778923035 seconds\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul 19 16:14:43 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun  2 15:23:11 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "import time\n",
    "start=time.time()\n",
    "import sys, os\n",
    "\n",
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017')\n",
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing as mp\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "sys.path.append('./prototype_python/')\n",
    "#import lingual as la\n",
    "import lingualPrinting as la\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "#sys.stdout = open(\"output.txt\", \"a\")\n",
    "print(str(datetime.now()))\n",
    "print('finished loading packages after '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#\n",
    "import getNewDocs as gnd\n",
    "\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "59\n",
      "20\n",
      "[['IntegralYoga', 'test11'], ['SeaShepherds', 'test1'], ['IntegralYoga', 'test1'], ['Bahai', 'test7'], ['IntegralYoga', 'test8'], ['Bahai', 'test3'], ['IntegralYoga', 'test4'], ['IntegralYoga', 'test10'], ['SeaShepherds', 'test2'], ['IntegralYoga', 'test0'], ['Bahai', 'test6'], ['Bahai', 'test2'], ['IntegralYoga', 'test7'], ['Bahai', 'test9'], ['SeaShepherds', 'test3'], ['IntegralYoga', 'test3'], ['Bahai', 'test5'], ['Bahai', 'test1'], ['IntegralYoga', 'test6'], ['Bahai', 'test8'], ['IntegralYoga', 'test2'], ['Bahai', 'test4'], ['SeaShepherds', 'test0'], ['Bahai', 'test0'], ['IntegralYoga', 'test9'], ['IntegralYoga', 'test5']]\n",
      "%%%%%\n",
      "length of subgroupList 26\n"
     ]
    }
   ],
   "source": [
    "fileDF=gnd.newDocsToDF('./data_dsicap/', bin=5) ################################### WHERE THE NEW FILES ARE\n",
    "\n",
    "fileList=fileDF.values.tolist()\n",
    "\n",
    "fileList=[[fileList[i][0],fileList[i][1],fileList[i][2]] for i in range(len(fileList))]\n",
    "\n",
    "\n",
    "#Get set of subgroups\n",
    "subgroupList=[ list(y) for y in set((x[0],x[2]) for x in fileList) ]\n",
    "print(subgroupList)\n",
    "print('%%%%%\\nlength of subgroupList is ' + str(len(subgroupList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawPath = './data_dsicap/' ###############change this eventually\n",
    "runDirectory='./modelOutput/'\n",
    "#groupList=['DorothyDay','JohnPiper','MehrBaba','NaumanKhan','PastorAnderson',\n",
    "#   'Rabbinic','Shepherd','Unitarian','WBC']\n",
    "groupList=['DorothyDay','NaumanKhan','Rabbinic','NawDawg','SeaShepherds','IntegralYoga','Bahai']\n",
    "#cocoWindow=int(sys.argv[1])\n",
    "#cvWindow=int(sys.argv[2])\n",
    "#startCount=int(sys.argv[3])\n",
    "#netAngle=int(sys.argv[4])\n",
    "cocoWindow=3\n",
    "cvWindow=3\n",
    "startCount=0\n",
    "netAngle=30\n",
    "groupSize=10\n",
    "#testSplit=.3\n",
    "targetWordCount=10\n",
    "svdInt=50\n",
    "simCount=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "#Create paramList\n",
    "paramList=[[x,fileList,targetWordCount,cocoWindow,svdInt,cvWindow,simCount,startCount,netAngle] for x in subgroupList]\n",
    "print(len(paramList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run calculation \n",
    "#masterOutput=[textAnalysis(x) for x in paramList]  ### INSTEAD OF THIS, WE MAKE THE OBJECT\n",
    "paramPick = paramList[0] ### instead of looping through, we just pick one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IntegralYoga', 'test11']\n"
     ]
    }
   ],
   "source": [
    "#def textAnalysis(paramPick):\n",
    "startTime=time.time()\n",
    "groupId=paramPick[0]\n",
    "fileList=paramPick[1]\n",
    "targetWordCount=paramPick[2]\n",
    "cocoWindow=paramPick[3]\n",
    "svdInt=paramPick[4]\n",
    "cvWindow=paramPick[5]\n",
    "simCount=paramPick[6]\n",
    "startCount=paramPick[7]\n",
    "netAngle=paramPick[8]    \n",
    "\n",
    "print(groupId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['./data_dsicap/IntegralYoga/raw/YV12.txt', './data_dsicap/IntegralYoga/raw/YV37.txt', './data_dsicap/IntegralYoga/raw/YV38.txt', './data_dsicap/IntegralYoga/raw/YV43.txt']\n"
     ]
    }
   ],
   "source": [
    "#Get list of subfiles\n",
    "subFileList=[x[1] for x in fileList if x[0]==groupId[0] and x[2]==groupId[1]]\n",
    "print(len(subFileList))\n",
    "print(subFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create lingual object\n",
    "loTest=la.lingualObject(subFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%\n",
      "cocoDict, length 757\n",
      "---the first ten keys:\n",
      "[u'all', u'forget', u'founder', u'rod', u'focus', u'mile', u'customari', u'abil', u'go', u'follow']\n",
      "---the first entry:\n",
      "all\n",
      "{u'all': 2, u'codecerror': 1, u'over': 2, u'move': 1, u'cheap': 1, u'becaus': 1, u'bring': 2, u'access': 1, u'send': 1, u'should': 1, 'to': 5, u'gave': 1, u'then': 1, u'them': 1, u'rememb': 1, u'seren': 1, u'wave': 1, u'util': 1, u'they': 1, u'not': 2, u'world': 1, u'necessari': 1, u'yantra': 1, u'bone': 1, u'ailment': 1, u'individu': 1, u'resist': 1, u'are': 2, u'will': 1, u'god': 1, u'away': 2, u'poison': 2, u'current': 1, u'religion': 1, u'various': 1, u'approach': 1, 'we': 2, u'immun': 1, u'bodi': 2, u'let': 1, u'path': 1, 'by': 1, u'faith': 1, 'of': 7, u'mani': 1, 'or': 1, u'into': 1, u'walk': 1, u'limb': 1, u'hatha': 1, u'your': 1, u'from': 3, u'give': 1, u'breath': 1, u'type': 1, u'that': 4, u'peopl': 1, u'tool': 1, u'but': 1, u'understand': 1, u'togeth': 1, u'compani': 1, u'with': 1, 'he': 1, u'kind': 1, u'these': 3, 'us': 2, u'air': 1, u'aim': 1, u'ail': 1, u'can': 1, u'learn': 1, u'aid': 1, u'cosmos': 1, u'purpos': 1, u'and': 8, u'transcend': 1, u'do': 1, 'is': 5, u'mind': 1, 'it': 2, 'at': 1, u'have': 1, 'in': 1, u'need': 1, u'ray': 1, u'strength': 1, u'yoga': 4, u'make': 1, u'toxin': 2, u'which': 1, u'you': 2, u'medit': 2, u'pain': 1, u'symbol': 1, u'whi': 1, u'stay': 1, u'eight': 1, u'veri': 1, u'robust': 1, u'peac': 1, 'a': 1, u'practic': 5, 'so': 1, u'clean': 1, u'time': 2, u'the': 20, u'spend': 1}\n"
     ]
    }
   ],
   "source": [
    "#Get coco\n",
    "loTest.getCoco(cocoWindow)\n",
    "\n",
    "#        self.cocoWindow=k\n",
    "#        self.cocoDict={}\n",
    "#        self.TF={}\n",
    "#        self.docTF={}\n",
    "\n",
    "print('%%%%\\ncocoDict, length ' + str(len(loTest.cocoDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cocoDict.keys()[:10])\n",
    "print('---the first entry:')\n",
    "key1 = loTest.cocoDict.keys()[0]\n",
    "print(key1)\n",
    "print(loTest.cocoDict[key1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.svdK: 50\n",
      "%%%%\n",
      "DSM, length 757\n",
      "---the first ten keys:\n",
      "[u'all', u'forget', u'chain', u'whatev', u'rod', u'focus', u'mile', u'customari', u'abil', u'dish']\n",
      "---the first entry:\n",
      "{0: 0.30793645998372027, 1: 0.008859848532153573, 2: 0.64271035027153911, 3: 0.27572242070120689, 4: -0.10392338752453978, 5: -0.65942479408698718, 6: -0.54621335389052705, 7: 0.34495970606751841, 8: 0.038953878245611251, 9: 0.051637993586715648, 10: -0.36793979481043321, 11: -0.067323461692883918, 12: -0.1611049561432151, 13: -0.25946558742264525, 14: -0.22027729579887756, 15: 0.17270209446663354, 16: -0.21745620416317324, 17: 0.029231190701872096, 18: 0.088393261247169314, 19: 0.06033199561124622, 20: -0.20426670446051856, 21: 0.14257302588998219, 22: -0.16459811637347516, 23: 0.069100837219998906, 24: 0.28878823382838914, 25: -0.055969808999803042, 26: 0.029894371176366948, 27: -0.05117613795496067, 28: -0.12168761027433433, 29: -0.15319293580792506, 30: 0.041193984031315259, 31: 0.030242246308157097, 32: 0.0018430872808987647, 33: -0.093426036204208127, 34: -0.17538933711316596, 35: -0.096225302629982148, 36: -0.08369829577170175, 37: 0.084420928558226083, 38: 0.034567173858380741, 39: 0.064846279563761586, 40: 0.10195765551659745, 41: 0.32435645404975622, 42: 0.16374212068071853, 43: -0.21119206586469316, 44: 0.09603711124386248, 45: 0.028461539302310282, 46: -0.10114621441033113, 47: -0.068374217797760747, 48: 0.19615216077574923, 49: 0.02230344008606196}\n"
     ]
    }
   ],
   "source": [
    "#Get DSM\n",
    "loTest.getDSM(svdInt)\n",
    "print('loTest.svdK: ' + str(loTest.svdK))\n",
    "\n",
    "print('%%%%\\nDSM, length ' + str(len(loTest.DSM)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.DSM.keys()[:10])\n",
    "print('---the first entry:')\n",
    "print(loTest.DSM[loTest.DSM.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'not', 'then', 'physical', 'so', 'other', 'good', 'when', 'little', 'healthy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./prototype_python/lingualPrinting.py:468: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  targetDF.sort(['count'],inplace=True,ascending=False)\n"
     ]
    }
   ],
   "source": [
    "#Set keywords\n",
    "loTest.setKeywords('adjAdv',targetWordCount,startCount)\n",
    "print(loTest.keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.cvWindow: 3\n",
      "%%%%\n",
      "cvDict, length 4\n",
      "---the first ten keys:\n",
      "['./data_dsicap/IntegralYoga/raw/YV38.txt', './data_dsicap/IntegralYoga/raw/YV43.txt', './data_dsicap/IntegralYoga/raw/YV37.txt', './data_dsicap/IntegralYoga/raw/YV12.txt']\n",
      "---the keywords each file:\n",
      "./data_dsicap/IntegralYoga/raw/YV38.txt: [u'then', u'good', u'when', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV43.txt: [u'not', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV37.txt: [u'then', u'good', u'when', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV12.txt: [u'not', u'then', u'other', u'when']\n",
      "%%%%%%%\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV38.txt (6 keys):\n",
      "---keys: [u'then', u'good', u'when', u'other', 'so', u'not']\n",
      "------thisfile[then]:\n",
      "---------length: 5\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "------thisfile[good]:\n",
      "---------length: 3\n",
      "---------length of thisfile[good][1]: 50\n",
      "---------length of thisfile[good][2]: 50\n",
      "---------length of thisfile[good][3]: 50\n",
      "------thisfile[when]:\n",
      "---------length: 4\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "------thisfile[other]:\n",
      "---------length: 4\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "------thisfile[so]:\n",
      "---------length: 6\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "------thisfile[not]:\n",
      "---------length: 6\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV43.txt (4 keys):\n",
      "---keys: [u'not', u'when', u'other', 'so']\n",
      "------thisfile[not]:\n",
      "---------length: 3\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "------thisfile[when]:\n",
      "---------length: 2\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "------thisfile[other]:\n",
      "---------length: 1\n",
      "---------length of thisfile[other][1]: 50\n",
      "------thisfile[so]:\n",
      "---------length: 3\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV37.txt (6 keys):\n",
      "---keys: [u'then', u'good', u'when', u'other', 'so', u'not']\n",
      "------thisfile[then]:\n",
      "---------length: 9\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "---------length of thisfile[then][7]: 50\n",
      "---------length of thisfile[then][8]: 50\n",
      "---------length of thisfile[then][9]: 50\n",
      "------thisfile[good]:\n",
      "---------length: 7\n",
      "---------length of thisfile[good][1]: 50\n",
      "---------length of thisfile[good][2]: 50\n",
      "---------length of thisfile[good][3]: 50\n",
      "---------length of thisfile[good][4]: 50\n",
      "---------length of thisfile[good][5]: 50\n",
      "---------length of thisfile[good][6]: 50\n",
      "---------length of thisfile[good][7]: 50\n",
      "------thisfile[when]:\n",
      "---------length: 1\n",
      "---------length of thisfile[when][1]: 50\n",
      "------thisfile[other]:\n",
      "---------length: 6\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "---------length of thisfile[other][5]: 50\n",
      "---------length of thisfile[other][6]: 50\n",
      "------thisfile[so]:\n",
      "---------length: 9\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "---------length of thisfile[so][7]: 50\n",
      "---------length of thisfile[so][8]: 50\n",
      "---------length of thisfile[so][9]: 50\n",
      "------thisfile[not]:\n",
      "---------length: 6\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV12.txt (4 keys):\n",
      "---keys: [u'not', u'then', u'other', u'when']\n",
      "------thisfile[not]:\n",
      "---------length: 1\n",
      "---------length of thisfile[not][1]: 50\n",
      "------thisfile[then]:\n",
      "---------length: 1\n",
      "---------length of thisfile[then][1]: 50\n",
      "------thisfile[other]:\n",
      "---------length: 1\n",
      "---------length of thisfile[other][1]: 50\n",
      "------thisfile[when]:\n",
      "---------length: 2\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n"
     ]
    }
   ],
   "source": [
    "#######################            \n",
    "###Semantic analysis###\n",
    "#######################\n",
    "\n",
    "#Get context vectors\n",
    "loTest.getContextVectors(cvWindow)\n",
    "print('loTest.cvWindow: ' + str(loTest.cvWindow))\n",
    "\n",
    "#        self.cvWindow=k\n",
    "#        self.cvDict={}\n",
    "\n",
    "print('%%%%\\ncvDict, length ' + str(len(loTest.cvDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cvDict.keys()[:10])\n",
    "print('---the keywords each file:')\n",
    "for key in loTest.cvDict.keys():\n",
    "    print(key + ': ' + str(loTest.cvDict[key].keys()))\n",
    "print('%%%%%%%')\n",
    "#file1 = loTest.cvDict.keys()[0] #'./data_dsicap/IntegralYoga/raw/YV38.txt'\n",
    "    \n",
    "for file1 in loTest.cvDict.keys():    \n",
    "    first = loTest.cvDict[file1]\n",
    "    #print('---the first entry (length ' + str(len(first[first.keys()[0]])) + '):')\n",
    "    print('%%%%%\\n' + file1 + ' (' + str(len(first.keys())) + ' keys):')\n",
    "    print('---keys: ' + str(first.keys()))\n",
    "    for wordkey in first.keys():\n",
    "        print('------thisfile[' + wordkey + ']:')\n",
    "        tftk = first[wordkey]\n",
    "        print('---------length: ' + str(len(tftk.keys())))\n",
    "        for numkey in tftk.keys():\n",
    "            print('---------length of thisfile[' + wordkey +'][' + str(numkey) + ']: ' + str(len(tftk[numkey])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get average semantic density\n",
    "avgSD=np.mean([x[1] for x in loTest.getSD(simCount)])\n",
    "\n",
    "########################################\n",
    "###POS Tagging and Judgement Analysis###\n",
    "########################################\n",
    "judgementAvg=list(np.mean(np.array([[x[1],x[2]] for x in loTest.getJudgements()]),axis=0))\n",
    "\n",
    "########################\n",
    "###Sentiment Analysis###\n",
    "########################\n",
    "\n",
    "sentimentList=loTest.sentimentLookup()\n",
    "\n",
    "############################\n",
    "###Network Quantification###\n",
    "############################\n",
    "loTest.setNetwork(netAngle)\n",
    "\n",
    "avgEVC=loTest.evc()\n",
    "\n",
    "endTime=time.time()\n",
    "timeRun=endTime-startTime\n",
    "print('finished running'+'_'.join(groupId)+' in '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#Append outputs to masterOutput\n",
    "return(['_'.join(groupId)]+[len(subFileList),timeRun]+sentimentList+judgementAvg+[avgSD]+[avgEVC])   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
