{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('maxent_treebank_pos_tagger')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n",
    "\n",
    "wikiPath = './wiki-i15-30k300-test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHERE I GOT STUFF\n",
    "\n",
    "#### the custom function\n",
    "http://slendermeans.org/ml4h-ch4.html\n",
    "\n",
    "#### the documentation for CountVectorizer\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sklearn_tdm_df(docs, **kwargs):\n",
    "    '''\n",
    "    Create a term-document matrix (TDM) in the form of a pandas DataFrame\n",
    "    Uses sklearn's CountVectorizer function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs: a sequence of documents (files, filenames, or the content) to be\n",
    "        included in the TDM. See the `input` argument to CountVectorizer.\n",
    "    **kwargs: keyword arguments for CountVectorizer options.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tdm_df: A pandas DataFrame with the term-document matrix. Columns are terms,\n",
    "        rows are documents.\n",
    "    '''\n",
    "    # Initialize the vectorizer and get term counts in each document.\n",
    "    vectorizer = CountVectorizer(**kwargs)\n",
    "    word_counts = vectorizer.fit_transform(docs)\n",
    "\n",
    "    # .vocabulary_ is a Dict whose keys are the terms in the documents,\n",
    "    # and whose entries are the columns in the matrix returned by fit_transform()\n",
    "    vocab = vectorizer.vocabulary_\n",
    "\n",
    "    # Make a dictionary of Series for each term; convert to DataFrame\n",
    "    count_dict = {w: pd.Series(word_counts.getcol(vocab[w]).data) for w in vocab}\n",
    "    tdm_df = pd.DataFrame(count_dict).fillna(0)\n",
    "    #return tdm_df\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the function on e-mail messages. The token_pattern is set so that terms are only\n",
    "# words with two or more letters (no numbers or punctuation)\n",
    "\n",
    "# message_tdm = sklearn_tdm_df(train_df['message'],\n",
    "#                             stop_words = 'english',\n",
    "#                             charset_error = 'ignore',\n",
    "#                             token_pattern = '[a-zA-Z]{2,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-Weird_Al-_Yankovic.txt', '.DS_Store', '2004_Indian_Ocean_earthquake.txt', '2005_Atlantic_hurricane_season.txt', 'Abkhazia.txt']\n"
     ]
    }
   ],
   "source": [
    "wikiFiles = os.listdir('./'+wikiPath)\n",
    "print(wikiFiles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the non-tokenized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VEC = CountVectorizer(input='filename')\n",
    "#os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF/wiki-i15-30k300-test')\n",
    "#tdm = VEC.fit_transform(wikiFiles)\n",
    "#tdm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE REAL THING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokeNstem(files):\n",
    "    import re\n",
    "    import string\n",
    "    import time\n",
    "    #\n",
    "    print('%%%%%%\\nRUNNING tokeNstem\\n%%%%%%')\n",
    "    punctuation = set(string.punctuation)\n",
    "    start=time.time()\n",
    "    tokens = {}\n",
    "    count = 0\n",
    "    totalFiles = len(files)\n",
    "    #\n",
    "    for fileName in files:\n",
    "        # increment count for updates\n",
    "        count += 1\n",
    "        if (count % 200 == 0):\n",
    "            print('$$$$ FINISHED ' + str(count) + ' of ' + str(totalFiles) + ' docs in ' + str(time.time()-start) + ' seconds')\n",
    "        #Extract raw text and update for encoding issues            \n",
    "        rawData=unicode(open(fileName).read(), \"utf-8\", errors=\"ignore\")\n",
    "        textList=nltk.word_tokenize(rawData)\n",
    "        tokenList=[]\n",
    "        for token in textList:\n",
    "            try:\n",
    "                tokenList.append(str(token))\n",
    "            except:\n",
    "                tokenList.append('**CODEC_ERROR**')\n",
    "        \n",
    "        #Convert all text to lower case\n",
    "        textList=[word.lower() for word in tokenList]\n",
    "\n",
    "        #Remove punctuation\n",
    "        punctuation = set(string.punctuation)\n",
    "        textList=[word for word in textList if word not in punctuation]\n",
    "        textList=[\"\".join(c for c in word if c not in punctuation) for word in textList ]\n",
    "\n",
    "        #convert digits into NUM\n",
    "        textList=[re.sub(\"\\d+\", \"NUM\", word) for word in textList]  \n",
    "\n",
    "        #Stem words\n",
    "        textList=[stemmer.stem(word) for word in textList]\n",
    "\n",
    "        #Remove blanks\n",
    "        textList=[word for word in textList if word!= ' ']\n",
    "            \n",
    "        #Extract tokens\n",
    "        tokens[fileName]=textList\n",
    "    #\n",
    "    end=time.time()\n",
    "    print('*** finished with ' + str(len(tokens.keys())) + ' documents in ' + str(end-start) + ' seconds')\n",
    "    #\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$ FINISHED 200 of 836 docs in 2.34880590439 seconds\n",
      "$$$$ FINISHED 400 of 836 docs in 4.67841696739 seconds\n",
      "$$$$ FINISHED 600 of 836 docs in 6.8709859848 seconds\n",
      "$$$$ FINISHED 800 of 836 docs in 9.11950707436 seconds\n",
      "*** finished with 836 documents in 9.83084511757 seconds\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF/wiki-i15-30k300-test')\n",
    "testTokens = tokeNstem(wikiFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testTokens['Bulgaria.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### got this below from\n",
    "http://stackoverflow.com/questions/35867484/pass-tokens-to-countvectorizer/38986703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VEC = CountVectorizer(input='filename')\n",
    "\n",
    "VEC = CountVectorizer(\n",
    "      # so we can pass it strings\n",
    "      input='content',\n",
    "      # turn off preprocessing of strings to avoid corrupting our keys\n",
    "      lowercase=False,\n",
    "      preprocessor=lambda x: x,\n",
    "      # use our token dictionary\n",
    "      tokenizer=lambda key: testTokens[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tdm = VEC.fit_transform(wikiFiles)\n",
    "tdm = VEC.fit_transform(testTokens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836, 18148)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " u'ioann',\n",
       " u'starokonstantinov',\n",
       " u'fawk',\n",
       " u'\\x00\\x00\\x00\\x00\\x00\\x00\\x01',\n",
       " u'canalnum',\n",
       " u'mps',\n",
       " u'foun',\n",
       " u'yellow',\n",
       " u'interchang',\n",
       " u'four',\n",
       " u'fortythird',\n",
       " u'realmnum',\n",
       " u'thirst',\n",
       " u'seifer',\n",
       " u'francesca',\n",
       " u'melodrama',\n",
       " u'cyprus',\n",
       " u'repetit',\n",
       " u'skillnum',\n",
       " u'lenca',\n",
       " u'nonitalian',\n",
       " u'accret',\n",
       " u'sunlik',\n",
       " u'lorn',\n",
       " u'discnum',\n",
       " u'crossbar',\n",
       " u'lord',\n",
       " u'incnum',\n",
       " u'kwashiorkor',\n",
       " u'olentangi',\n",
       " u'digit',\n",
       " u'kemet',\n",
       " u'saskatchewan',\n",
       " u'trojan',\n",
       " u'figh',\n",
       " u'bratislava',\n",
       " u'gravitinum',\n",
       " u'lumin',\n",
       " u'delv',\n",
       " u'fur',\n",
       " u'ironi',\n",
       " u'elvi',\n",
       " u'disturb',\n",
       " u'thannum',\n",
       " u'prize',\n",
       " u'fevernum',\n",
       " u'wooden',\n",
       " u'carthag',\n",
       " u'predecessornum',\n",
       " u'wednesday',\n",
       " u'elementari',\n",
       " u'solid',\n",
       " u'penguinnum',\n",
       " u'sakartvelo',\n",
       " u'ninetyfoot',\n",
       " u'wwwmillenniumaznummcaccounthtm',\n",
       " u'hussit',\n",
       " u'brantford',\n",
       " u'religiouslymotiv',\n",
       " u'charter',\n",
       " u'mission',\n",
       " u'sturm',\n",
       " u'thrace',\n",
       " u'popularis',\n",
       " u'dramasom',\n",
       " u'miller',\n",
       " u'bacon',\n",
       " u'shorthaul',\n",
       " u'histor',\n",
       " u'second',\n",
       " u'summer',\n",
       " u'politicaleconomi',\n",
       " u'opponnum',\n",
       " u'nascer',\n",
       " u'divingpetrel',\n",
       " u'tempernum',\n",
       " u'inaccur',\n",
       " u'tumen',\n",
       " u'dialogu',\n",
       " u'captain',\n",
       " u'argentinath',\n",
       " u'histon',\n",
       " u'thunder',\n",
       " u'unlisten',\n",
       " u'schism',\n",
       " u'decre',\n",
       " u'mom',\n",
       " u'gujarati',\n",
       " u'fossil',\n",
       " u'notari',\n",
       " u'therapi',\n",
       " u'buddhismnum',\n",
       " u'celticnum',\n",
       " u'specialist',\n",
       " u'intellectu',\n",
       " u'hero',\n",
       " u'moksha',\n",
       " u'herm',\n",
       " u'sitehttp',\n",
       " u'encyclopediacom',\n",
       " u'financinum',\n",
       " u'grecoroman',\n",
       " u'backtoback',\n",
       " u'here',\n",
       " u'herd',\n",
       " u'lgbt',\n",
       " u'china',\n",
       " u'bromin',\n",
       " u'cult',\n",
       " u'dori',\n",
       " u'christophorus',\n",
       " u'mysticsutin',\n",
       " u'deterior',\n",
       " u'wtro',\n",
       " u'militari',\n",
       " 'k',\n",
       " u'cindi',\n",
       " u'deregul',\n",
       " u'songwrit',\n",
       " u'togethnum',\n",
       " u'windnum',\n",
       " u'mieszko',\n",
       " u'neurologist',\n",
       " u'wwwachtungpanzercomtnumhtm',\n",
       " u'climber',\n",
       " u'gottlob',\n",
       " u'controversi',\n",
       " u'golden',\n",
       " u'ponum',\n",
       " u'causnum',\n",
       " u'unio',\n",
       " 'hw',\n",
       " u'uknum',\n",
       " u'ground',\n",
       " u'wikimedia',\n",
       " u'dma',\n",
       " u'unif',\n",
       " u'brought',\n",
       " u'zweit',\n",
       " u'remnant',\n",
       " u'topographi',\n",
       " u'sterl',\n",
       " u'nightmarish',\n",
       " u'sexualnum',\n",
       " u'francnum',\n",
       " u'unit',\n",
       " u'agassi',\n",
       " u'symphoni',\n",
       " u'dna',\n",
       " u'spoke',\n",
       " u'joseon',\n",
       " u'overshadow',\n",
       " u'hydraulicpress',\n",
       " u'geoellipsoid',\n",
       " u'prospector',\n",
       " u'moth',\n",
       " u'music',\n",
       " u'telegraph',\n",
       " u'passport',\n",
       " u'lumbini',\n",
       " u'strike',\n",
       " u'unliknum',\n",
       " u'licinius',\n",
       " u'consumerlevel',\n",
       " u'until',\n",
       " u'benedikt',\n",
       " u'nebul',\n",
       " u'playboy',\n",
       " u'middlnum',\n",
       " u'firepow',\n",
       " u'georgian',\n",
       " u'notif',\n",
       " u'notic',\n",
       " u'holo',\n",
       " u'glass',\n",
       " u'wwwine',\n",
       " u'holi',\n",
       " u'outskirt',\n",
       " u'cofoundnum',\n",
       " u'biblia',\n",
       " u'hole',\n",
       " u'biblic',\n",
       " u'hurd',\n",
       " u'accid',\n",
       " u'latinnum',\n",
       " u'cubanum',\n",
       " u'blade',\n",
       " u'ret',\n",
       " u'embodinum',\n",
       " u'conceptu',\n",
       " u'possessnum',\n",
       " u'maximilian',\n",
       " u'promotnum',\n",
       " u'burnett',\n",
       " u'numrashid',\n",
       " u'rudyard',\n",
       " u'skynum',\n",
       " u'unofficinum',\n",
       " u'modelnum',\n",
       " u'dramatistgreenblatt',\n",
       " u'wang',\n",
       " u'lenum',\n",
       " u'hyatt',\n",
       " u'unjust',\n",
       " u'household',\n",
       " u'centuri',\n",
       " u'infus',\n",
       " u'nipigon',\n",
       " u'expansnum',\n",
       " u'tribesmen',\n",
       " u'malign',\n",
       " u'ienum',\n",
       " u'faultlin',\n",
       " u'galile',\n",
       " u'componnum',\n",
       " u'syllablnum',\n",
       " u'platenum',\n",
       " u'syphilisi',\n",
       " u'admirnum',\n",
       " u'houstonnum',\n",
       " u'hon',\n",
       " u'travel',\n",
       " u'newnum',\n",
       " u'hournum',\n",
       " u'financnum',\n",
       " u'how',\n",
       " u'hot',\n",
       " u'hos',\n",
       " u'hop',\n",
       " u'marinnum',\n",
       " u'place',\n",
       " u'perspect',\n",
       " u'searchnum',\n",
       " u'raleigh',\n",
       " u'overpopul',\n",
       " u'barbra',\n",
       " u'muscovyglass',\n",
       " u'insubr',\n",
       " u'coffeeshop',\n",
       " u'outfight',\n",
       " u'pimpl',\n",
       " u'diagram',\n",
       " u'sede',\n",
       " u'wrong',\n",
       " u'selfidentificationwvu',\n",
       " u'genderequit',\n",
       " u'endang',\n",
       " u'keynum',\n",
       " u'sankt',\n",
       " u'purchasnum',\n",
       " u'reshap',\n",
       " u'wiktionari',\n",
       " u'sioux',\n",
       " u'vicin',\n",
       " u'statesxxl',\n",
       " u'kingdoma',\n",
       " u'warfar',\n",
       " u'revolt',\n",
       " u'revolv',\n",
       " u'imposs',\n",
       " u'tulip',\n",
       " u'almaghrib',\n",
       " u'dispar',\n",
       " u'inreuterscomarticleworldnewsidinindianum',\n",
       " u'menlo',\n",
       " u'mesozo',\n",
       " u'selfgovern',\n",
       " u'armyss',\n",
       " u'santo',\n",
       " u'wing',\n",
       " u'backdrop',\n",
       " u'wine',\n",
       " u'francojapanes',\n",
       " u'midatlantnum',\n",
       " u'rivalnum',\n",
       " u'antivir',\n",
       " u'predomin',\n",
       " u'transect',\n",
       " u'secondlargest',\n",
       " 'is',\n",
       " u'shorten',\n",
       " u'feign',\n",
       " u'cpc',\n",
       " u'surrend',\n",
       " u'foodstuff',\n",
       " u'nelsonnum',\n",
       " u'ectotherm',\n",
       " u'appar',\n",
       " u'dispatch',\n",
       " u'classicnum',\n",
       " u'heliumnum',\n",
       " u'vari',\n",
       " u'amleth',\n",
       " u'merseysid',\n",
       " u'fir',\n",
       " u'shoshon',\n",
       " u'iwerddon',\n",
       " u'fiv',\n",
       " u'fit',\n",
       " u'benign',\n",
       " u'gridiron',\n",
       " u'intelligentsia',\n",
       " u'anarchocapitalist',\n",
       " u'narrowest',\n",
       " u'fia',\n",
       " u'mwcomdictionarytruth',\n",
       " u'auditori',\n",
       " u'fourengin',\n",
       " u'shinawatra',\n",
       " u'fin',\n",
       " u'easier',\n",
       " u'cnet',\n",
       " u'recours',\n",
       " u'jurisdictionsgeorg',\n",
       " u'offnum',\n",
       " u'ankol',\n",
       " u'numvolum',\n",
       " u'cristoforo',\n",
       " u'octavianus',\n",
       " u'miniseri',\n",
       " u'rectangl',\n",
       " u'democraticallyelect',\n",
       " u'sovi',\n",
       " u'effectu',\n",
       " u'surgic',\n",
       " u'interrupt',\n",
       " u'dialectnum',\n",
       " u'itanium',\n",
       " u'sixteen',\n",
       " u'anglofrisian',\n",
       " u'sedgefield',\n",
       " u'preemin',\n",
       " u'rumour',\n",
       " u'damnat',\n",
       " u'capricorn',\n",
       " u'debut',\n",
       " u'numbroughton',\n",
       " 'xx',\n",
       " u'hauraki',\n",
       " u'accommod',\n",
       " u'rheinquellhorn',\n",
       " u'memphi',\n",
       " u'arrow',\n",
       " u'ingrid',\n",
       " u'opilion',\n",
       " u'volcano',\n",
       " u'healthcar',\n",
       " u'macromolecul',\n",
       " u'angola',\n",
       " u'muham',\n",
       " u'callnum',\n",
       " u'knockout',\n",
       " u'lapidg',\n",
       " u'allah',\n",
       " u'natofootnot',\n",
       " u'whic',\n",
       " u'scriptnum',\n",
       " u'dhabi',\n",
       " u'whiz',\n",
       " u'actium',\n",
       " u'preemptiv',\n",
       " u'wellwat',\n",
       " u'distilleri',\n",
       " u'commiss',\n",
       " u'theynum',\n",
       " u'whip',\n",
       " 'ru',\n",
       " u'starvat',\n",
       " 'rp',\n",
       " u'diction',\n",
       " u'oprah',\n",
       " u'tianjin',\n",
       " u'nepo',\n",
       " u'mayan',\n",
       " u'adamnum',\n",
       " u'eleusinian',\n",
       " u'mason',\n",
       " 're',\n",
       " u'genghi',\n",
       " 'rg',\n",
       " u'adapt',\n",
       " 'rc',\n",
       " u'hippocr',\n",
       " 'rn',\n",
       " 'ro',\n",
       " u'strategist',\n",
       " u'outburst',\n",
       " u'sensori',\n",
       " u'watchnum',\n",
       " u'navig',\n",
       " u'tetrapod',\n",
       " u'epithet',\n",
       " u'nightmar',\n",
       " u'greenish',\n",
       " u'midpoint',\n",
       " u'theogoni',\n",
       " u'grandsen',\n",
       " u'deduct',\n",
       " u'busiest',\n",
       " u'sheet',\n",
       " u'wasnum',\n",
       " u'gameplay',\n",
       " u'yellowhamm',\n",
       " u'sahelian',\n",
       " u'untreat',\n",
       " u'smallscal',\n",
       " u'redhair',\n",
       " u'speedi',\n",
       " u'district',\n",
       " u'elsewheredata',\n",
       " u'shiftnum',\n",
       " u'identifinum',\n",
       " u'kashmir',\n",
       " u'monomotapa',\n",
       " u'silicon',\n",
       " u'planeterwin',\n",
       " u'frontiernum',\n",
       " u'sentimentnum',\n",
       " u'atp',\n",
       " u'croatian',\n",
       " u'ostens',\n",
       " u'yio',\n",
       " u'radicnum',\n",
       " u'humanismhonderich',\n",
       " u'paradisus',\n",
       " u'nigel',\n",
       " u'vertebr',\n",
       " u'zacheriah',\n",
       " u'wasp',\n",
       " u'vocalnum',\n",
       " u'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n",
       " u'instruct',\n",
       " u'legendarinum',\n",
       " u'knight',\n",
       " u'devastnum',\n",
       " u'niger',\n",
       " u'declaim',\n",
       " u'moneynum',\n",
       " u'carnivora',\n",
       " u'easili',\n",
       " u'xii',\n",
       " u'christiannum',\n",
       " u'understat',\n",
       " u'necessarili',\n",
       " u'master',\n",
       " u'smallarm',\n",
       " u'xiv',\n",
       " u'intraven',\n",
       " u'bitter',\n",
       " u'hewitt',\n",
       " u'whinum',\n",
       " u'danish',\n",
       " u'wizard',\n",
       " u'circl',\n",
       " u'geneva',\n",
       " u'yellownum',\n",
       " u'standnum',\n",
       " u'signatur',\n",
       " u'lumber',\n",
       " u'sindebel',\n",
       " u'siegel',\n",
       " u'wisdom',\n",
       " u'legislatur',\n",
       " u'naturallyoccur',\n",
       " u'technic',\n",
       " u'trek',\n",
       " u'peril',\n",
       " u'maglev',\n",
       " u'dystopian',\n",
       " u'medicineliterari',\n",
       " u'coward',\n",
       " u'tree',\n",
       " u'durin',\n",
       " u'humma',\n",
       " u'project',\n",
       " u'pneumonia',\n",
       " u'friend',\n",
       " u'entri',\n",
       " u'numfisch',\n",
       " u'treu',\n",
       " u'ballarat',\n",
       " u'pronouncenamescom',\n",
       " u'seria',\n",
       " u'behavior',\n",
       " u'thar',\n",
       " u'runner',\n",
       " u'boston',\n",
       " u'spectrum',\n",
       " u'wiland',\n",
       " u'sensnum',\n",
       " u'louisiananum',\n",
       " u'toulon',\n",
       " u'increment',\n",
       " u'miniatur',\n",
       " u'infring',\n",
       " u'dozen',\n",
       " u'extirp',\n",
       " u'downnum',\n",
       " u'sitin',\n",
       " u'courier',\n",
       " u'rudolph',\n",
       " u'overalnum',\n",
       " u'israelnum',\n",
       " u'lumpur',\n",
       " u'season',\n",
       " u'kfor',\n",
       " u'graduatnum',\n",
       " u'kremlin',\n",
       " u'simplifi',\n",
       " u'britannicanum',\n",
       " u'limelinden',\n",
       " u'rhodesia',\n",
       " u'shall',\n",
       " u'buonapart',\n",
       " u'object',\n",
       " u'correct',\n",
       " u'victoria',\n",
       " u'suburbnum',\n",
       " u'mouth',\n",
       " u'specifi',\n",
       " u'letter',\n",
       " u'ugandadiffer',\n",
       " u'ministnum',\n",
       " u'airship',\n",
       " u'thriller',\n",
       " u'wellb',\n",
       " u'expound',\n",
       " u'singer',\n",
       " u'rockhampton',\n",
       " u'normannum',\n",
       " u'tracenum',\n",
       " u'heqiao',\n",
       " u'unexplain',\n",
       " u'grove',\n",
       " u'professor',\n",
       " u'camp',\n",
       " u'hospit',\n",
       " u'foundernum',\n",
       " u'stupid',\n",
       " u'tech',\n",
       " u'dernum',\n",
       " u'framework',\n",
       " u'lewinum',\n",
       " u'citystnum',\n",
       " u'arkabutla',\n",
       " u'bisexu',\n",
       " u'behaviornum',\n",
       " u'came',\n",
       " u'ensurnum',\n",
       " u'szayna',\n",
       " u'explan',\n",
       " u'ostentati',\n",
       " u'historiannum',\n",
       " u'bomb',\n",
       " u'quak',\n",
       " u'childhoodnum',\n",
       " u'hungari',\n",
       " u'numinnovationsindex',\n",
       " u'teresa',\n",
       " u'numaustralian',\n",
       " u'transluc',\n",
       " u'lostnum',\n",
       " u'dicken',\n",
       " u'advisori',\n",
       " u'ulcer',\n",
       " u'sexism',\n",
       " u'lethal',\n",
       " u'insecta',\n",
       " u'thermomet',\n",
       " u'provincinum',\n",
       " u'incarnatio',\n",
       " u'szalipszki',\n",
       " u'rogernum',\n",
       " u'layout',\n",
       " u'independnum',\n",
       " u'holder',\n",
       " u'nontrinitarian',\n",
       " u'neopagan',\n",
       " u'releas',\n",
       " u'restaur',\n",
       " u'pressurnum',\n",
       " u'rihanna',\n",
       " u'rico',\n",
       " u'midtwentieth',\n",
       " u'busi',\n",
       " u'bliss',\n",
       " u'rick',\n",
       " u'rich',\n",
       " u'neoplaton',\n",
       " u'mend',\n",
       " u'epeir',\n",
       " u'rice',\n",
       " u'sieg',\n",
       " u'handspe',\n",
       " u'rnum',\n",
       " u'rica',\n",
       " u'plate',\n",
       " u'pubsacsorgcgibinabstractcgibichawnuminumabsbinumjhtml',\n",
       " u'plata',\n",
       " u'klein',\n",
       " u'partnersnytimescombooksfirstbbrinkleyparkshtml',\n",
       " u'vener',\n",
       " u'fung',\n",
       " u'strengthnum',\n",
       " u'foremost',\n",
       " u'pocket',\n",
       " u'rossnum',\n",
       " u'stormnum',\n",
       " u'new',\n",
       " u'nationnum',\n",
       " u'aroma',\n",
       " u'equilibriocept',\n",
       " u'randal',\n",
       " u'farnum',\n",
       " u'accelernum',\n",
       " u'flour',\n",
       " u'statusnum',\n",
       " u'boarder',\n",
       " u'phra',\n",
       " u'nationth',\n",
       " u'succeednum',\n",
       " u'patch',\n",
       " u'sauc',\n",
       " u'indigen',\n",
       " u'saxecoburgsaalfeld',\n",
       " u'saud',\n",
       " u'wrangel',\n",
       " u'antedec',\n",
       " u'fred',\n",
       " u'sowand',\n",
       " u'saul',\n",
       " u'choluim',\n",
       " u'blew',\n",
       " u'detectnum',\n",
       " u'ongo',\n",
       " u'zeitgeist',\n",
       " u'nonvolcan',\n",
       " u'eneminum',\n",
       " u'guardianunlimit',\n",
       " u'manchus',\n",
       " u'mandatori',\n",
       " u'result',\n",
       " u'respons',\n",
       " u'fail',\n",
       " u'atyeo',\n",
       " u'countrycia',\n",
       " u'peternum',\n",
       " u'dahl',\n",
       " u'turman',\n",
       " u'oceania',\n",
       " u'furbertharri',\n",
       " u'hanseat',\n",
       " u'lenap',\n",
       " u'heterogen',\n",
       " u'particlnum',\n",
       " u'delphi',\n",
       " u'easi',\n",
       " u'wikipedia',\n",
       " u'irv',\n",
       " u'xvi',\n",
       " u'iri',\n",
       " u'figur',\n",
       " u'score',\n",
       " u'irl',\n",
       " u'unto',\n",
       " u'herb',\n",
       " u'ira',\n",
       " u'confirmnum',\n",
       " u'glasgow',\n",
       " u'cooney',\n",
       " u'inabl',\n",
       " u'marknum',\n",
       " u'natura',\n",
       " u'extend',\n",
       " u'canadanum',\n",
       " u'travelogu',\n",
       " u'sunspot',\n",
       " u'extens',\n",
       " u'mifflin',\n",
       " u'wtc',\n",
       " u'drew',\n",
       " u'extent',\n",
       " u'zililo',\n",
       " u'toler',\n",
       " u'advertis',\n",
       " u'debt',\n",
       " u'aerosol',\n",
       " u'cur',\n",
       " u'ingest',\n",
       " u'vavrinec',\n",
       " u'accident',\n",
       " u'disdain',\n",
       " u'unemploy',\n",
       " u'metastas',\n",
       " u'macedonia',\n",
       " u'stuttgart',\n",
       " u'principlnum',\n",
       " u'antipop',\n",
       " u'logic',\n",
       " u'wipeout',\n",
       " u'countri',\n",
       " u'seri',\n",
       " u'numthnum',\n",
       " u'southeastern',\n",
       " u'moravia',\n",
       " u'comenum',\n",
       " u'compromis',\n",
       " u'libyan',\n",
       " u'assur',\n",
       " u'okh',\n",
       " u'dietari',\n",
       " u'researchnum',\n",
       " u'nghymru',\n",
       " u'suprasegment',\n",
       " u'ang',\n",
       " u'bridgerteton',\n",
       " u'stupa',\n",
       " u'pra',\n",
       " u'summat',\n",
       " u'assum',\n",
       " u'summar',\n",
       " u'godhead',\n",
       " u'yale',\n",
       " u'watercraft',\n",
       " u'angel',\n",
       " u'adverb',\n",
       " u'dhar',\n",
       " u'union',\n",
       " u'languagnum',\n",
       " u'jurchen',\n",
       " u'frontlin',\n",
       " u'advert',\n",
       " u'hugenum',\n",
       " u'cultivnum',\n",
       " u'much',\n",
       " u'stadium',\n",
       " u'progenitor',\n",
       " u'hillenburg',\n",
       " u'phyla',\n",
       " u'superhuman',\n",
       " u'tallest',\n",
       " u'pro',\n",
       " u'hesit',\n",
       " u'dixon',\n",
       " u'spir',\n",
       " u'thnum',\n",
       " u'life',\n",
       " u'votiv',\n",
       " u'regul',\n",
       " u'homeland',\n",
       " u'oryza',\n",
       " u'eastern',\n",
       " u'worker',\n",
       " u'golda',\n",
       " u'afternum',\n",
       " u'wish',\n",
       " u'catchment',\n",
       " u'steerabl',\n",
       " u'lift',\n",
       " u'erythema',\n",
       " u'booknum',\n",
       " u'child',\n",
       " u'landbas',\n",
       " u'doti',\n",
       " u'overseanum',\n",
       " u'gemston',\n",
       " u'bookstor',\n",
       " u'davi',\n",
       " u'wildcat',\n",
       " u'crucibl',\n",
       " u'actressbritannicacom',\n",
       " u'wanapitei',\n",
       " u'steinitz',\n",
       " u'accessori',\n",
       " u'ada',\n",
       " u'dissect',\n",
       " u'limeston',\n",
       " u'intak',\n",
       " u'heidelberg',\n",
       " u'employ',\n",
       " u'calcium',\n",
       " u'denveraurorabould',\n",
       " u'fezzan',\n",
       " u'viii',\n",
       " u'propernum',\n",
       " u'seduc',\n",
       " u'ratenum',\n",
       " u'gloucestershir',\n",
       " u'tintin',\n",
       " u'caucasian',\n",
       " u'governornum',\n",
       " u'seiznum',\n",
       " u'linguistnum',\n",
       " u'trini',\n",
       " u'rediscov',\n",
       " u'toolkit',\n",
       " u'player',\n",
       " u'eighteen',\n",
       " u'violin',\n",
       " u'pastur',\n",
       " u'emperorconf',\n",
       " u'piotr',\n",
       " u'flore',\n",
       " u'guineanum',\n",
       " u'hong',\n",
       " u'harmoni',\n",
       " u'aazein',\n",
       " u'calima',\n",
       " u'presidentjo',\n",
       " u'woollen',\n",
       " u'oleum',\n",
       " u'split',\n",
       " u'jungl',\n",
       " u'elliott',\n",
       " u'costum',\n",
       " u'rebound',\n",
       " u'european',\n",
       " u'graem',\n",
       " u'midnumnum',\n",
       " u'paintnum',\n",
       " u'permit',\n",
       " u'josef',\n",
       " u'donnchada',\n",
       " u'smartcard',\n",
       " u'intuit',\n",
       " u'slovenia',\n",
       " u'ownership',\n",
       " u'refin',\n",
       " u'flownum',\n",
       " u'tune',\n",
       " u'smallnum',\n",
       " u'ordinarinum',\n",
       " u'sivana',\n",
       " u'chinesnum',\n",
       " u'earliernum',\n",
       " u'resourcnum',\n",
       " u'erectus',\n",
       " u'spanishnum',\n",
       " u'redeem',\n",
       " u'tabriz',\n",
       " u'anim',\n",
       " u'academia',\n",
       " u'letternum',\n",
       " u'annapoli',\n",
       " u'anglospher',\n",
       " u'moreov',\n",
       " u'legisl',\n",
       " u'bonni',\n",
       " u'autobahn',\n",
       " u'capitol',\n",
       " u'moray',\n",
       " u'editnum',\n",
       " u'airbas',\n",
       " u'ordin',\n",
       " u'crew',\n",
       " u'beset',\n",
       " u'djibouti',\n",
       " u'birmingham',\n",
       " u'malta',\n",
       " u'plight',\n",
       " u'previous',\n",
       " u'noscript',\n",
       " u'tonga',\n",
       " u'walknum',\n",
       " u'hal',\n",
       " u'benedicto',\n",
       " u'shtetl',\n",
       " u'haa',\n",
       " u'memberpluto',\n",
       " u'had',\n",
       " u'ideal',\n",
       " u'woodstock',\n",
       " u'barbado',\n",
       " u'turquin',\n",
       " u'mcnamara',\n",
       " u'prison',\n",
       " u'striation',\n",
       " u'har',\n",
       " u'has',\n",
       " u'hat',\n",
       " u'befuddl',\n",
       " u'hav',\n",
       " u'keeley',\n",
       " u'sanit',\n",
       " u'soldnum',\n",
       " u'tomnum',\n",
       " u'computnum',\n",
       " u'ranknum',\n",
       " u'posen',\n",
       " u'fortif',\n",
       " u'motornum',\n",
       " u'airtoair',\n",
       " u'zondervan',\n",
       " u'anarchnum',\n",
       " u'itemidfnum',\n",
       " u'birth',\n",
       " u'valv',\n",
       " u'shadow',\n",
       " u'anticommun',\n",
       " 'd',\n",
       " u'measur',\n",
       " u'ufdfnum',\n",
       " u'cumbrian',\n",
       " u'moscownum',\n",
       " u'specif',\n",
       " u'playnum',\n",
       " u'signumnaonumzmlsnumuaxnummevpzanumksiy',\n",
       " u'neighbournum',\n",
       " u'remind',\n",
       " u'madhya',\n",
       " u'peabodi',\n",
       " u'lymphat',\n",
       " u'bobbi',\n",
       " u'fourwheel',\n",
       " u'sebastian',\n",
       " u'tombston',\n",
       " u'battlefield',\n",
       " u'right',\n",
       " u'old',\n",
       " u'yoweri',\n",
       " u'crowd',\n",
       " u'nonrepres',\n",
       " u'czech',\n",
       " u'workstationlevel',\n",
       " u'creed',\n",
       " u'pollsbud',\n",
       " u'crown',\n",
       " u'mustain',\n",
       " u'valignano',\n",
       " u'welch',\n",
       " u'tajik',\n",
       " u'choctaw',\n",
       " u'marriagnum',\n",
       " u'billboard',\n",
       " u'ladderworld',\n",
       " u'creep',\n",
       " u'transmiss',\n",
       " u'occasionnum',\n",
       " u'fou',\n",
       " u'christiaan',\n",
       " u'koussi',\n",
       " u'peripheri',\n",
       " u'for',\n",
       " u'bottom',\n",
       " u'univ',\n",
       " u'fox',\n",
       " u'gioro',\n",
       " u'foe',\n",
       " u'fog',\n",
       " u'uma',\n",
       " u'umm',\n",
       " u'condit',\n",
       " u'baidoa',\n",
       " u'euthanasia',\n",
       " u'sensibl',\n",
       " u'annal',\n",
       " u'whatnum',\n",
       " u'stefan',\n",
       " u'byzantium',\n",
       " u'moderateto',\n",
       " u'mainnum',\n",
       " u'unfrozen',\n",
       " u'bornnum',\n",
       " u'silvestri',\n",
       " u'friedrichnum',\n",
       " u'bergendoff',\n",
       " u'islandrakiura',\n",
       " u'albanianum',\n",
       " u'staynum',\n",
       " u'timelin',\n",
       " u'req',\n",
       " u'filipino',\n",
       " u'connot',\n",
       " u'sugarnum',\n",
       " u'supernum',\n",
       " u'bynum',\n",
       " u'northeastnum',\n",
       " u'machinegun',\n",
       " u'collett',\n",
       " u'electnum',\n",
       " u'lar',\n",
       " u'musaget',\n",
       " u'bicamer',\n",
       " u'omnipot',\n",
       " u'adem',\n",
       " u'aden',\n",
       " u'mohanda',\n",
       " u'unequivoc',\n",
       " u'nixon',\n",
       " u'renown',\n",
       " u'lamprey',\n",
       " u'soc',\n",
       " u'millennianum',\n",
       " u'lenin',\n",
       " u'mbe',\n",
       " u'moralistsbradford',\n",
       " u'som',\n",
       " u'sol',\n",
       " u'ethnolog',\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = VEC.vocabulary_\n",
    "# Make a dictionary of Series for each term;\n",
    "count_dict = {w: pd.Series(tdm.getcol(vocab[w]).data) for w in vocab}\n",
    "count_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%\n",
      "RUNNING makeFreqDict\n",
      "%%%%%%\n",
      "$$$$ FINISHED 1000 of 18148 docs in 0.00609612464905 seconds\n",
      "$$$$ FINISHED 2000 of 18148 docs in 0.0132689476013 seconds\n",
      "$$$$ FINISHED 3000 of 18148 docs in 0.0187590122223 seconds\n",
      "$$$$ FINISHED 4000 of 18148 docs in 0.0247349739075 seconds\n",
      "$$$$ FINISHED 5000 of 18148 docs in 0.0304040908813 seconds\n",
      "$$$$ FINISHED 6000 of 18148 docs in 0.0353710651398 seconds\n",
      "$$$$ FINISHED 7000 of 18148 docs in 0.0410079956055 seconds\n",
      "$$$$ FINISHED 8000 of 18148 docs in 0.0462470054626 seconds\n",
      "$$$$ FINISHED 9000 of 18148 docs in 0.0522980690002 seconds\n",
      "$$$$ FINISHED 10000 of 18148 docs in 0.0581500530243 seconds\n",
      "$$$$ FINISHED 11000 of 18148 docs in 0.0644819736481 seconds\n",
      "$$$$ FINISHED 12000 of 18148 docs in 0.0715520381927 seconds\n",
      "$$$$ FINISHED 13000 of 18148 docs in 0.0765740871429 seconds\n",
      "$$$$ FINISHED 14000 of 18148 docs in 0.0815050601959 seconds\n",
      "$$$$ FINISHED 15000 of 18148 docs in 0.0866451263428 seconds\n",
      "$$$$ FINISHED 16000 of 18148 docs in 0.0906760692596 seconds\n",
      "$$$$ FINISHED 17000 of 18148 docs in 0.0936551094055 seconds\n",
      "$$$$ FINISHED 18000 of 18148 docs in 0.0965731143951 seconds\n",
      "*** finished with 18148 documents in 0.0973339080811 seconds\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "def makeFreqDict(count_dict):\n",
    "    import string\n",
    "    import time\n",
    "    #\n",
    "    print('%%%%%%\\nRUNNING makeFreqDict\\n%%%%%%')\n",
    "    start=time.time()\n",
    "    freqDict = {}\n",
    "    count = 0\n",
    "    totalTerms = len(count_dict.keys())\n",
    "    #\n",
    "    for key in count_dict.keys():\n",
    "        # increment count for updates\n",
    "        count += 1\n",
    "        if (count % 1000 == 0):\n",
    "            print('$$$$ FINISHED ' + str(count) + ' of ' + str(totalTerms) + ' docs in ' + str(time.time()-start) + ' seconds')\n",
    "        freqDict[key] = len(count_dict[key])\n",
    "    #\n",
    "    end=time.time()\n",
    "    print('*** finished with ' + str(totalTerms) + ' terms in ' + str(end-start) + ' seconds')\n",
    "    #\n",
    "    return freqDict\n",
    "\n",
    "freqDict = makeFreqDict(count_dict)\n",
    "\n",
    "## THE OLD THING\n",
    "#freqDict = {}\n",
    "#for key in count_dict.keys():\n",
    "#    freqDict[key] = len(count_dict[key])\n",
    "#\n",
    "#freqDict ## I double checked this by searching a few keys in the finder and it looked good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ioann</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conapo</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fawk</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longer-run</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pendulum</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq\n",
       "term            \n",
       "ioann          1\n",
       "conapo         1\n",
       "fawk           1\n",
       "longer-run     1\n",
       "pendulum       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countDF = pd.DataFrame(freqDict.items(), columns=['term', 'freq'])\n",
    "countDF = countDF.set_index('term')\n",
    "countDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6325, 1)\n"
     ]
    }
   ],
   "source": [
    "print(countDF[countDF['freq'] > 1].shape)\n",
    "DF = countDF[countDF['freq'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6325, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "M = len(wikiFiles)\n",
    "DF['idf'] = M / DF['freq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#### use this approach and hard code the log base is you want something other than e\n",
    "def getLog(num):\n",
    "    return math.log(num, 2) # put in log base here (where the 2 is)\n",
    "\n",
    "#countDF['logidf'] = countDF['idf'].apply(getLog) \n",
    "\n",
    "#### or just use this if you just want natural log\n",
    "DF['logidf'] = DF['idf'].apply(math.log) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linknum:num</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>833</td>\n",
       "      <td>1.001200</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>831</td>\n",
       "      <td>1.003610</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>815</td>\n",
       "      <td>1.023313</td>\n",
       "      <td>0.023045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>804</td>\n",
       "      <td>1.037313</td>\n",
       "      <td>0.036634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>769</td>\n",
       "      <td>1.084525</td>\n",
       "      <td>0.081142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>765</td>\n",
       "      <td>1.090196</td>\n",
       "      <td>0.086358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>761</td>\n",
       "      <td>1.095926</td>\n",
       "      <td>0.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>752</td>\n",
       "      <td>1.109043</td>\n",
       "      <td>0.103497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>748</td>\n",
       "      <td>1.114973</td>\n",
       "      <td>0.108830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>666</td>\n",
       "      <td>1.252252</td>\n",
       "      <td>0.224944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>621</td>\n",
       "      <td>1.342995</td>\n",
       "      <td>0.294902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>611</td>\n",
       "      <td>1.364975</td>\n",
       "      <td>0.311136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>578</td>\n",
       "      <td>1.442907</td>\n",
       "      <td>0.366660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>572</td>\n",
       "      <td>1.458042</td>\n",
       "      <td>0.377094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq       idf    logidf\n",
       "term                                 \n",
       "of            834  1.000000  0.000000\n",
       ",             834  1.000000  0.000000\n",
       "linknum:num   834  1.000000  0.000000\n",
       "the           834  1.000000  0.000000\n",
       ".             834  1.000000  0.000000\n",
       ":             834  1.000000  0.000000\n",
       "and           833  1.001200  0.001200\n",
       "in            831  1.003610  0.003604\n",
       "a             815  1.023313  0.023045\n",
       "to            804  1.037313  0.036634\n",
       "(             769  1.084525  0.081142\n",
       ")             765  1.090196  0.086358\n",
       "num           761  1.095926  0.091600\n",
       "as            752  1.109043  0.103497\n",
       "is            748  1.114973  0.108830\n",
       "by            666  1.252252  0.224944\n",
       "it            621  1.342995  0.294902\n",
       "with          611  1.364975  0.311136\n",
       "for           578  1.442907  0.366660\n",
       "was           572  1.458042  0.377094"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.sort_values(by='idf').head(20)\n",
    "#idf.sort_values(by='idf', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reliabl</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bactria</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>katrina</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fourth-most</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiji</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methan</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalinist</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vladimir</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-lay</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robbin</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engel</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disintegr</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renounc</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perish</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grenada</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avon</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eurostat</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shallow</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humorist</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mumbai</th>\n",
       "      <td>2</td>\n",
       "      <td>417.0</td>\n",
       "      <td>6.033086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq    idf    logidf\n",
       "term                              \n",
       "reliabl         2  417.0  6.033086\n",
       "bactria         2  417.0  6.033086\n",
       "katrina         2  417.0  6.033086\n",
       "fourth-most     2  417.0  6.033086\n",
       "fiji            2  417.0  6.033086\n",
       "methan          2  417.0  6.033086\n",
       "stalinist       2  417.0  6.033086\n",
       "vladimir        2  417.0  6.033086\n",
       "multi-lay       2  417.0  6.033086\n",
       "robbin          2  417.0  6.033086\n",
       "engel           2  417.0  6.033086\n",
       "disintegr       2  417.0  6.033086\n",
       "renounc         2  417.0  6.033086\n",
       "perish          2  417.0  6.033086\n",
       "grenada         2  417.0  6.033086\n",
       "avon            2  417.0  6.033086\n",
       "eurostat        2  417.0  6.033086\n",
       "shallow         2  417.0  6.033086\n",
       "humorist        2  417.0  6.033086\n",
       "mumbai          2  417.0  6.033086"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.sort_values(by='idf', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF.to_csv('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017/wiki-IDF/wiki-IDF-test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wps = wikiPath.split('-')\n",
    "wps[len(wps)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
