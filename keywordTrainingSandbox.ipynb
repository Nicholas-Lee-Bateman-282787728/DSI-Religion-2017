{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "2016-11-07 15:48:17.831192\n",
      "finished loading packages after 2.96554899216 seconds\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul 19 16:14:43 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun  2 15:23:11 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "import time\n",
    "start=time.time()\n",
    "import sys, os\n",
    "\n",
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017')\n",
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing as mp\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "sys.path.append('./prototype_python/')\n",
    "import lingual as la\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "#sys.stdout = open(\"output.txt\", \"a\")\n",
    "print(str(datetime.now()))\n",
    "print('finished loading packages after '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#\n",
    "import getNewDocs as gnd\n",
    "\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "41\n",
      "59\n",
      "20\n",
      "53\n",
      "[['DorothyDay', 'test0'], ['IntegralYoga', 'test11'], ['SeaShepherds', 'test1'], ['IntegralYoga', 'test1'], ['WBC', 'test3'], ['DorothyDay', 'test4'], ['Bahai', 'test7'], ['IntegralYoga', 'test8'], ['WBC', 'test8'], ['WBC', 'test7'], ['DorothyDay', 'test8'], ['Bahai', 'test3'], ['IntegralYoga', 'test4'], ['DorothyDay', 'test1'], ['IntegralYoga', 'test10'], ['SeaShepherds', 'test2'], ['IntegralYoga', 'test0'], ['WBC', 'test0'], ['DorothyDay', 'test5'], ['Bahai', 'test6'], ['WBC', 'test9'], ['WBC', 'test4'], ['Bahai', 'test2'], ['IntegralYoga', 'test7'], ['Bahai', 'test9'], ['WBC', 'test10'], ['SeaShepherds', 'test3'], ['IntegralYoga', 'test3'], ['WBC', 'test1'], ['DorothyDay', 'test2'], ['Bahai', 'test5'], ['WBC', 'test5'], ['DorothyDay', 'test6'], ['Bahai', 'test1'], ['IntegralYoga', 'test6'], ['Bahai', 'test8'], ['IntegralYoga', 'test2'], ['DorothyDay', 'test3'], ['Bahai', 'test4'], ['SeaShepherds', 'test0'], ['WBC', 'test2'], ['DorothyDay', 'test7'], ['Bahai', 'test0'], ['IntegralYoga', 'test9'], ['WBC', 'test6'], ['IntegralYoga', 'test5']]\n",
      "%%%%%\n",
      "length of subgroupList is 46\n"
     ]
    }
   ],
   "source": [
    "fileDF=gnd.newDocsToDF('./data_dsicap/', bin=5) ################################### WHERE THE NEW FILES ARE\n",
    "\n",
    "fileList=fileDF.values.tolist()\n",
    "\n",
    "fileList=[[fileList[i][0],fileList[i][1],fileList[i][2]] for i in range(len(fileList))]\n",
    "\n",
    "\n",
    "#Get set of subgroups\n",
    "subgroupList=[ list(y) for y in set((x[0],x[2]) for x in fileList) ]\n",
    "print(subgroupList)\n",
    "print('%%%%%\\nlength of subgroupList is ' + str(len(subgroupList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawPath = './data_dsicap/' ###############change this eventually\n",
    "runDirectory='./modelOutput/'\n",
    "#groupList=['DorothyDay','JohnPiper','MehrBaba','NaumanKhan','PastorAnderson',\n",
    "#   'Rabbinic','Shepherd','Unitarian','WBC']\n",
    "#groupList=['DorothyDay','NaumanKhan','Rabbinic','NawDawg','SeaShepherds','IntegralYoga','Bahai']\n",
    "#cocoWindow=int(sys.argv[1])\n",
    "#cvWindow=int(sys.argv[2])\n",
    "#startCount=int(sys.argv[3])\n",
    "#netAngle=int(sys.argv[4])\n",
    "cocoWindow=3\n",
    "cvWindow=3\n",
    "startCount=0\n",
    "netAngle=30\n",
    "groupSize=10\n",
    "#testSplit=.3\n",
    "targetWordCount=20\n",
    "svdInt=50\n",
    "simCount=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "#Create paramList\n",
    "paramList=[[x,fileList,targetWordCount,cocoWindow,svdInt,cvWindow,simCount,startCount,netAngle] for x in subgroupList]\n",
    "print(len(paramList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICK THE GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run calculation \n",
    "#masterOutput=[textAnalysis(x) for x in paramList]  ### INSTEAD OF THIS, WE MAKE THE OBJECT\n",
    "paramPick = paramList[6] ### instead of looping through, we just pick one\n",
    "#print(paramPick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bahai', 'test7']\n"
     ]
    }
   ],
   "source": [
    "#def textAnalysis(paramPick):\n",
    "startTime=time.time()\n",
    "groupId=paramPick[0]\n",
    "fileList=paramPick[1]\n",
    "targetWordCount=paramPick[2]\n",
    "cocoWindow=paramPick[3]\n",
    "svdInt=paramPick[4]\n",
    "cvWindow=paramPick[5]\n",
    "simCount=paramPick[6]\n",
    "startCount=paramPick[7]\n",
    "netAngle=paramPick[8]    \n",
    "\n",
    "print(groupId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['./data_dsicap/Bahai/raw/Bahai12.txt', './data_dsicap/Bahai/raw/Bahai16.txt', './data_dsicap/Bahai/raw/Bahai17.txt', './data_dsicap/Bahai/raw/Bahai43.txt', './data_dsicap/Bahai/raw/Bahai50.txt']\n"
     ]
    }
   ],
   "source": [
    "#Get list of subfiles\n",
    "subFileList=[x[1] for x in fileList if x[0]==groupId[0] and x[2]==groupId[1]]\n",
    "print(len(subFileList))\n",
    "print(subFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#Create lingual object\n",
    "loTest=la.lingualObject(subFileList)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LOOK AT LIST OF TOKENS FOR FILE\n",
    "#print(subFileList[0])\n",
    "#loTest.tokens[subFileList[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%\n",
      "cocoDict, length 995\n",
      "---the first ten keys:\n",
      "[u'essay', u'breadth', u'all', u'befriend', u'cincinnati', u'consider', u'global', u'focus', u'hath', u'concept']\n",
      "---the first entry:\n",
      "essay\n",
      "{u'quot': 1, u'this': 2, 'of': 1, u'with': 1, u'num': 1, u'take': 1, 'in': 2, u'our': 1, u'might': 1, u'seri': 1}\n"
     ]
    }
   ],
   "source": [
    "#Get coco\n",
    "loTest.getCoco(cocoWindow)\n",
    "\n",
    "#        self.cocoWindow=k\n",
    "#        self.cocoDict={}\n",
    "#        self.TF={}\n",
    "#        self.docTF={}\n",
    "\n",
    "print('%%%%\\ncocoDict, length ' + str(len(loTest.cocoDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cocoDict.keys()[:10])\n",
    "print('---the first entry:')\n",
    "key1 = loTest.cocoDict.keys()[0]\n",
    "print(key1)\n",
    "print(loTest.cocoDict[key1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.svdK: 50\n",
      "%%%%\n",
      "DSM, length 995\n",
      "---the first ten keys:\n",
      "[u'essay', u'breadth', u'all', u'befriend', u'cincinnati', u'consider', u'thi', u'global', u'focus', u'hath']\n",
      "---the first entry:\n",
      "{0: 0.65202854576580038, 1: -0.62490034055502386, 2: -0.17456216715568607, 3: 0.15337368643753194, 4: 0.47960791216668475, 5: -0.44828802063800782, 6: 0.24742287137322999, 7: 0.26808139006495424, 8: -0.031003907471725798, 9: -0.28197215169383599, 10: 0.40936860667659608, 11: -0.10361744159737875, 12: 0.24315973695576809, 13: -0.090769207178386269, 14: 0.14704680240123918, 15: -0.097073469023868764, 16: 0.098030263234155979, 17: -0.20531710718452378, 18: -0.17078588797490865, 19: 0.036194375345687937, 20: -0.055989046960168529, 21: -0.17550054795553563, 22: 0.055599489116615941, 23: 0.1128522996640232, 24: 0.30534821335598428, 25: -0.25192522566678593, 26: 0.31304098926863555, 27: -0.2491626448889018, 28: 0.058680681049895898, 29: -0.35836475473385293, 30: -0.08983565815531859, 31: 0.022170721627092355, 32: 0.033405683472400742, 33: -0.1346474487217427, 34: 0.07183621752594356, 35: 0.079408154510043169, 36: 0.053422001436266062, 37: -0.233186976540254, 38: 0.011561544245436484, 39: -0.10412041620565085, 40: -0.11325685867930299, 41: 0.096206378916797244, 42: 0.011672015325474933, 43: -0.17732221203967202, 44: -0.20419006149105695, 45: -0.12467562581232297, 46: -0.0082158646615905721, 47: -0.042640420990813749, 48: 0.38306106164257925, 49: 0.067917114670645054}\n"
     ]
    }
   ],
   "source": [
    "#Get DSM\n",
    "loTest.getDSM(svdInt)\n",
    "print('loTest.svdK: ' + str(loTest.svdK))\n",
    "\n",
    "print('%%%%\\nDSM, length ' + str(len(loTest.DSM)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.DSM.keys()[:10])\n",
    "print('---the first entry:')\n",
    "print(loTest.DSM[loTest.DSM.keys()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the old way\n",
    "##### adjadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Set keywords\n",
    "#loTest.setKeywords('adjAdv',targetWordCount,startCount)\n",
    "#print(loTest.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# the new way\n",
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'uniti', u'imagin', u'you', u'ive', u'everyon', u'will', u'realiz', u'mankind', u'impress', u'manifest', 'ye', u'howard', u'colbi', u'dream', 'we', u'our', u'infecti', 'p', u'diseas']\n"
     ]
    }
   ],
   "source": [
    "loTest.setKeywords('tfidf',targetWordCount,startCount)\n",
    "#print(loTest.keywords)\n",
    "#keys = [word for word in loTest.keywords if not 'codecerror']\n",
    "keys = []\n",
    "for word in loTest.keywords:\n",
    "    if word != 'codecerror':\n",
    "        keys = keys + [word]\n",
    "#print(keys)\n",
    "loTest.keywords = keys\n",
    "print(loTest.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### the guts of the new way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>four</td>\n",
       "      <td>91</td>\n",
       "      <td>9.164835</td>\n",
       "      <td>2.215374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cyprus</td>\n",
       "      <td>8</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>4.646792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lord</td>\n",
       "      <td>15</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>4.018183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit</td>\n",
       "      <td>9</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>4.529009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prize</td>\n",
       "      <td>18</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>3.835862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     term  freq         idf    logidf\n",
       "0    four    91    9.164835  2.215374\n",
       "1  cyprus     8  104.250000  4.646792\n",
       "2    lord    15   55.600000  4.018183\n",
       "3   digit     9   92.666667  4.529009\n",
       "4   prize    18   46.333333  3.835862"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfFile = 'wiki-test-5-IDF.csv' \n",
    "idf = pd.read_csv('./wiki-IDF/' + idfFile)\n",
    "idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2612.000000</td>\n",
       "      <td>2612.000000</td>\n",
       "      <td>2612.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.557427</td>\n",
       "      <td>65.961852</td>\n",
       "      <td>3.847418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>83.011571</td>\n",
       "      <td>43.172716</td>\n",
       "      <td>0.989037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>3.325036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>59.571429</td>\n",
       "      <td>4.087176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>4.646792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>834.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              freq          idf       logidf\n",
       "count  2612.000000  2612.000000  2612.000000\n",
       "mean     36.557427    65.961852     3.847418\n",
       "std      83.011571    43.172716     0.989037\n",
       "min       6.000000     1.000000     0.000000\n",
       "25%       8.000000    27.800000     3.325036\n",
       "50%      14.000000    59.571429     4.087176\n",
       "75%      30.000000   104.250000     4.646792\n",
       "max     834.000000   139.000000     4.934474"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#idf.ix[loTest.keywords[0]]\n",
    "#loTest.keywords[0]\n",
    "idf = idf.set_index('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senat</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abolish</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mph</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excess</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gordon</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gone</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minnesota</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seventeenth</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq    idf    logidf\n",
       "term                              \n",
       "threat          6  139.0  4.934474\n",
       "senat           6  139.0  4.934474\n",
       "abolish         6  139.0  4.934474\n",
       "mph             6  139.0  4.934474\n",
       "milk            6  139.0  4.934474\n",
       "excess          6  139.0  4.934474\n",
       "gordon          6  139.0  4.934474\n",
       "gone            6  139.0  4.934474\n",
       "minnesota       6  139.0  4.934474\n",
       "seventeenth     6  139.0  4.934474"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.sort_values(by='idf', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linknum:num</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>833</td>\n",
       "      <td>1.001200</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>831</td>\n",
       "      <td>1.003610</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>815</td>\n",
       "      <td>1.023313</td>\n",
       "      <td>0.023045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>804</td>\n",
       "      <td>1.037313</td>\n",
       "      <td>0.036634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq       idf    logidf\n",
       "term                                 \n",
       "of            834  1.000000  0.000000\n",
       ",             834  1.000000  0.000000\n",
       ":             834  1.000000  0.000000\n",
       "linknum:num   834  1.000000  0.000000\n",
       ".             834  1.000000  0.000000\n",
       "the           834  1.000000  0.000000\n",
       "and           833  1.001200  0.001200\n",
       "in            831  1.003610  0.003604\n",
       "a             815  1.023313  0.023045\n",
       "to            804  1.037313  0.036634"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.sort_values(by='idf', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freq        6.000000\n",
       "idf       139.000000\n",
       "logidf      4.934474\n",
       "Name: milk, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf.head()\n",
    "idf.ix['milk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "u'thi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-23a3acdc3987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no slices here, handle elsewhere'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   1777\u001b[0m                                                       drop_level=drop_level)\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4160)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4024)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13161)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13115)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'thi'"
     ]
    }
   ],
   "source": [
    "print(loTest.keywords[0])\n",
    "idf.ix[loTest.keywords[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'thi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-69f4cc7787dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no slices here, handle elsewhere'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   1777\u001b[0m                                                       drop_level=drop_level)\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Seth/anaconda/envs/py27/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4160)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4024)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13161)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13115)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'thi'"
     ]
    }
   ],
   "source": [
    "idf.ix[loTest.keywords[0]].tolist()\n",
    "idf.ix[loTest.keywords[0]][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi\n",
      "thi\n",
      "NOT FOUND\n",
      "thou\n",
      "thou\n",
      "NOT FOUND\n",
      "my\n",
      "freq        7.000000\n",
      "idf       119.142857\n",
      "logidf      4.780323\n",
      "Name: my, dtype: float64\n",
      "thee\n",
      "thee\n",
      "NOT FOUND\n",
      "prophet\n",
      "freq        6.000000\n",
      "idf       139.000000\n",
      "logidf      4.934474\n",
      "Name: prophet, dtype: float64\n",
      "me\n",
      "me\n",
      "NOT FOUND\n",
      "we\n",
      "freq      11.000000\n",
      "idf       75.818182\n",
      "logidf     4.328338\n",
      "Name: we, dtype: float64\n",
      "uniti\n",
      "uniti\n",
      "NOT FOUND\n",
      "fate\n",
      "fate\n",
      "NOT FOUND\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for keyword in loTest.keywords:\n",
    "    try:\n",
    "        print(keyword)\n",
    "        print(idf.ix[keyword])\n",
    "    except:\n",
    "        print(keyword)\n",
    "        print('NOT FOUND')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loTest.rawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4217\n",
      "['o', u'thou', u'whose', u'face', 'is', u'the', u'object', 'of', 'my', u'ador', u'whose', u'beauti', 'is', 'my', u'sanctuari', u'whose', u'habit', 'is', 'my', u'goal']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "#[all_words + toke for toke in loTest.tokens.values()]\n",
    "for toke in loTest.tokens.values():\n",
    "    all_words = all_words + toke\n",
    "\n",
    "print(len(all_words))\n",
    "print(all_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqDF (1195, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crusad</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founder</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanctiti</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq\n",
       "term          \n",
       "all         41\n",
       "concept      1\n",
       "crusad       1\n",
       "founder      1\n",
       "sanctiti     1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "freq = FreqDist(all_words) ## create FreqDist object with word frequencies\n",
    "#\n",
    "columns_obj = [\"term\", \"freq\"]\n",
    "freqDF = pd.DataFrame(freq.items(), columns=columns_obj) # convert it to a data frame\n",
    "freqDF = freqDF.set_index('term')\n",
    "print('freqDF ' + str(freqDF.shape))\n",
    "freqDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqit (1195, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>41</td>\n",
       "      <td>4.343750</td>\n",
       "      <td>1.468738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept</th>\n",
       "      <td>1</td>\n",
       "      <td>28.758621</td>\n",
       "      <td>3.358938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crusad</th>\n",
       "      <td>1</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founder</th>\n",
       "      <td>1</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>3.835862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanctiti</th>\n",
       "      <td>1</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq         idf    logidf\n",
       "term                                \n",
       "all         41    4.343750  1.468738\n",
       "concept      1   28.758621  3.358938\n",
       "crusad       1  139.000000  4.934474\n",
       "founder      1   46.333333  3.835862\n",
       "sanctiti     1  139.000000  4.934474"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freqit = pd.concat([freqDF, idf])\n",
    "freqit = freqDF.join(idf[['idf', 'logidf']])\n",
    "# replace null values with max\n",
    "maxidf = max(freqit['idf'].dropna())\n",
    "maxlogidf = max(freqit['logidf'].dropna())\n",
    "freqit.loc[pd.isnull(freqit['idf']), 'idf'] = maxidf\n",
    "freqit.loc[pd.isnull(freqit['logidf']), 'logidf'] = maxlogidf\n",
    "\n",
    "\n",
    "print('freqit ' + str(freqit.shape))\n",
    "freqit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [freq, idf, logidf]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# should be empty, if the above cell has worked correctly\n",
    "print(freqit[pd.isnull(freqit['idf'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqit['tfidf'] = freqit['freq'] * freqit['idf']\n",
    "freqit['logtfidf'] = freqit['freq'] * freqit['logidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 5)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freqit = freqit.dropna(subset=['freq'], how='all')\n",
    "freqit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE RANKED TERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>logtfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>codecerror</th>\n",
       "      <td>98</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>13622.000000</td>\n",
       "      <td>483.578445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thi</th>\n",
       "      <td>42</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>5838.000000</td>\n",
       "      <td>207.247905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thou</th>\n",
       "      <td>34</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>4726.000000</td>\n",
       "      <td>167.772114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>21</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>4.780323</td>\n",
       "      <td>2502.000000</td>\n",
       "      <td>100.386788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thee</th>\n",
       "      <td>18</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>2502.000000</td>\n",
       "      <td>88.820531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prophet</th>\n",
       "      <td>12</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>59.213687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>12</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>59.213687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>21</td>\n",
       "      <td>75.818182</td>\n",
       "      <td>4.328338</td>\n",
       "      <td>1592.181818</td>\n",
       "      <td>90.895101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniti</th>\n",
       "      <td>9</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>44.410265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fate</th>\n",
       "      <td>8</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1112.000000</td>\n",
       "      <td>39.475791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muhammad</th>\n",
       "      <td>8</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1112.000000</td>\n",
       "      <td>39.475791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decre</th>\n",
       "      <td>8</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1112.000000</td>\n",
       "      <td>39.475791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christ</th>\n",
       "      <td>10</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>4.646792</td>\n",
       "      <td>1042.500000</td>\n",
       "      <td>46.467919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verili</th>\n",
       "      <td>7</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>34.541318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heaven</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prais</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babel</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lord</th>\n",
       "      <td>15</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>4.018183</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>60.272748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shall</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thine</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamp</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tower</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revel</th>\n",
       "      <td>6</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>29.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will</th>\n",
       "      <td>24</td>\n",
       "      <td>30.888889</td>\n",
       "      <td>3.430397</td>\n",
       "      <td>741.333333</td>\n",
       "      <td>82.329517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unto</th>\n",
       "      <td>5</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>24.672370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forth</th>\n",
       "      <td>5</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>24.672370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>divin</th>\n",
       "      <td>10</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>4.241327</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>42.413268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hath</th>\n",
       "      <td>5</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>24.672370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auxiliari</th>\n",
       "      <td>5</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>24.672370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grace</th>\n",
       "      <td>5</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>24.672370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>1</td>\n",
       "      <td>8.257426</td>\n",
       "      <td>2.111113</td>\n",
       "      <td>8.257426</td>\n",
       "      <td>2.111113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sea</th>\n",
       "      <td>1</td>\n",
       "      <td>8.176471</td>\n",
       "      <td>2.101261</td>\n",
       "      <td>8.176471</td>\n",
       "      <td>2.101261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>1</td>\n",
       "      <td>8.097087</td>\n",
       "      <td>2.091504</td>\n",
       "      <td>8.097087</td>\n",
       "      <td>2.091504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>1</td>\n",
       "      <td>7.380531</td>\n",
       "      <td>1.998846</td>\n",
       "      <td>7.380531</td>\n",
       "      <td>1.998846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>territori</th>\n",
       "      <td>1</td>\n",
       "      <td>7.252174</td>\n",
       "      <td>1.981301</td>\n",
       "      <td>7.252174</td>\n",
       "      <td>1.981301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>1</td>\n",
       "      <td>7.067797</td>\n",
       "      <td>1.955549</td>\n",
       "      <td>7.067797</td>\n",
       "      <td>1.955549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popul</th>\n",
       "      <td>2</td>\n",
       "      <td>3.489540</td>\n",
       "      <td>1.249770</td>\n",
       "      <td>6.979079</td>\n",
       "      <td>2.499540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>born</th>\n",
       "      <td>1</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>1.938742</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>1.938742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sever</th>\n",
       "      <td>1</td>\n",
       "      <td>6.619048</td>\n",
       "      <td>1.889951</td>\n",
       "      <td>6.619048</td>\n",
       "      <td>1.889951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>1</td>\n",
       "      <td>6.515625</td>\n",
       "      <td>1.874203</td>\n",
       "      <td>6.515625</td>\n",
       "      <td>1.874203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earli</th>\n",
       "      <td>1</td>\n",
       "      <td>6.415385</td>\n",
       "      <td>1.858699</td>\n",
       "      <td>6.415385</td>\n",
       "      <td>1.858699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>2</td>\n",
       "      <td>3.100372</td>\n",
       "      <td>1.131522</td>\n",
       "      <td>6.200743</td>\n",
       "      <td>2.263044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polit</th>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>1</td>\n",
       "      <td>5.712329</td>\n",
       "      <td>1.742627</td>\n",
       "      <td>5.712329</td>\n",
       "      <td>1.742627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>both</th>\n",
       "      <td>1</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>develop</th>\n",
       "      <td>1</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>becam</th>\n",
       "      <td>1</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>west</th>\n",
       "      <td>1</td>\n",
       "      <td>5.148148</td>\n",
       "      <td>1.638637</td>\n",
       "      <td>5.148148</td>\n",
       "      <td>1.638637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>1</td>\n",
       "      <td>5.024096</td>\n",
       "      <td>1.614246</td>\n",
       "      <td>5.024096</td>\n",
       "      <td>1.614246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>1</td>\n",
       "      <td>4.848837</td>\n",
       "      <td>1.578739</td>\n",
       "      <td>4.848837</td>\n",
       "      <td>1.578739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>2</td>\n",
       "      <td>2.329609</td>\n",
       "      <td>0.845700</td>\n",
       "      <td>4.659218</td>\n",
       "      <td>1.691401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refer</th>\n",
       "      <td>1</td>\n",
       "      <td>4.557377</td>\n",
       "      <td>1.516747</td>\n",
       "      <td>4.557377</td>\n",
       "      <td>1.516747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north</th>\n",
       "      <td>1</td>\n",
       "      <td>4.298969</td>\n",
       "      <td>1.458375</td>\n",
       "      <td>4.298969</td>\n",
       "      <td>1.458375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histori</th>\n",
       "      <td>1</td>\n",
       "      <td>4.212121</td>\n",
       "      <td>1.437966</td>\n",
       "      <td>4.212121</td>\n",
       "      <td>1.437966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>1</td>\n",
       "      <td>3.952607</td>\n",
       "      <td>1.374375</td>\n",
       "      <td>3.952607</td>\n",
       "      <td>1.374375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countri</th>\n",
       "      <td>1</td>\n",
       "      <td>3.808219</td>\n",
       "      <td>1.337162</td>\n",
       "      <td>3.808219</td>\n",
       "      <td>1.337162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>1</td>\n",
       "      <td>3.808219</td>\n",
       "      <td>1.337162</td>\n",
       "      <td>3.808219</td>\n",
       "      <td>1.337162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citi</th>\n",
       "      <td>1</td>\n",
       "      <td>3.626087</td>\n",
       "      <td>1.288154</td>\n",
       "      <td>3.626087</td>\n",
       "      <td>1.288154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "      <td>1</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.022451</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.022451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>known</th>\n",
       "      <td>1</td>\n",
       "      <td>2.542683</td>\n",
       "      <td>0.933220</td>\n",
       "      <td>2.542683</td>\n",
       "      <td>0.933220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq         idf    logidf         tfidf    logtfidf\n",
       "term                                                            \n",
       "codecerror    98  139.000000  4.934474  13622.000000  483.578445\n",
       "thi           42  139.000000  4.934474   5838.000000  207.247905\n",
       "thou          34  139.000000  4.934474   4726.000000  167.772114\n",
       "my            21  119.142857  4.780323   2502.000000  100.386788\n",
       "thee          18  139.000000  4.934474   2502.000000   88.820531\n",
       "prophet       12  139.000000  4.934474   1668.000000   59.213687\n",
       "me            12  139.000000  4.934474   1668.000000   59.213687\n",
       "we            21   75.818182  4.328338   1592.181818   90.895101\n",
       "uniti          9  139.000000  4.934474   1251.000000   44.410265\n",
       "fate           8  139.000000  4.934474   1112.000000   39.475791\n",
       "muhammad       8  139.000000  4.934474   1112.000000   39.475791\n",
       "decre          8  139.000000  4.934474   1112.000000   39.475791\n",
       "christ        10  104.250000  4.646792   1042.500000   46.467919\n",
       "verili         7  139.000000  4.934474    973.000000   34.541318\n",
       "heaven         6  139.000000  4.934474    834.000000   29.606844\n",
       "prais          6  139.000000  4.934474    834.000000   29.606844\n",
       "babel          6  139.000000  4.934474    834.000000   29.606844\n",
       "lord          15   55.600000  4.018183    834.000000   60.272748\n",
       "shall          6  139.000000  4.934474    834.000000   29.606844\n",
       "thine          6  139.000000  4.934474    834.000000   29.606844\n",
       "lamp           6  139.000000  4.934474    834.000000   29.606844\n",
       "tower          6  139.000000  4.934474    834.000000   29.606844\n",
       "revel          6  139.000000  4.934474    834.000000   29.606844\n",
       "will          24   30.888889  3.430397    741.333333   82.329517\n",
       "unto           5  139.000000  4.934474    695.000000   24.672370\n",
       "forth          5  139.000000  4.934474    695.000000   24.672370\n",
       "divin         10   69.500000  4.241327    695.000000   42.413268\n",
       "hath           5  139.000000  4.934474    695.000000   24.672370\n",
       "auxiliari      5  139.000000  4.934474    695.000000   24.672370\n",
       "grace          5  139.000000  4.934474    695.000000   24.672370\n",
       "...          ...         ...       ...           ...         ...\n",
       "high           1    8.257426  2.111113      8.257426    2.111113\n",
       "sea            1    8.176471  2.101261      8.176471    2.101261\n",
       "around         1    8.097087  2.091504      8.097087    2.091504\n",
       "land           1    7.380531  1.998846      7.380531    1.998846\n",
       "territori      1    7.252174  1.981301      7.252174    1.981301\n",
       "see            1    7.067797  1.955549      7.067797    1.955549\n",
       "popul          2    3.489540  1.249770      6.979079    2.499540\n",
       "born           1    6.950000  1.938742      6.950000    1.938742\n",
       "sever          1    6.619048  1.889951      6.619048    1.889951\n",
       "english        1    6.515625  1.874203      6.515625    1.874203\n",
       "earli          1    6.415385  1.858699      6.415385    1.858699\n",
       "after          2    3.100372  1.131522      6.200743    2.263044\n",
       "polit          1    6.000000  1.791759      6.000000    1.791759\n",
       "well           1    5.712329  1.742627      5.712329    1.742627\n",
       "both           1    5.180124  1.644829      5.180124    1.644829\n",
       "develop        1    5.180124  1.644829      5.180124    1.644829\n",
       "becam          1    5.180124  1.644829      5.180124    1.644829\n",
       "west           1    5.148148  1.638637      5.148148    1.638637\n",
       "region         1    5.024096  1.614246      5.024096    1.614246\n",
       "million        1    4.848837  1.578739      4.848837    1.578739\n",
       "state          2    2.329609  0.845700      4.659218    1.691401\n",
       "refer          1    4.557377  1.516747      4.557377    1.516747\n",
       "north          1    4.298969  1.458375      4.298969    1.458375\n",
       "histori        1    4.212121  1.437966      4.212121    1.437966\n",
       "over           1    3.952607  1.374375      3.952607    1.374375\n",
       "countri        1    3.808219  1.337162      3.808219    1.337162\n",
       "dure           1    3.808219  1.337162      3.808219    1.337162\n",
       "citi           1    3.626087  1.288154      3.626087    1.288154\n",
       "unit           1    2.780000  1.022451      2.780000    1.022451\n",
       "known          1    2.542683  0.933220      2.542683    0.933220\n",
       "\n",
       "[1195 rows x 5 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqit = freqit.sort_values(by='tfidf', ascending=False) \n",
    "freqit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'codecerror',\n",
       " u'you',\n",
       " 'we',\n",
       " u'yoga',\n",
       " u'your',\n",
       " u'mind',\n",
       " u'our',\n",
       " u'self',\n",
       " u'sutra',\n",
       " u'conscious']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startCount=0\n",
    "wordCount=10\n",
    "freqit.iloc[startCount:wordCount+startCount].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing a little exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not: 94\n",
      "when: 67\n",
      "so: 58\n",
      "onli: 28\n",
      "where: 28\n",
      "mani: 23\n",
      "then: 23\n",
      "good: 24\n",
      "more: 23\n",
      "back: 22\n"
     ]
    }
   ],
   "source": [
    "for word in loTest.keywords:\n",
    "    print(word + ': ' + str(freq[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%\n",
      "not: freq      262.000000\n",
      "idf       803.729008\n",
      "logidf      6.689262\n",
      "Name: not, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "when not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "so not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "onli not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "where: freq      390.000000\n",
      "idf       539.941026\n",
      "logidf      6.291460\n",
      "Name: where, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "mani: freq      103808.000000\n",
      "idf            2.028524\n",
      "logidf         0.707308\n",
      "Name: mani, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "then not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "good: freq      43387.000000\n",
      "idf           4.853458\n",
      "logidf        1.579692\n",
      "Name: good, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "more: freq      458.000000\n",
      "idf       459.775109\n",
      "logidf      6.130737\n",
      "Name: more, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "back: freq      61096.000000\n",
      "idf           3.446658\n",
      "logidf        1.237405\n",
      "Name: back, dtype: float64\n",
      "%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "for word in loTest.keywords:\n",
    "    try:\n",
    "        print('%%%%%%%%\\n' + word + ': ' + str(idf.ix[word]) + '\\n%%%%%%%%')\n",
    "    except:\n",
    "        print('%%%%%%%%\\n' + word + ' not found in IDF\\n%%%%%%%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vermin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>four</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mansion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>whose</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>accus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>under</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lord</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hedg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sway</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>worth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hatr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>everi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>newburgh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rise</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>govern</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>enslav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>scholar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>commonw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mancent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fritter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>probabl</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>diego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>diplomat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>jocist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>book</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>arama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>rememb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>varieti</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>u</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>monday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>uncomprehend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>class</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>june</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>stay</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>thoreau</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>quotat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>ghost</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>experienc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>atheist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>drbaker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>encycl</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>rule</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>syllabl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>influenc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>craft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>rural</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>decemb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>confess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  freq\n",
       "0                      5\n",
       "1           vermin     2\n",
       "2             four     7\n",
       "3          protest     1\n",
       "4            sleep     5\n",
       "5          mansion     2\n",
       "6           oldest     1\n",
       "7             hate     3\n",
       "8            whose     4\n",
       "9            accus     4\n",
       "10           under     5\n",
       "11            lord     6\n",
       "12            hedg     1\n",
       "13            sway     1\n",
       "14           worth     1\n",
       "15            hatr     2\n",
       "16           everi     3\n",
       "17        newburgh     1\n",
       "18            rise     2\n",
       "19            vase     1\n",
       "20           arous     1\n",
       "21          govern     3\n",
       "22          enslav     2\n",
       "23          school     2\n",
       "24         scholar     2\n",
       "25         commonw     1\n",
       "26         mancent     1\n",
       "27        straight     1\n",
       "28         fritter     1\n",
       "29           enjoy     3\n",
       "...            ...   ...\n",
       "2205       probabl     5\n",
       "2206         diego     1\n",
       "2207      diplomat     1\n",
       "2208        jocist     1\n",
       "2209        detail     1\n",
       "2210          book    18\n",
       "2211         arama     1\n",
       "2212        rememb     4\n",
       "2213       varieti     3\n",
       "2214             u     2\n",
       "2215        repeat     1\n",
       "2216        monday     1\n",
       "2217  uncomprehend     1\n",
       "2218         class     5\n",
       "2219          june     1\n",
       "2220          stay     7\n",
       "2221       thoreau     2\n",
       "2222        quotat     1\n",
       "2223         ghost     2\n",
       "2224     experienc     1\n",
       "2225       atheist     1\n",
       "2226       drbaker     1\n",
       "2227        encycl     8\n",
       "2228          rule     1\n",
       "2229       syllabl     1\n",
       "2230      influenc     2\n",
       "2231         craft     1\n",
       "2232         rural     5\n",
       "2233        decemb     1\n",
       "2234       confess     1\n",
       "\n",
       "[2235 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # term_frequency is a dict which structure is like:\n",
    "    # {\n",
    "    #     'path_to_file': \n",
    "    #         {'term': 13.4, 'another_term': 15}, \n",
    "    #     'another_file': \n",
    "    #         {'term2': 12, 'foo': 15}\n",
    "    #  } \n",
    "    for term in freq.keys():\n",
    "        if isintance(term_frequency[text], dict):\n",
    "            term_frequency[text][term] = freq[term]/numbers_of_words\n",
    "        else:\n",
    "            term_frequency[text] = {term: freq[term]/numbers_of_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#stemmer = nltk.stem.snowball.EnglishStemmer()\n",
    "#stemkeywords=[stemmer.stem(word) for word in loTest.keywords]\n",
    "#print(stemkeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%\n",
      "not\n",
      "{u'all': 2, u'distanc': 1, u'they': 2, u'just': 2, u'queen': 1, u'sage': 1, u'becaus': 3, u'violent': 1, u'go': 1, u'chair': 1, u'still': 1, u'find': 1, u'help': 1, u'fit': 1, u'readabl': 1, u'should': 2, 'to': 11, u'book': 1, u'factor': 1, u'sens': 2, u'delici': 1, u'has': 1, u'might': 1, u'real': 1, 'do': 3, u'good': 1, u'everi': 1, u'read': 2, u'dessert': 1, u'somebodi': 1, u'know': 1, u'codecerror': 11, u'veri': 1, u'one': 1, u'school': 1, u'anyth': 5, u'smell': 1, u'drop': 1, u'these': 1, u'bad': 2, u'contain': 1, u'plank': 1, u'enjoy': 1, u'the': 23, u'right': 2, u'mental': 1, u'natur': 1, u'mind': 3, u'realli': 1, u'see': 1, u'are': 16, u'seeabl': 1, u'cold': 1, u'infinit': 1, u'serv': 1, u'what': 1, u'said': 1, u'for': 3, u'bhagavad': 1, u'someth': 1, u'abl': 2, u'uniform': 1, u'doer': 1, u'experi': 1, 'be': 6, 'we': 3, u'who': 1, u'led': 1, u'isol': 1, u'here': 1, u'bodi': 3, u'ask': 1, u'eye': 1, u'come': 1, 'by': 2, u'faith': 2, 'of': 2, u'could': 1, u'vidyalayam': 1, u'thing': 1, u'outsid': 1, u'share': 1, 'or': 4, u'gita': 1, u'feel': 1, u'guidelin': 2, u'yourself': 1, u'open': 1, u'your': 5, u'use': 2, u'from': 2, u'log': 1, u'there': 5, u'happi': 2, u'start': 1, u'live': 1, u'way': 2, u'spring': 1, u'scope': 1, u'was': 1, u'that': 7, u'forc': 1, u'peopl': 2, u'but': 8, u'drown': 1, u'hear': 2, u'compani': 1, u'with': 2, u'eat': 2, 'he': 2, 'me': 1, u'made': 1, u'word': 1, u'look': 1, u'perceiv': 1, u'this': 3, u'work': 1, 'us': 1, u'can': 13, u'problem': 1, u'everyon': 1, u'expect': 2, u'and': 8, u'give': 2, u'certain': 1, 'is': 12, 'am': 2, 'it': 6, 'an': 1, u'say': 1, u'his': 1, u'exist': 2, 'at': 1, u'have': 4, 'in': 5, u'disappear': 1, 'if': 3, u'result': 1, u'selfish': 1, u'sit': 1, u'anoth': 1, u'when': 1, u'same': 4, u'intellect': 1, u'alway': 1, u'other': 1, u'rememb': 1, u'you': 19, u'simpl': 1, u'shall': 1, u'may': 1, u'object': 3, u'moment': 1, u'fruit': 1, u'whether': 1, u'water': 1, u'extern': 1, u'peac': 1, u'man': 1, 'a': 5, u'essenti': 1, 'i': 3, u'bind': 1, u'proud': 1, u'doe': 3, u'thought': 1, u'part': 1, u'adam': 1, u'allow': 1, u'everyth': 4}\n",
      "%%%%%\n",
      "good\n",
      "{u'and': 2, u'all': 1, u'have': 2, u'creat': 1, u'they': 1, u'feel': 1, u'natur': 1, 'is': 5, u'hard': 1, u'disciplin': 2, u'not': 1, 'as': 1, u'are': 4, u'want': 1, 'in': 1, u'proper': 1, u'home': 1, u'find': 1, u'might': 1, u'what': 3, u'nonsmok': 1, u'televis': 1, u'get': 1, u'yogi': 1, u'been': 1, 'to': 3, u'program': 1, u'call': 1, u'build': 1, u'environ': 1, u'you': 4, 'if': 1, u'codecerror': 3, u'noth': 1, 'do': 1, u'good': 2, u'that': 2, u'some': 1, u'after': 1, u'pave': 1, u'befor': 1, u'know': 1, u'satsang': 2, u'veri': 1, u'yoga': 1, u'compani': 9, u'grow': 1, u'those': 1, u'must': 1, 'a': 1, 'on': 2, u'join': 3, u'this': 1, 'of': 1, 'up': 1, u'charact': 3, u'will': 1, u'thing': 2, u'place': 1, u'the': 11, u'manner': 2}\n",
      "%%%%%\n",
      "then\n",
      "{u'and': 7, u'codecerror': 1, u'guidelin': 1, 'is': 4, u'becaus': 1, u'yourself': 2, u'alway': 1, 'as': 1, u'are': 4, u'tabl': 2, u'ship': 1, u'yes': 1, u'even': 1, u'decid': 1, u'ash': 1, u'depend': 1, u'guest': 1, u'suprem': 1, 'to': 1, u'relax': 1, u'sometim': 1, u'been': 1, u'plank': 3, u'their': 1, u'wood': 3, u'call': 1, u'sens': 1, u'you': 4, u'immedi': 1, u'until': 1, 'be': 1, u'finish': 1, u'see': 1, u'though': 2, u'may': 1, u'tree': 1, u'time': 1, u'piec': 1, 'it': 2, u'how': 1, u'chair': 1, u'made': 1, u'they': 1, u'delici': 1, u'now': 1, u'burnt': 1, u'the': 9, u'log': 2, 'a': 1, u'experi': 1, u'practic': 1, u'never': 1, u'conscious': 1, u'whether': 1, 'of': 3, u'into': 1, u'sit': 1, u'alon': 1, u'remain': 2, 'us': 1, u'benefit': 1, u'were': 1, u'chang': 1, u'principl': 1, 'my': 1, 'or': 1, u'for': 1}\n",
      "%%%%%\n",
      "even\n",
      "{u'blind': 1, u'vedanta': 1, u'all': 1, u'help': 1, 'be': 1, u'give': 2, u'natur': 1, 'it': 2, u'down': 1, u'perpetu': 1, u'dazzl': 1, u'want': 1, 'in': 5, u'go': 1, u'our': 1, u'ship': 1, u'faith': 1, u'your': 3, 'if': 2, u'awar': 1, u'use': 1, u'spiritu': 1, u'daytoday': 1, u'with': 1, u'sometim': 1, u'littl': 1, 'to': 2, u'again': 1, u'seeker': 1, u'lot': 1, u'you': 3, u'codecerror': 1, u'more': 1, u'then': 1, u'them': 1, u'which': 1, u'though': 3, u'may': 1, u'shallow': 2, u'here': 1, u'hand': 1, u'water': 2, u'fruit': 1, u'they': 1, u'compani': 1, u'nobodi': 1, u'effort': 1, u'longer': 1, 'a': 3, u'also': 1, u'room': 1, u'anyth': 1, u'this': 1, 'of': 1, u'bother': 1, 'no': 1, 'up': 1, 'or': 1, u'will': 3, u'without': 1, u'grain': 1, u'smoke': 1, u'push': 1, u'field': 1, u'the': 3, u'think': 1, u'daili': 1, 'at': 1}\n",
      "%%%%%\n",
      "when\n",
      "{u'and': 2, u'old': 1, u'help': 1, u'activ': 1, 'is': 4, u'emot': 1, u'one': 2, u'say': 1, u'are': 3, u'slip': 1, 'in': 1, 'go': 1, u'forget': 1, u'your': 2, u'stage': 1, u'fill': 1, u'selfish': 1, u'onli': 2, u'ear': 1, u'built': 1, u'daytoday': 1, u'someth': 2, u'there': 1, u'seat': 1, u'young': 1, u'eat': 1, 'to': 2, u'other': 2, u'analyz': 1, u'you': 10, u'deafen': 1, u'codecerror': 2, 'be': 1, u'that': 2, u'forc': 1, u'absorb': 1, u'never': 1, u'reach': 1, u'use': 1, u'but': 1, u'bodi': 1, u'know': 1, u'they': 1, u'not': 1, u'affect': 1, u'now': 1, u'with': 1, u'day': 1, u'like': 1, 'on': 1, u'went': 1, u'avoid': 1, 'i': 2, 'of': 1, u'thing': 1, u'each': 1, u'the': 2, u'think': 1, u'expect': 1}\n",
      "%%%%%\n",
      "so\n",
      "{u'our': 2, u'and': 1, u'all': 1, u'they': 3, 'be': 1, u'feel': 1, u'guidelin': 1, 'is': 2, 'in': 2, u'mind': 1, u'becaus': 1, u'capac': 1, u'see': 1, u'are': 5, u'want': 1, u'someth': 1, u'seen': 1, u'your': 1, 'as': 2, 'if': 1, u'caus': 1, u'differ': 1, u'said': 1, u'end': 1, 'i': 1, u'also': 1, u'section': 1, u'there': 2, u'bowl': 1, u'thank': 1, u'long': 1, u'should': 1, 'to': 6, u'other': 1, u'health': 1, u'too': 1, u'natur': 2, u'sens': 1, u'you': 5, u'man': 1, u'gave': 1, 'do': 3, 'we': 1, u'his': 1, u'return': 1, u'truth': 1, u'that': 4, u'mess': 1, u'peopl': 1, u'who': 1, u'watch': 1, u'hand': 1, u'vomit': 1, u'codecerror': 2, u'share': 1, u'shun': 1, u'compani': 1, u'with': 1, u'chang': 1, u'physic': 1, u'must': 1, 'a': 2, u'experienc': 1, u'this': 1, 'of': 1, 'up': 1, u'separ': 1, u'collect': 1, u'achiev': 1, u'can': 1, u'smoke': 1, u'mani': 1, u'the': 5, u'purpos': 1, 'or': 1, u'say': 1}\n",
      "%%%%%\n",
      "here\n",
      "{u'and': 3, u'old': 1, u'guidelin': 2, u'over': 1, 'it': 1, u'born': 2, 'as': 2, u'are': 2, u'have': 1, 'in': 3, u'our': 1, u'your': 1, u'communiti': 1, 'if': 2, u'even': 1, u'yogavill': 2, u'harmoni': 1, 'no': 2, u'ruin': 1, u'littl': 1, u'should': 1, 'to': 1, u'live': 1, u'you': 5, u'main': 1, 'is': 2, u'more': 1, 'be': 4, u'vibrat': 1, u'that': 1, u'shallow': 1, u'but': 1, u'codecerror': 3, u'refin': 1, u'not': 1, u'come': 2, 'by': 1, 'a': 1, 'i': 1, 'of': 2, u'benefit': 1, u'follow': 3, u'can': 1, u'wild': 1, u'mani': 1, u'the': 6, u'purpos': 1, u'similar': 1}\n",
      "%%%%%\n",
      "other\n",
      "{u'and': 2, u'right': 1, u'help': 2, u'ten': 1, u'speci': 1, 'is': 1, u'share': 1, u'becaus': 1, u'one': 2, u'offer': 1, u'kill': 1, u'are': 3, u'slip': 1, u'find': 1, 'if': 1, u'said': 1, u'group': 1, u'appear': 1, u'for': 1, u'also': 1, u'with': 1, u'there': 2, u'when': 2, u'same': 1, u'should': 1, 'to': 4, u'live': 1, u'chamber': 1, 'it': 2, 'so': 1, u'you': 2, u'codecerror': 1, 'be': 1, 'we': 1, u'that': 1, u'may': 1, u'peopl': 1, u'innermost': 1, u'hand': 3, u'somebodi': 1, u'togeth': 2, u'they': 3, u'not': 1, u'from': 2, 'on': 4, u'come': 1, u'peac': 1, u'gregorian': 1, 'a': 2, u'pull': 1, u'protect': 1, u'lead': 1, u'chant': 1, 'no': 1, u'well': 1, 'as': 1, u'know': 1, u'thing': 1, u'environ': 1, u'can': 2, u'each': 4, 'at': 1, u'the': 10, u'view': 2, u'silver': 1, u'ourselv': 1}\n",
      "%%%%%\n",
      "also\n",
      "{u'and': 2, u'natur': 1, 'is': 1, u'accord': 1, u'annihil': 1, u'are': 4, u'children': 1, u'even': 1, u'spiritu': 2, u'realm': 1, u'for': 1, 'to': 1, u'highest': 1, u'there': 1, u'same': 1, u'field': 1, u'book': 1, u'you': 2, u'experi': 2, 'we': 2, u'truth': 1, u'that': 2, u'but': 1, u'bodi': 1, u'part': 1, u'know': 1, u'ash': 1, u'ident': 1, 'of': 1, 'so': 1, u'can': 3, u'though': 1, u'the': 9, u'other': 1, u'adult': 1}\n",
      "%%%%%\n",
      "differ\n",
      "{u'and': 3, u'all': 1, u'identifi': 1, u'feel': 1, 'is': 3, u'mind': 1, u'are': 3, u'have': 2, 'in': 2, u'total': 1, u'your': 3, u'given': 1, u'from': 2, u'etc': 1, u'there': 2, u'capac': 2, 'to': 2, u'seeker': 1, u'suppos': 1, u'suit': 1, u'got': 2, u'you': 2, u'therefor': 1, u'method': 1, u'real': 1, u'that': 3, u'peopl': 3, u'men': 2, u'differ': 2, u'but': 1, u'bodi': 2, u'reason': 1, u'understand': 1, u'know': 1, u'codecerror': 1, u'such': 1, 'by': 1, u'present': 1, 'a': 1, u'these': 1, 'of': 6, u'facet': 1, 'i': 1, 'so': 1, u'she': 1, u'abov': 1, u'grasp': 1, u'opinion': 1, u'the': 5, u'view': 1}\n",
      "{u'respond': 2, u'faith': 1, u'ultim': 1, 'is': 1, 'to': 2, u'codecerror': 1, u'the': 3, u'essenc': 1}\n"
     ]
    }
   ],
   "source": [
    "for key in loTest.keywords: ### get context vectors for keywords...\n",
    "    print('%%%%%\\n' + key)\n",
    "    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n",
    "#print(loTest.cocoDict['spiritual'])\n",
    "print(loTest.cocoDict['spirit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for key in stemkeywords: ### get context vectors for keywords...\n",
    "#    print('%%%%%\\n' + key)\n",
    "#    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in loTest.keywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "#    if 'spirtual' in filetokens:\n",
    "#        print(\"UAL!\")\n",
    "#    if 'spirit' in filetokens:\n",
    "#        print(\"SPIRIT!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## STEM keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in stemkeywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.cvWindow: 3\n",
      "%%%%\n",
      "cvDict, length 4\n",
      "---the first ten keys:\n",
      "['./data_dsicap/IntegralYoga/raw/YV58.txt', './data_dsicap/IntegralYoga/raw/YV48.txt', './data_dsicap/IntegralYoga/raw/YV54.txt', './data_dsicap/IntegralYoga/raw/YV05.txt']\n",
      "---the keywords each file:\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt: [u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "%%%%%%%\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 5 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 10 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "---------length of thisfile[then][7]: 50\n",
      "---------length of thisfile[then][8]: 50\n",
      "---------length of thisfile[then][9]: 50\n",
      "---------length of thisfile[then][10]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 9 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "---------length of thisfile[differ][6]: 50\n",
      "---------length of thisfile[differ][7]: 50\n",
      "---------length of thisfile[differ][8]: 50\n",
      "---------length of thisfile[differ][9]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 3 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 5 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "---------length of thisfile[also][3]: 50\n",
      "---------length of thisfile[also][4]: 50\n",
      "---------length of thisfile[also][5]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 4 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 6 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 24 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n",
      "---------length of thisfile[not][21]: 50\n",
      "---------length of thisfile[not][22]: 50\n",
      "---------length of thisfile[not][23]: 50\n",
      "---------length of thisfile[not][24]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 1 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 5 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 4 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 2 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 11 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt (5 keys):\n",
      "---keys: [u'not', u'even', u'when', u'other', 'so']\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 8 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 1 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 3 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt (9 keys):\n",
      "---keys: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 8 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "---------length of thisfile[even][6]: 50\n",
      "---------length of thisfile[even][7]: 50\n",
      "---------length of thisfile[even][8]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 6 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "------thisfile[good]:\n",
      "-------length: \"good\" appears 18 times in this file.\n",
      "---------length of thisfile[good][1]: 50\n",
      "---------length of thisfile[good][2]: 50\n",
      "---------length of thisfile[good][3]: 50\n",
      "---------length of thisfile[good][4]: 50\n",
      "---------length of thisfile[good][5]: 50\n",
      "---------length of thisfile[good][6]: 50\n",
      "---------length of thisfile[good][7]: 50\n",
      "---------length of thisfile[good][8]: 50\n",
      "---------length of thisfile[good][9]: 50\n",
      "---------length of thisfile[good][10]: 50\n",
      "---------length of thisfile[good][11]: 50\n",
      "---------length of thisfile[good][12]: 50\n",
      "---------length of thisfile[good][13]: 50\n",
      "---------length of thisfile[good][14]: 50\n",
      "---------length of thisfile[good][15]: 50\n",
      "---------length of thisfile[good][16]: 50\n",
      "---------length of thisfile[good][17]: 50\n",
      "---------length of thisfile[good][18]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 6 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "---------length of thisfile[when][5]: 50\n",
      "---------length of thisfile[when][6]: 50\n",
      "------thisfile[here]:\n",
      "-------length: \"here\" appears 13 times in this file.\n",
      "---------length of thisfile[here][1]: 50\n",
      "---------length of thisfile[here][2]: 50\n",
      "---------length of thisfile[here][3]: 50\n",
      "---------length of thisfile[here][4]: 50\n",
      "---------length of thisfile[here][5]: 50\n",
      "---------length of thisfile[here][6]: 50\n",
      "---------length of thisfile[here][7]: 50\n",
      "---------length of thisfile[here][8]: 50\n",
      "---------length of thisfile[here][9]: 50\n",
      "---------length of thisfile[here][10]: 50\n",
      "---------length of thisfile[here][11]: 50\n",
      "---------length of thisfile[here][12]: 50\n",
      "---------length of thisfile[here][13]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 8 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "---------length of thisfile[other][5]: 50\n",
      "---------length of thisfile[other][6]: 50\n",
      "---------length of thisfile[other][7]: 50\n",
      "---------length of thisfile[other][8]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 8 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "---------length of thisfile[so][7]: 50\n",
      "---------length of thisfile[so][8]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 20 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n"
     ]
    }
   ],
   "source": [
    "#######################            \n",
    "###Semantic analysis###\n",
    "#######################\n",
    "\n",
    "#Get context vectors\n",
    "loTest.getContextVectors(cvWindow)\n",
    "print('loTest.cvWindow: ' + str(loTest.cvWindow))\n",
    "\n",
    "#        self.cvWindow=k\n",
    "#        self.cvDict={}\n",
    "\n",
    "print('%%%%\\ncvDict, length ' + str(len(loTest.cvDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cvDict.keys()[:10])\n",
    "print('---the keywords each file:')\n",
    "for key in loTest.cvDict.keys():\n",
    "    print(key + ': ' + str(loTest.cvDict[key].keys()))\n",
    "print('%%%%%%%')\n",
    "#file1 = loTest.cvDict.keys()[0] #'./data_dsicap/IntegralYoga/raw/YV38.txt'\n",
    "    \n",
    "for file1 in loTest.cvDict.keys():    \n",
    "    first = loTest.cvDict[file1]\n",
    "    #print('---the first entry (length ' + str(len(first[first.keys()[0]])) + '):')\n",
    "    print('%%%%%\\n' + file1 + ' (' + str(len(first.keys())) + ' keys):')\n",
    "    print('---keys: ' + str(first.keys()))\n",
    "    for wordkey in first.keys():\n",
    "        print('------thisfile[' + wordkey + ']:')\n",
    "        tftk = first[wordkey]\n",
    "        print('-------length: \"' + wordkey + '\" appears ' + str(len(tftk.keys())) + ' times in this file.')\n",
    "        for numkey in tftk.keys():\n",
    "            print('---------length of thisfile[' + wordkey +'][' + str(numkey) + ']: ' + str(len(tftk[numkey])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "[u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "[u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "10\n",
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n",
      "[0.72404735956380151, 0.70700627327625354, 0.71615225785121706, 0.69572043045266363, 0.75862725558225175, 0.72200533701172254, 0.75878819429898337, 0.67993472478851136, 0.77246014024129339, 0.76795665602778718]\n"
     ]
    }
   ],
   "source": [
    "#Get average semantic density\n",
    "#avgSD=np.mean([x[1] for x in loTest.getSD(simCount)])\n",
    "#print(avgSD)\n",
    "\n",
    "SD = [x[1] for x in loTest.getSD(simCount)]\n",
    "print(len(SD))\n",
    "print(loTest.keywords)\n",
    "print(SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "###POS Tagging and Judgement Analysis###\n",
    "########################################\n",
    "judgementAvg=list(np.mean(np.array([[x[1],x[2]] for x in loTest.getJudgements()]),axis=0))\n",
    "\n",
    "########################\n",
    "###Sentiment Analysis###\n",
    "########################\n",
    "\n",
    "sentimentList=loTest.sentimentLookup()\n",
    "\n",
    "############################\n",
    "###Network Quantification###\n",
    "############################\n",
    "loTest.setNetwork(netAngle)\n",
    "\n",
    "avgEVC=loTest.evc()\n",
    "\n",
    "endTime=time.time()\n",
    "timeRun=endTime-startTime\n",
    "print('finished running'+'_'.join(groupId)+' in '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#Append outputs to masterOutput\n",
    "return(['_'.join(groupId)]+[len(subFileList),timeRun]+sentimentList+judgementAvg+[avgSD]+[avgEVC])   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
