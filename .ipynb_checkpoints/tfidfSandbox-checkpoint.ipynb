{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "2016-10-30 10:12:47.634287\n",
      "finished loading packages after 3.01520800591 seconds\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul 19 16:14:43 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun  2 15:23:11 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "import time\n",
    "start=time.time()\n",
    "import sys, os\n",
    "\n",
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017')\n",
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing as mp\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "sys.path.append('./prototype_python/')\n",
    "#import lingual as la\n",
    "import lingualPrinting as la\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "#sys.stdout = open(\"output.txt\", \"a\")\n",
    "print(str(datetime.now()))\n",
    "print('finished loading packages after '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#\n",
    "import getNewDocs as gnd\n",
    "\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "41\n",
      "[['DorothyDay', 'test0'], ['DorothyDay', 'test3'], ['Bahai', 'test4'], ['DorothyDay', 'test2'], ['Bahai', 'test5'], ['DorothyDay', 'test5'], ['Bahai', 'test6'], ['DorothyDay', 'test4'], ['Bahai', 'test7'], ['DorothyDay', 'test7'], ['Bahai', 'test0'], ['DorothyDay', 'test6'], ['Bahai', 'test1'], ['Bahai', 'test2'], ['DorothyDay', 'test8'], ['Bahai', 'test8'], ['Bahai', 'test3'], ['Bahai', 'test9'], ['DorothyDay', 'test1']]\n",
      "%%%%%\n",
      "length of subgroupList is 19\n"
     ]
    }
   ],
   "source": [
    "fileDF=gnd.newDocsToDF('./data_dsicap/', bin=5) ################################### WHERE THE NEW FILES ARE\n",
    "\n",
    "fileList=fileDF.values.tolist()\n",
    "\n",
    "fileList=[[fileList[i][0],fileList[i][1],fileList[i][2]] for i in range(len(fileList))]\n",
    "\n",
    "\n",
    "#Get set of subgroups\n",
    "subgroupList=[ list(y) for y in set((x[0],x[2]) for x in fileList) ]\n",
    "print(subgroupList)\n",
    "print('%%%%%\\nlength of subgroupList is ' + str(len(subgroupList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawPath = './data_dsicap/' ###############change this eventually\n",
    "runDirectory='./modelOutput/'\n",
    "#groupList=['DorothyDay','JohnPiper','MehrBaba','NaumanKhan','PastorAnderson',\n",
    "#   'Rabbinic','Shepherd','Unitarian','WBC']\n",
    "#groupList=['DorothyDay','NaumanKhan','Rabbinic','NawDawg','SeaShepherds','IntegralYoga','Bahai']\n",
    "#cocoWindow=int(sys.argv[1])\n",
    "#cvWindow=int(sys.argv[2])\n",
    "#startCount=int(sys.argv[3])\n",
    "#netAngle=int(sys.argv[4])\n",
    "cocoWindow=3\n",
    "cvWindow=3\n",
    "startCount=0\n",
    "netAngle=30\n",
    "groupSize=10\n",
    "#testSplit=.3\n",
    "targetWordCount=10\n",
    "svdInt=50\n",
    "simCount=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "#Create paramList\n",
    "paramList=[[x,fileList,targetWordCount,cocoWindow,svdInt,cvWindow,simCount,startCount,netAngle] for x in subgroupList]\n",
    "print(len(paramList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run calculation \n",
    "#masterOutput=[textAnalysis(x) for x in paramList]  ### INSTEAD OF THIS, WE MAKE THE OBJECT\n",
    "paramPick = paramList[0] ### instead of looping through, we just pick one\n",
    "#print(paramPick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DorothyDay', 'test0']\n"
     ]
    }
   ],
   "source": [
    "#def textAnalysis(paramPick):\n",
    "startTime=time.time()\n",
    "groupId=paramPick[0]\n",
    "fileList=paramPick[1]\n",
    "targetWordCount=paramPick[2]\n",
    "cocoWindow=paramPick[3]\n",
    "svdInt=paramPick[4]\n",
    "cvWindow=paramPick[5]\n",
    "simCount=paramPick[6]\n",
    "startCount=paramPick[7]\n",
    "netAngle=paramPick[8]    \n",
    "\n",
    "print(groupId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['./data_dsicap/DorothyDay/raw/146.html.txt', './data_dsicap/DorothyDay/raw/151.html.txt', './data_dsicap/DorothyDay/raw/154.html.txt', './data_dsicap/DorothyDay/raw/167.html.txt', './data_dsicap/DorothyDay/raw/5.html.txt']\n"
     ]
    }
   ],
   "source": [
    "#Get list of subfiles\n",
    "subFileList=[x[1] for x in fileList if x[0]==groupId[0] and x[2]==groupId[1]]\n",
    "print(len(subFileList))\n",
    "print(subFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#Create lingual object\n",
    "loTest=la.lingualObject(subFileList)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LOOK AT LIST OF TOKENS FOR FILE\n",
    "#print(subFileList[0])\n",
    "#loTest.tokens[subFileList[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%\n",
      "cocoDict, length 2235\n",
      "---the first ten keys:\n",
      "['', u'vermin', u'four', u'protest', u'sleep', u'mansion', u'oldest', u'hate', u'whose', u'accus']\n",
      "---the first entry:\n",
      "\n",
      "{u'work': 1, u'tri': 1, 'is': 2, 'it': 1, u'still': 1, u'poem': 1, u'from': 1, u'there': 1, u'wherein': 1, u'sic': 1, 'to': 1, u'includ': 1, u'rememb': 1, u'you': 1, u'was': 1, 'do': 1, u'that': 1, u'worker': 1, u'beast': 1, 'a': 1, u'not': 1, 'me': 1, u'short': 1, u'justic': 1, u'cathol': 1, u'keep': 1, u'dwelleth': 1}\n"
     ]
    }
   ],
   "source": [
    "#Get coco\n",
    "loTest.getCoco(cocoWindow)\n",
    "\n",
    "#        self.cocoWindow=k\n",
    "#        self.cocoDict={}\n",
    "#        self.TF={}\n",
    "#        self.docTF={}\n",
    "\n",
    "print('%%%%\\ncocoDict, length ' + str(len(loTest.cocoDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cocoDict.keys()[:10])\n",
    "print('---the first entry:')\n",
    "key1 = loTest.cocoDict.keys()[0]\n",
    "print(key1)\n",
    "print(loTest.cocoDict[key1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.svdK: 50\n",
      "%%%%\n",
      "DSM, length 2235\n",
      "---the first ten keys:\n",
      "['', u'hatr', u'four', u'protest', u'sleep', u'mansion', u'oldest', u'hate', u'whose', u'accus']\n",
      "---the first entry:\n",
      "{0: 1.3731796726725851, 1: -0.46637495596425738, 2: 1.8863327235061298, 3: 0.5941415478936819, 4: -0.48213000021201424, 5: -1.0167722820931586, 6: -0.034310482823596375, 7: -0.37754599470448774, 8: 1.1842163879555685, 9: 0.089813369246233746, 10: -0.1546425865604717, 11: -0.067089097283259055, 12: 0.82117831290686483, 13: -0.17501254377988504, 14: -0.46943998551711869, 15: -0.63380230180748298, 16: 0.54609116287146597, 17: 0.050816767336322725, 18: -0.11587949763219284, 19: -0.18701507823391003, 20: 0.40055329805830026, 21: 0.39597198974961373, 22: 0.38801644694417831, 23: 0.20137122408184191, 24: 0.15102204576769784, 25: -0.43794010630723534, 26: -0.43811827203013987, 27: -0.15324019653063628, 28: 0.11070887993875991, 29: -0.28020982831192931, 30: -0.52460898421355806, 31: 0.1813512821329136, 32: 0.02532182667046631, 33: -0.13219259693838598, 34: -0.36691711419975293, 35: -0.48858364387222808, 36: -0.055108350213995058, 37: 0.38691769041138802, 38: 0.8028374981996006, 39: 0.0067398263684728182, 40: 0.29509604761969732, 41: -0.34981515227273829, 42: -0.14939468487810037, 43: 0.66858928619066083, 44: -0.13058073649694535, 45: -0.061927910452663618, 46: -0.2027604648549684, 47: 0.20535003022696047, 48: -0.36224739296633029, 49: 0.34584286804443276}\n"
     ]
    }
   ],
   "source": [
    "#Get DSM\n",
    "loTest.getDSM(svdInt)\n",
    "print('loTest.svdK: ' + str(loTest.svdK))\n",
    "\n",
    "print('%%%%\\nDSM, length ' + str(len(loTest.DSM)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.DSM.keys()[:10])\n",
    "print('---the first entry:')\n",
    "print(loTest.DSM[loTest.DSM.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'not', u'when', 'so', u'onli', u'where', u'mani', u'then', u'good', u'more', u'back']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./prototype_python/lingualPrinting.py:472: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  targetDF.sort(['count'],inplace=True,ascending=False)\n"
     ]
    }
   ],
   "source": [
    "#Set keywords\n",
    "loTest.setKeywords('adjAdv',targetWordCount,startCount)\n",
    "print(loTest.keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>½inch</td>\n",
       "      <td>30</td>\n",
       "      <td>7019.233333</td>\n",
       "      <td>8.856409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¼inch</td>\n",
       "      <td>30</td>\n",
       "      <td>7019.233333</td>\n",
       "      <td>8.856409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>892</td>\n",
       "      <td>236.072870</td>\n",
       "      <td>5.464141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaa</td>\n",
       "      <td>75</td>\n",
       "      <td>2807.693333</td>\n",
       "      <td>7.940119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaa</td>\n",
       "      <td>26</td>\n",
       "      <td>8099.115385</td>\n",
       "      <td>8.999510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    term  freq          idf    logidf\n",
       "0  ½inch    30  7019.233333  8.856409\n",
       "1  ¼inch    30  7019.233333  8.856409\n",
       "2    aaa   892   236.072870  5.464141\n",
       "3   aaaa    75  2807.693333  7.940119\n",
       "4  aaaaa    26  8099.115385  8.999510"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfFile = 'IDF-210kNS20.csv'\n",
    "idf = pd.read_csv('./pythonOutput/' + idfFile)\n",
    "idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>123769.000000</td>\n",
       "      <td>123769.000000</td>\n",
       "      <td>123769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>673.278535</td>\n",
       "      <td>4462.480517</td>\n",
       "      <td>7.835587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3940.258476</td>\n",
       "      <td>3272.555451</td>\n",
       "      <td>1.451800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.015264</td>\n",
       "      <td>0.700750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>1442.308219</td>\n",
       "      <td>7.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>4049.557692</td>\n",
       "      <td>8.306363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>146.000000</td>\n",
       "      <td>7261.275862</td>\n",
       "      <td>8.890311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104491.000000</td>\n",
       "      <td>10528.850000</td>\n",
       "      <td>9.261874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                freq            idf         logidf\n",
       "count  123769.000000  123769.000000  123769.000000\n",
       "mean      673.278535    4462.480517       7.835587\n",
       "std      3940.258476    3272.555451       1.451800\n",
       "min        20.000000       2.015264       0.700750\n",
       "25%        29.000000    1442.308219       7.274000\n",
       "50%        52.000000    4049.557692       8.306363\n",
       "75%       146.000000    7261.275862       8.890311\n",
       "max    104491.000000   10528.850000       9.261874"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#idf.ix[loTest.keywords[0]]\n",
    "#loTest.keywords[0]\n",
    "idf = idf.set_index('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freq        85.000000\n",
       "idf       2477.376471\n",
       "logidf       7.814955\n",
       "Name: aaliyah, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf.head()\n",
    "idf.ix['aaliyah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freq      262.000000\n",
       "idf       803.729008\n",
       "logidf      6.689262\n",
       "Name: not, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loTest.keywords[0])\n",
    "idf.ix[loTest.keywords[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loTest.rawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13451"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "#[all_words + toke for toke in loTest.tokens.values()]\n",
    "for toke in loTest.tokens.values():\n",
    "    all_words = all_words + toke\n",
    "\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vermin</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protest</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq\n",
       "term         \n",
       "            5\n",
       "vermin      2\n",
       "four        7\n",
       "protest     1\n",
       "sleep       5"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "freq = FreqDist(all_words) ## create FreqDist object with word frequencies\n",
    "#\n",
    "columns_obj = [\"term\", \"freq\"]\n",
    "freqDF = pd.DataFrame(freq.items(), columns=columns_obj) # convert it to a data frame\n",
    "freqDF = freqDF.set_index('term')\n",
    "freqDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqDF (2235, 1)\n",
      "freqit (2235, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vermin</th>\n",
       "      <td>2</td>\n",
       "      <td>1096.755208</td>\n",
       "      <td>7.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>7</td>\n",
       "      <td>3.120260</td>\n",
       "      <td>1.137916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protest</th>\n",
       "      <td>1</td>\n",
       "      <td>13.130698</td>\n",
       "      <td>2.574953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>5</td>\n",
       "      <td>30.826673</td>\n",
       "      <td>3.428380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq          idf    logidf\n",
       "term                                \n",
       "            5          NaN       NaN\n",
       "vermin      2  1096.755208  7.000111\n",
       "four        7     3.120260  1.137916\n",
       "protest     1    13.130698  2.574953\n",
       "sleep       5    30.826673  3.428380"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freqit = pd.concat([freqDF, idf])\n",
    "freqit = freqDF.join(idf[['idf', 'logidf']])\n",
    "print('freqDF ' + str(freqDF.shape))\n",
    "print('freqit ' + str(freqit.shape))\n",
    "freqit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqit['tfidf'] = freqit['freq'] * freqit['idf']\n",
    "freqit['logtfidf'] = freqit['freq'] * freqit['logidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#freqit = freqit.dropna(subset=['freq'], how='all')\n",
    "#freqit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>logtfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>525</td>\n",
       "      <td>2568.012195</td>\n",
       "      <td>7.850887</td>\n",
       "      <td>1.348206e+06</td>\n",
       "      <td>4121.715892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>101</td>\n",
       "      <td>6792.806452</td>\n",
       "      <td>8.823619</td>\n",
       "      <td>6.860735e+05</td>\n",
       "      <td>891.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>136</td>\n",
       "      <td>3630.637931</td>\n",
       "      <td>8.197164</td>\n",
       "      <td>4.937668e+05</td>\n",
       "      <td>1114.814256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>34</td>\n",
       "      <td>8423.080000</td>\n",
       "      <td>9.038731</td>\n",
       "      <td>2.863847e+05</td>\n",
       "      <td>307.316848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>74</td>\n",
       "      <td>2105.770000</td>\n",
       "      <td>7.652436</td>\n",
       "      <td>1.558270e+05</td>\n",
       "      <td>566.280299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>75</td>\n",
       "      <td>2005.495238</td>\n",
       "      <td>7.603646</td>\n",
       "      <td>1.504121e+05</td>\n",
       "      <td>570.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>19</td>\n",
       "      <td>6792.806452</td>\n",
       "      <td>8.823619</td>\n",
       "      <td>1.290633e+05</td>\n",
       "      <td>167.648770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onc</th>\n",
       "      <td>17</td>\n",
       "      <td>7261.275862</td>\n",
       "      <td>8.890311</td>\n",
       "      <td>1.234417e+05</td>\n",
       "      <td>151.135284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>14</td>\n",
       "      <td>8774.041667</td>\n",
       "      <td>9.079553</td>\n",
       "      <td>1.228366e+05</td>\n",
       "      <td>127.113740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <td>14</td>\n",
       "      <td>8099.115385</td>\n",
       "      <td>8.999510</td>\n",
       "      <td>1.133876e+05</td>\n",
       "      <td>125.993142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>been</th>\n",
       "      <td>23</td>\n",
       "      <td>4785.840909</td>\n",
       "      <td>8.473417</td>\n",
       "      <td>1.100743e+05</td>\n",
       "      <td>194.888592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>22</td>\n",
       "      <td>4049.557692</td>\n",
       "      <td>8.306363</td>\n",
       "      <td>8.909027e+04</td>\n",
       "      <td>182.739985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>94</td>\n",
       "      <td>803.729008</td>\n",
       "      <td>6.689262</td>\n",
       "      <td>7.555053e+04</td>\n",
       "      <td>628.790643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>while</th>\n",
       "      <td>7</td>\n",
       "      <td>9571.681818</td>\n",
       "      <td>9.166564</td>\n",
       "      <td>6.700177e+04</td>\n",
       "      <td>64.165949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>112</td>\n",
       "      <td>569.127027</td>\n",
       "      <td>6.344104</td>\n",
       "      <td>6.374223e+04</td>\n",
       "      <td>710.539609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>7</td>\n",
       "      <td>8423.080000</td>\n",
       "      <td>9.038731</td>\n",
       "      <td>5.896156e+04</td>\n",
       "      <td>63.271116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>novena</th>\n",
       "      <td>14</td>\n",
       "      <td>3569.101695</td>\n",
       "      <td>8.180069</td>\n",
       "      <td>4.996742e+04</td>\n",
       "      <td>114.520969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between</th>\n",
       "      <td>5</td>\n",
       "      <td>9571.681818</td>\n",
       "      <td>9.166564</td>\n",
       "      <td>4.785841e+04</td>\n",
       "      <td>45.832821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veri</th>\n",
       "      <td>10</td>\n",
       "      <td>4577.760870</td>\n",
       "      <td>8.428965</td>\n",
       "      <td>4.577761e+04</td>\n",
       "      <td>84.289653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>38</td>\n",
       "      <td>997.995261</td>\n",
       "      <td>6.905749</td>\n",
       "      <td>3.792382e+04</td>\n",
       "      <td>262.418444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antigonish</th>\n",
       "      <td>7</td>\n",
       "      <td>4577.760870</td>\n",
       "      <td>8.428965</td>\n",
       "      <td>3.204433e+04</td>\n",
       "      <td>59.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>same</th>\n",
       "      <td>11</td>\n",
       "      <td>2420.425287</td>\n",
       "      <td>7.791699</td>\n",
       "      <td>2.662468e+04</td>\n",
       "      <td>85.708684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>59</td>\n",
       "      <td>346.343750</td>\n",
       "      <td>5.847432</td>\n",
       "      <td>2.043428e+04</td>\n",
       "      <td>344.998475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyo</th>\n",
       "      <td>2</td>\n",
       "      <td>10027.476190</td>\n",
       "      <td>9.213084</td>\n",
       "      <td>2.005495e+04</td>\n",
       "      <td>18.426168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actu</th>\n",
       "      <td>2</td>\n",
       "      <td>10027.476190</td>\n",
       "      <td>9.213084</td>\n",
       "      <td>2.005495e+04</td>\n",
       "      <td>18.426168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>both</th>\n",
       "      <td>5</td>\n",
       "      <td>3973.150943</td>\n",
       "      <td>8.287315</td>\n",
       "      <td>1.986575e+04</td>\n",
       "      <td>41.436574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precapitalist</th>\n",
       "      <td>2</td>\n",
       "      <td>9571.681818</td>\n",
       "      <td>9.166564</td>\n",
       "      <td>1.914336e+04</td>\n",
       "      <td>18.333128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stpaul</th>\n",
       "      <td>3</td>\n",
       "      <td>6381.121212</td>\n",
       "      <td>8.761099</td>\n",
       "      <td>1.914336e+04</td>\n",
       "      <td>26.283297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maurin</th>\n",
       "      <td>5</td>\n",
       "      <td>3452.081967</td>\n",
       "      <td>8.146733</td>\n",
       "      <td>1.726041e+04</td>\n",
       "      <td>40.733664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>28</td>\n",
       "      <td>539.941026</td>\n",
       "      <td>6.291460</td>\n",
       "      <td>1.511835e+04</td>\n",
       "      <td>176.160878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mewher</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>their</th>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motherinclud</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herself</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whi</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scottv</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>should</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newold</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cw</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winsthat</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougement</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scateri</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sttheres</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themthey</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwelleth</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jocist</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drbaker</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               freq           idf    logidf         tfidf     logtfidf\n",
       "term                                                                  \n",
       "and             525   2568.012195  7.850887  1.348206e+06  4121.715892\n",
       "with            101   6792.806452  8.823619  6.860735e+05   891.185565\n",
       "for             136   3630.637931  8.197164  4.937668e+05  1114.814256\n",
       "about            34   8423.080000  9.038731  2.863847e+05   307.316848\n",
       "but              74   2105.770000  7.652436  1.558270e+05   566.280299\n",
       "have             75   2005.495238  7.603646  1.504121e+05   570.273473\n",
       "him              19   6792.806452  8.823619  1.290633e+05   167.648770\n",
       "onc              17   7261.275862  8.890311  1.234417e+05   151.135284\n",
       "some             14   8774.041667  9.079553  1.228366e+05   127.113740\n",
       "again            14   8099.115385  8.999510  1.133876e+05   125.993142\n",
       "been             23   4785.840909  8.473417  1.100743e+05   194.888592\n",
       "such             22   4049.557692  8.306363  8.909027e+04   182.739985\n",
       "not              94    803.729008  6.689262  7.555053e+04   628.790643\n",
       "while             7   9571.681818  9.166564  6.700177e+04    64.165949\n",
       "are             112    569.127027  6.344104  6.374223e+04   710.539609\n",
       "dure              7   8423.080000  9.038731  5.896156e+04    63.271116\n",
       "novena           14   3569.101695  8.180069  4.996742e+04   114.520969\n",
       "between           5   9571.681818  9.166564  4.785841e+04    45.832821\n",
       "veri             10   4577.760870  8.428965  4.577761e+04    84.289653\n",
       "num              38    997.995261  6.905749  3.792382e+04   262.418444\n",
       "antigonish        7   4577.760870  8.428965  3.204433e+04    59.002757\n",
       "same             11   2420.425287  7.791699  2.662468e+04    85.708684\n",
       "all              59    346.343750  5.847432  2.043428e+04   344.998475\n",
       "cyo               2  10027.476190  9.213084  2.005495e+04    18.426168\n",
       "actu              2  10027.476190  9.213084  2.005495e+04    18.426168\n",
       "both              5   3973.150943  8.287315  1.986575e+04    41.436574\n",
       "precapitalist     2   9571.681818  9.166564  1.914336e+04    18.333128\n",
       "stpaul            3   6381.121212  8.761099  1.914336e+04    26.283297\n",
       "maurin            5   3452.081967  8.146733  1.726041e+04    40.733664\n",
       "where            28    539.941026  6.291460  1.511835e+04   176.160878\n",
       "...             ...           ...       ...           ...          ...\n",
       "g                 2           NaN       NaN           NaN          NaN\n",
       "mewher            1           NaN       NaN           NaN          NaN\n",
       "could             7           NaN       NaN           NaN          NaN\n",
       "has              30           NaN       NaN           NaN          NaN\n",
       "their            60           NaN       NaN           NaN          NaN\n",
       "motherinclud      1           NaN       NaN           NaN          NaN\n",
       "herself           3           NaN       NaN           NaN          NaN\n",
       "which            50           NaN       NaN           NaN          NaN\n",
       "who              48           NaN       NaN           NaN          NaN\n",
       "whi               1           NaN       NaN           NaN          NaN\n",
       "scottv            1           NaN       NaN           NaN          NaN\n",
       "should            9           NaN       NaN           NaN          NaN\n",
       "she              17           NaN       NaN           NaN          NaN\n",
       "we              154           NaN       NaN           NaN          NaN\n",
       "state             9           NaN       NaN           NaN          NaN\n",
       "newold            1           NaN       NaN           NaN          NaN\n",
       "cw                3           NaN       NaN           NaN          NaN\n",
       "winsthat          1           NaN       NaN           NaN          NaN\n",
       "rougement         3           NaN       NaN           NaN          NaN\n",
       "scateri           3           NaN       NaN           NaN          NaN\n",
       "sttheres          1           NaN       NaN           NaN          NaN\n",
       "i               112           NaN       NaN           NaN          NaN\n",
       "themthey          1           NaN       NaN           NaN          NaN\n",
       "dwelleth          1           NaN       NaN           NaN          NaN\n",
       "he               71           NaN       NaN           NaN          NaN\n",
       "made              9           NaN       NaN           NaN          NaN\n",
       "j                 4           NaN       NaN           NaN          NaN\n",
       "jocist            1           NaN       NaN           NaN          NaN\n",
       "u                 2           NaN       NaN           NaN          NaN\n",
       "drbaker           1           NaN       NaN           NaN          NaN\n",
       "\n",
       "[2235 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqit.sort_values(by='tfidf', ascending=False) # WORKS IN THEORY, BUT WE HAVE SOME DISCREPENCIES\n",
    "# IN THE WAY WE'RE STOPWORDING AND STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>logtfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>influenc</th>\n",
       "      <td>2</td>\n",
       "      <td>6.212077</td>\n",
       "      <td>1.826495</td>\n",
       "      <td>12.424155</td>\n",
       "      <td>3.652991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>craft</th>\n",
       "      <td>1</td>\n",
       "      <td>29.186001</td>\n",
       "      <td>3.373689</td>\n",
       "      <td>29.186001</td>\n",
       "      <td>3.373689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rural</th>\n",
       "      <td>5</td>\n",
       "      <td>16.775034</td>\n",
       "      <td>2.819892</td>\n",
       "      <td>83.875169</td>\n",
       "      <td>14.099459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decemb</th>\n",
       "      <td>1</td>\n",
       "      <td>3.708060</td>\n",
       "      <td>1.310509</td>\n",
       "      <td>3.708060</td>\n",
       "      <td>1.310509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confess</th>\n",
       "      <td>1</td>\n",
       "      <td>50.042063</td>\n",
       "      <td>3.912864</td>\n",
       "      <td>50.042063</td>\n",
       "      <td>3.912864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq        idf    logidf      tfidf   logtfidf\n",
       "term                                                     \n",
       "influenc     2   6.212077  1.826495  12.424155   3.652991\n",
       "craft        1  29.186001  3.373689  29.186001   3.373689\n",
       "rural        5  16.775034  2.819892  83.875169  14.099459\n",
       "decemb       1   3.708060  1.310509   3.708060   1.310509\n",
       "confess      1  50.042063  3.912864  50.042063   3.912864"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing a little exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not: 94\n",
      "when: 67\n",
      "so: 58\n",
      "onli: 28\n",
      "where: 28\n",
      "mani: 23\n",
      "then: 23\n",
      "good: 24\n",
      "more: 23\n",
      "back: 22\n"
     ]
    }
   ],
   "source": [
    "for word in loTest.keywords:\n",
    "    print(word + ': ' + str(freq[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%\n",
      "not: freq      262.000000\n",
      "idf       803.729008\n",
      "logidf      6.689262\n",
      "Name: not, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "when not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "so not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "onli not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "where: freq      390.000000\n",
      "idf       539.941026\n",
      "logidf      6.291460\n",
      "Name: where, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "mani: freq      103808.000000\n",
      "idf            2.028524\n",
      "logidf         0.707308\n",
      "Name: mani, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "then not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "good: freq      43387.000000\n",
      "idf           4.853458\n",
      "logidf        1.579692\n",
      "Name: good, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "more: freq      458.000000\n",
      "idf       459.775109\n",
      "logidf      6.130737\n",
      "Name: more, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "back: freq      61096.000000\n",
      "idf           3.446658\n",
      "logidf        1.237405\n",
      "Name: back, dtype: float64\n",
      "%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "for word in loTest.keywords:\n",
    "    try:\n",
    "        print('%%%%%%%%\\n' + word + ': ' + str(idf.ix[word]) + '\\n%%%%%%%%')\n",
    "    except:\n",
    "        print('%%%%%%%%\\n' + word + ' not found in IDF\\n%%%%%%%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vermin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>four</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mansion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>whose</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>accus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>under</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lord</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hedg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sway</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>worth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hatr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>everi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>newburgh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rise</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>govern</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>enslav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>scholar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>commonw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mancent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fritter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>probabl</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>diego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>diplomat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>jocist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>book</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>arama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>rememb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>varieti</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>u</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>monday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>uncomprehend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>class</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>june</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>stay</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>thoreau</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>quotat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>ghost</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>experienc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>atheist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>drbaker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>encycl</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>rule</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>syllabl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>influenc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>craft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>rural</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>decemb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>confess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  freq\n",
       "0                      5\n",
       "1           vermin     2\n",
       "2             four     7\n",
       "3          protest     1\n",
       "4            sleep     5\n",
       "5          mansion     2\n",
       "6           oldest     1\n",
       "7             hate     3\n",
       "8            whose     4\n",
       "9            accus     4\n",
       "10           under     5\n",
       "11            lord     6\n",
       "12            hedg     1\n",
       "13            sway     1\n",
       "14           worth     1\n",
       "15            hatr     2\n",
       "16           everi     3\n",
       "17        newburgh     1\n",
       "18            rise     2\n",
       "19            vase     1\n",
       "20           arous     1\n",
       "21          govern     3\n",
       "22          enslav     2\n",
       "23          school     2\n",
       "24         scholar     2\n",
       "25         commonw     1\n",
       "26         mancent     1\n",
       "27        straight     1\n",
       "28         fritter     1\n",
       "29           enjoy     3\n",
       "...            ...   ...\n",
       "2205       probabl     5\n",
       "2206         diego     1\n",
       "2207      diplomat     1\n",
       "2208        jocist     1\n",
       "2209        detail     1\n",
       "2210          book    18\n",
       "2211         arama     1\n",
       "2212        rememb     4\n",
       "2213       varieti     3\n",
       "2214             u     2\n",
       "2215        repeat     1\n",
       "2216        monday     1\n",
       "2217  uncomprehend     1\n",
       "2218         class     5\n",
       "2219          june     1\n",
       "2220          stay     7\n",
       "2221       thoreau     2\n",
       "2222        quotat     1\n",
       "2223         ghost     2\n",
       "2224     experienc     1\n",
       "2225       atheist     1\n",
       "2226       drbaker     1\n",
       "2227        encycl     8\n",
       "2228          rule     1\n",
       "2229       syllabl     1\n",
       "2230      influenc     2\n",
       "2231         craft     1\n",
       "2232         rural     5\n",
       "2233        decemb     1\n",
       "2234       confess     1\n",
       "\n",
       "[2235 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # term_frequency is a dict which structure is like:\n",
    "    # {\n",
    "    #     'path_to_file': \n",
    "    #         {'term': 13.4, 'another_term': 15}, \n",
    "    #     'another_file': \n",
    "    #         {'term2': 12, 'foo': 15}\n",
    "    #  } \n",
    "    for term in freq.keys():\n",
    "        if isintance(term_frequency[text], dict):\n",
    "            term_frequency[text][term] = freq[term]/numbers_of_words\n",
    "        else:\n",
    "            term_frequency[text] = {term: freq[term]/numbers_of_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#stemmer = nltk.stem.snowball.EnglishStemmer()\n",
    "#stemkeywords=[stemmer.stem(word) for word in loTest.keywords]\n",
    "#print(stemkeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%\n",
      "not\n",
      "{u'all': 2, u'distanc': 1, u'they': 2, u'just': 2, u'queen': 1, u'sage': 1, u'becaus': 3, u'violent': 1, u'go': 1, u'chair': 1, u'still': 1, u'find': 1, u'help': 1, u'fit': 1, u'readabl': 1, u'should': 2, 'to': 11, u'book': 1, u'factor': 1, u'sens': 2, u'delici': 1, u'has': 1, u'might': 1, u'real': 1, 'do': 3, u'good': 1, u'everi': 1, u'read': 2, u'dessert': 1, u'somebodi': 1, u'know': 1, u'codecerror': 11, u'veri': 1, u'one': 1, u'school': 1, u'anyth': 5, u'smell': 1, u'drop': 1, u'these': 1, u'bad': 2, u'contain': 1, u'plank': 1, u'enjoy': 1, u'the': 23, u'right': 2, u'mental': 1, u'natur': 1, u'mind': 3, u'realli': 1, u'see': 1, u'are': 16, u'seeabl': 1, u'cold': 1, u'infinit': 1, u'serv': 1, u'what': 1, u'said': 1, u'for': 3, u'bhagavad': 1, u'someth': 1, u'abl': 2, u'uniform': 1, u'doer': 1, u'experi': 1, 'be': 6, 'we': 3, u'who': 1, u'led': 1, u'isol': 1, u'here': 1, u'bodi': 3, u'ask': 1, u'eye': 1, u'come': 1, 'by': 2, u'faith': 2, 'of': 2, u'could': 1, u'vidyalayam': 1, u'thing': 1, u'outsid': 1, u'share': 1, 'or': 4, u'gita': 1, u'feel': 1, u'guidelin': 2, u'yourself': 1, u'open': 1, u'your': 5, u'use': 2, u'from': 2, u'log': 1, u'there': 5, u'happi': 2, u'start': 1, u'live': 1, u'way': 2, u'spring': 1, u'scope': 1, u'was': 1, u'that': 7, u'forc': 1, u'peopl': 2, u'but': 8, u'drown': 1, u'hear': 2, u'compani': 1, u'with': 2, u'eat': 2, 'he': 2, 'me': 1, u'made': 1, u'word': 1, u'look': 1, u'perceiv': 1, u'this': 3, u'work': 1, 'us': 1, u'can': 13, u'problem': 1, u'everyon': 1, u'expect': 2, u'and': 8, u'give': 2, u'certain': 1, 'is': 12, 'am': 2, 'it': 6, 'an': 1, u'say': 1, u'his': 1, u'exist': 2, 'at': 1, u'have': 4, 'in': 5, u'disappear': 1, 'if': 3, u'result': 1, u'selfish': 1, u'sit': 1, u'anoth': 1, u'when': 1, u'same': 4, u'intellect': 1, u'alway': 1, u'other': 1, u'rememb': 1, u'you': 19, u'simpl': 1, u'shall': 1, u'may': 1, u'object': 3, u'moment': 1, u'fruit': 1, u'whether': 1, u'water': 1, u'extern': 1, u'peac': 1, u'man': 1, 'a': 5, u'essenti': 1, 'i': 3, u'bind': 1, u'proud': 1, u'doe': 3, u'thought': 1, u'part': 1, u'adam': 1, u'allow': 1, u'everyth': 4}\n",
      "%%%%%\n",
      "good\n",
      "{u'and': 2, u'all': 1, u'have': 2, u'creat': 1, u'they': 1, u'feel': 1, u'natur': 1, 'is': 5, u'hard': 1, u'disciplin': 2, u'not': 1, 'as': 1, u'are': 4, u'want': 1, 'in': 1, u'proper': 1, u'home': 1, u'find': 1, u'might': 1, u'what': 3, u'nonsmok': 1, u'televis': 1, u'get': 1, u'yogi': 1, u'been': 1, 'to': 3, u'program': 1, u'call': 1, u'build': 1, u'environ': 1, u'you': 4, 'if': 1, u'codecerror': 3, u'noth': 1, 'do': 1, u'good': 2, u'that': 2, u'some': 1, u'after': 1, u'pave': 1, u'befor': 1, u'know': 1, u'satsang': 2, u'veri': 1, u'yoga': 1, u'compani': 9, u'grow': 1, u'those': 1, u'must': 1, 'a': 1, 'on': 2, u'join': 3, u'this': 1, 'of': 1, 'up': 1, u'charact': 3, u'will': 1, u'thing': 2, u'place': 1, u'the': 11, u'manner': 2}\n",
      "%%%%%\n",
      "then\n",
      "{u'and': 7, u'codecerror': 1, u'guidelin': 1, 'is': 4, u'becaus': 1, u'yourself': 2, u'alway': 1, 'as': 1, u'are': 4, u'tabl': 2, u'ship': 1, u'yes': 1, u'even': 1, u'decid': 1, u'ash': 1, u'depend': 1, u'guest': 1, u'suprem': 1, 'to': 1, u'relax': 1, u'sometim': 1, u'been': 1, u'plank': 3, u'their': 1, u'wood': 3, u'call': 1, u'sens': 1, u'you': 4, u'immedi': 1, u'until': 1, 'be': 1, u'finish': 1, u'see': 1, u'though': 2, u'may': 1, u'tree': 1, u'time': 1, u'piec': 1, 'it': 2, u'how': 1, u'chair': 1, u'made': 1, u'they': 1, u'delici': 1, u'now': 1, u'burnt': 1, u'the': 9, u'log': 2, 'a': 1, u'experi': 1, u'practic': 1, u'never': 1, u'conscious': 1, u'whether': 1, 'of': 3, u'into': 1, u'sit': 1, u'alon': 1, u'remain': 2, 'us': 1, u'benefit': 1, u'were': 1, u'chang': 1, u'principl': 1, 'my': 1, 'or': 1, u'for': 1}\n",
      "%%%%%\n",
      "even\n",
      "{u'blind': 1, u'vedanta': 1, u'all': 1, u'help': 1, 'be': 1, u'give': 2, u'natur': 1, 'it': 2, u'down': 1, u'perpetu': 1, u'dazzl': 1, u'want': 1, 'in': 5, u'go': 1, u'our': 1, u'ship': 1, u'faith': 1, u'your': 3, 'if': 2, u'awar': 1, u'use': 1, u'spiritu': 1, u'daytoday': 1, u'with': 1, u'sometim': 1, u'littl': 1, 'to': 2, u'again': 1, u'seeker': 1, u'lot': 1, u'you': 3, u'codecerror': 1, u'more': 1, u'then': 1, u'them': 1, u'which': 1, u'though': 3, u'may': 1, u'shallow': 2, u'here': 1, u'hand': 1, u'water': 2, u'fruit': 1, u'they': 1, u'compani': 1, u'nobodi': 1, u'effort': 1, u'longer': 1, 'a': 3, u'also': 1, u'room': 1, u'anyth': 1, u'this': 1, 'of': 1, u'bother': 1, 'no': 1, 'up': 1, 'or': 1, u'will': 3, u'without': 1, u'grain': 1, u'smoke': 1, u'push': 1, u'field': 1, u'the': 3, u'think': 1, u'daili': 1, 'at': 1}\n",
      "%%%%%\n",
      "when\n",
      "{u'and': 2, u'old': 1, u'help': 1, u'activ': 1, 'is': 4, u'emot': 1, u'one': 2, u'say': 1, u'are': 3, u'slip': 1, 'in': 1, 'go': 1, u'forget': 1, u'your': 2, u'stage': 1, u'fill': 1, u'selfish': 1, u'onli': 2, u'ear': 1, u'built': 1, u'daytoday': 1, u'someth': 2, u'there': 1, u'seat': 1, u'young': 1, u'eat': 1, 'to': 2, u'other': 2, u'analyz': 1, u'you': 10, u'deafen': 1, u'codecerror': 2, 'be': 1, u'that': 2, u'forc': 1, u'absorb': 1, u'never': 1, u'reach': 1, u'use': 1, u'but': 1, u'bodi': 1, u'know': 1, u'they': 1, u'not': 1, u'affect': 1, u'now': 1, u'with': 1, u'day': 1, u'like': 1, 'on': 1, u'went': 1, u'avoid': 1, 'i': 2, 'of': 1, u'thing': 1, u'each': 1, u'the': 2, u'think': 1, u'expect': 1}\n",
      "%%%%%\n",
      "so\n",
      "{u'our': 2, u'and': 1, u'all': 1, u'they': 3, 'be': 1, u'feel': 1, u'guidelin': 1, 'is': 2, 'in': 2, u'mind': 1, u'becaus': 1, u'capac': 1, u'see': 1, u'are': 5, u'want': 1, u'someth': 1, u'seen': 1, u'your': 1, 'as': 2, 'if': 1, u'caus': 1, u'differ': 1, u'said': 1, u'end': 1, 'i': 1, u'also': 1, u'section': 1, u'there': 2, u'bowl': 1, u'thank': 1, u'long': 1, u'should': 1, 'to': 6, u'other': 1, u'health': 1, u'too': 1, u'natur': 2, u'sens': 1, u'you': 5, u'man': 1, u'gave': 1, 'do': 3, 'we': 1, u'his': 1, u'return': 1, u'truth': 1, u'that': 4, u'mess': 1, u'peopl': 1, u'who': 1, u'watch': 1, u'hand': 1, u'vomit': 1, u'codecerror': 2, u'share': 1, u'shun': 1, u'compani': 1, u'with': 1, u'chang': 1, u'physic': 1, u'must': 1, 'a': 2, u'experienc': 1, u'this': 1, 'of': 1, 'up': 1, u'separ': 1, u'collect': 1, u'achiev': 1, u'can': 1, u'smoke': 1, u'mani': 1, u'the': 5, u'purpos': 1, 'or': 1, u'say': 1}\n",
      "%%%%%\n",
      "here\n",
      "{u'and': 3, u'old': 1, u'guidelin': 2, u'over': 1, 'it': 1, u'born': 2, 'as': 2, u'are': 2, u'have': 1, 'in': 3, u'our': 1, u'your': 1, u'communiti': 1, 'if': 2, u'even': 1, u'yogavill': 2, u'harmoni': 1, 'no': 2, u'ruin': 1, u'littl': 1, u'should': 1, 'to': 1, u'live': 1, u'you': 5, u'main': 1, 'is': 2, u'more': 1, 'be': 4, u'vibrat': 1, u'that': 1, u'shallow': 1, u'but': 1, u'codecerror': 3, u'refin': 1, u'not': 1, u'come': 2, 'by': 1, 'a': 1, 'i': 1, 'of': 2, u'benefit': 1, u'follow': 3, u'can': 1, u'wild': 1, u'mani': 1, u'the': 6, u'purpos': 1, u'similar': 1}\n",
      "%%%%%\n",
      "other\n",
      "{u'and': 2, u'right': 1, u'help': 2, u'ten': 1, u'speci': 1, 'is': 1, u'share': 1, u'becaus': 1, u'one': 2, u'offer': 1, u'kill': 1, u'are': 3, u'slip': 1, u'find': 1, 'if': 1, u'said': 1, u'group': 1, u'appear': 1, u'for': 1, u'also': 1, u'with': 1, u'there': 2, u'when': 2, u'same': 1, u'should': 1, 'to': 4, u'live': 1, u'chamber': 1, 'it': 2, 'so': 1, u'you': 2, u'codecerror': 1, 'be': 1, 'we': 1, u'that': 1, u'may': 1, u'peopl': 1, u'innermost': 1, u'hand': 3, u'somebodi': 1, u'togeth': 2, u'they': 3, u'not': 1, u'from': 2, 'on': 4, u'come': 1, u'peac': 1, u'gregorian': 1, 'a': 2, u'pull': 1, u'protect': 1, u'lead': 1, u'chant': 1, 'no': 1, u'well': 1, 'as': 1, u'know': 1, u'thing': 1, u'environ': 1, u'can': 2, u'each': 4, 'at': 1, u'the': 10, u'view': 2, u'silver': 1, u'ourselv': 1}\n",
      "%%%%%\n",
      "also\n",
      "{u'and': 2, u'natur': 1, 'is': 1, u'accord': 1, u'annihil': 1, u'are': 4, u'children': 1, u'even': 1, u'spiritu': 2, u'realm': 1, u'for': 1, 'to': 1, u'highest': 1, u'there': 1, u'same': 1, u'field': 1, u'book': 1, u'you': 2, u'experi': 2, 'we': 2, u'truth': 1, u'that': 2, u'but': 1, u'bodi': 1, u'part': 1, u'know': 1, u'ash': 1, u'ident': 1, 'of': 1, 'so': 1, u'can': 3, u'though': 1, u'the': 9, u'other': 1, u'adult': 1}\n",
      "%%%%%\n",
      "differ\n",
      "{u'and': 3, u'all': 1, u'identifi': 1, u'feel': 1, 'is': 3, u'mind': 1, u'are': 3, u'have': 2, 'in': 2, u'total': 1, u'your': 3, u'given': 1, u'from': 2, u'etc': 1, u'there': 2, u'capac': 2, 'to': 2, u'seeker': 1, u'suppos': 1, u'suit': 1, u'got': 2, u'you': 2, u'therefor': 1, u'method': 1, u'real': 1, u'that': 3, u'peopl': 3, u'men': 2, u'differ': 2, u'but': 1, u'bodi': 2, u'reason': 1, u'understand': 1, u'know': 1, u'codecerror': 1, u'such': 1, 'by': 1, u'present': 1, 'a': 1, u'these': 1, 'of': 6, u'facet': 1, 'i': 1, 'so': 1, u'she': 1, u'abov': 1, u'grasp': 1, u'opinion': 1, u'the': 5, u'view': 1}\n",
      "{u'respond': 2, u'faith': 1, u'ultim': 1, 'is': 1, 'to': 2, u'codecerror': 1, u'the': 3, u'essenc': 1}\n"
     ]
    }
   ],
   "source": [
    "for key in loTest.keywords: ### get context vectors for keywords...\n",
    "    print('%%%%%\\n' + key)\n",
    "    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n",
    "#print(loTest.cocoDict['spiritual'])\n",
    "print(loTest.cocoDict['spirit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for key in stemkeywords: ### get context vectors for keywords...\n",
    "#    print('%%%%%\\n' + key)\n",
    "#    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in loTest.keywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "#    if 'spirtual' in filetokens:\n",
    "#        print(\"UAL!\")\n",
    "#    if 'spirit' in filetokens:\n",
    "#        print(\"SPIRIT!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## STEM keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in stemkeywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.cvWindow: 3\n",
      "%%%%\n",
      "cvDict, length 4\n",
      "---the first ten keys:\n",
      "['./data_dsicap/IntegralYoga/raw/YV58.txt', './data_dsicap/IntegralYoga/raw/YV48.txt', './data_dsicap/IntegralYoga/raw/YV54.txt', './data_dsicap/IntegralYoga/raw/YV05.txt']\n",
      "---the keywords each file:\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt: [u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "%%%%%%%\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 5 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 10 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "---------length of thisfile[then][7]: 50\n",
      "---------length of thisfile[then][8]: 50\n",
      "---------length of thisfile[then][9]: 50\n",
      "---------length of thisfile[then][10]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 9 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "---------length of thisfile[differ][6]: 50\n",
      "---------length of thisfile[differ][7]: 50\n",
      "---------length of thisfile[differ][8]: 50\n",
      "---------length of thisfile[differ][9]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 3 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 5 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "---------length of thisfile[also][3]: 50\n",
      "---------length of thisfile[also][4]: 50\n",
      "---------length of thisfile[also][5]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 4 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 6 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 24 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n",
      "---------length of thisfile[not][21]: 50\n",
      "---------length of thisfile[not][22]: 50\n",
      "---------length of thisfile[not][23]: 50\n",
      "---------length of thisfile[not][24]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 1 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 5 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 4 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 2 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 11 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt (5 keys):\n",
      "---keys: [u'not', u'even', u'when', u'other', 'so']\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 8 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 1 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 3 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt (9 keys):\n",
      "---keys: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 8 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "---------length of thisfile[even][6]: 50\n",
      "---------length of thisfile[even][7]: 50\n",
      "---------length of thisfile[even][8]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 6 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "------thisfile[good]:\n",
      "-------length: \"good\" appears 18 times in this file.\n",
      "---------length of thisfile[good][1]: 50\n",
      "---------length of thisfile[good][2]: 50\n",
      "---------length of thisfile[good][3]: 50\n",
      "---------length of thisfile[good][4]: 50\n",
      "---------length of thisfile[good][5]: 50\n",
      "---------length of thisfile[good][6]: 50\n",
      "---------length of thisfile[good][7]: 50\n",
      "---------length of thisfile[good][8]: 50\n",
      "---------length of thisfile[good][9]: 50\n",
      "---------length of thisfile[good][10]: 50\n",
      "---------length of thisfile[good][11]: 50\n",
      "---------length of thisfile[good][12]: 50\n",
      "---------length of thisfile[good][13]: 50\n",
      "---------length of thisfile[good][14]: 50\n",
      "---------length of thisfile[good][15]: 50\n",
      "---------length of thisfile[good][16]: 50\n",
      "---------length of thisfile[good][17]: 50\n",
      "---------length of thisfile[good][18]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 6 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "---------length of thisfile[when][5]: 50\n",
      "---------length of thisfile[when][6]: 50\n",
      "------thisfile[here]:\n",
      "-------length: \"here\" appears 13 times in this file.\n",
      "---------length of thisfile[here][1]: 50\n",
      "---------length of thisfile[here][2]: 50\n",
      "---------length of thisfile[here][3]: 50\n",
      "---------length of thisfile[here][4]: 50\n",
      "---------length of thisfile[here][5]: 50\n",
      "---------length of thisfile[here][6]: 50\n",
      "---------length of thisfile[here][7]: 50\n",
      "---------length of thisfile[here][8]: 50\n",
      "---------length of thisfile[here][9]: 50\n",
      "---------length of thisfile[here][10]: 50\n",
      "---------length of thisfile[here][11]: 50\n",
      "---------length of thisfile[here][12]: 50\n",
      "---------length of thisfile[here][13]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 8 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "---------length of thisfile[other][5]: 50\n",
      "---------length of thisfile[other][6]: 50\n",
      "---------length of thisfile[other][7]: 50\n",
      "---------length of thisfile[other][8]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 8 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "---------length of thisfile[so][7]: 50\n",
      "---------length of thisfile[so][8]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 20 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n"
     ]
    }
   ],
   "source": [
    "#######################            \n",
    "###Semantic analysis###\n",
    "#######################\n",
    "\n",
    "#Get context vectors\n",
    "loTest.getContextVectors(cvWindow)\n",
    "print('loTest.cvWindow: ' + str(loTest.cvWindow))\n",
    "\n",
    "#        self.cvWindow=k\n",
    "#        self.cvDict={}\n",
    "\n",
    "print('%%%%\\ncvDict, length ' + str(len(loTest.cvDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cvDict.keys()[:10])\n",
    "print('---the keywords each file:')\n",
    "for key in loTest.cvDict.keys():\n",
    "    print(key + ': ' + str(loTest.cvDict[key].keys()))\n",
    "print('%%%%%%%')\n",
    "#file1 = loTest.cvDict.keys()[0] #'./data_dsicap/IntegralYoga/raw/YV38.txt'\n",
    "    \n",
    "for file1 in loTest.cvDict.keys():    \n",
    "    first = loTest.cvDict[file1]\n",
    "    #print('---the first entry (length ' + str(len(first[first.keys()[0]])) + '):')\n",
    "    print('%%%%%\\n' + file1 + ' (' + str(len(first.keys())) + ' keys):')\n",
    "    print('---keys: ' + str(first.keys()))\n",
    "    for wordkey in first.keys():\n",
    "        print('------thisfile[' + wordkey + ']:')\n",
    "        tftk = first[wordkey]\n",
    "        print('-------length: \"' + wordkey + '\" appears ' + str(len(tftk.keys())) + ' times in this file.')\n",
    "        for numkey in tftk.keys():\n",
    "            print('---------length of thisfile[' + wordkey +'][' + str(numkey) + ']: ' + str(len(tftk[numkey])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "[u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "[u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "10\n",
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n",
      "[0.72404735956380151, 0.70700627327625354, 0.71615225785121706, 0.69572043045266363, 0.75862725558225175, 0.72200533701172254, 0.75878819429898337, 0.67993472478851136, 0.77246014024129339, 0.76795665602778718]\n"
     ]
    }
   ],
   "source": [
    "#Get average semantic density\n",
    "#avgSD=np.mean([x[1] for x in loTest.getSD(simCount)])\n",
    "#print(avgSD)\n",
    "\n",
    "SD = [x[1] for x in loTest.getSD(simCount)]\n",
    "print(len(SD))\n",
    "print(loTest.keywords)\n",
    "print(SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "###POS Tagging and Judgement Analysis###\n",
    "########################################\n",
    "judgementAvg=list(np.mean(np.array([[x[1],x[2]] for x in loTest.getJudgements()]),axis=0))\n",
    "\n",
    "########################\n",
    "###Sentiment Analysis###\n",
    "########################\n",
    "\n",
    "sentimentList=loTest.sentimentLookup()\n",
    "\n",
    "############################\n",
    "###Network Quantification###\n",
    "############################\n",
    "loTest.setNetwork(netAngle)\n",
    "\n",
    "avgEVC=loTest.evc()\n",
    "\n",
    "endTime=time.time()\n",
    "timeRun=endTime-startTime\n",
    "print('finished running'+'_'.join(groupId)+' in '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#Append outputs to masterOutput\n",
    "return(['_'.join(groupId)]+[len(subFileList),timeRun]+sentimentList+judgementAvg+[avgSD]+[avgEVC])   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
