{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "2016-10-26 15:00:49.081444\n",
      "finished loading packages after 0.00162982940674 seconds\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul 19 16:14:43 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun  2 15:23:11 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "import time\n",
    "start=time.time()\n",
    "import sys, os\n",
    "\n",
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017')\n",
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing as mp\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "sys.path.append('./prototype_python/')\n",
    "import lingual as la\n",
    "#import lingualPrinting as la\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "#sys.stdout = open(\"output.txt\", \"a\")\n",
    "print(str(datetime.now()))\n",
    "print('finished loading packages after '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#\n",
    "import getNewDocs as gnd\n",
    "\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "59\n",
      "20\n",
      "[['IntegralYoga', 'test11'], ['SeaShepherds', 'test1'], ['IntegralYoga', 'test1'], ['Bahai', 'test7'], ['IntegralYoga', 'test8'], ['Bahai', 'test3'], ['IntegralYoga', 'test4'], ['IntegralYoga', 'test10'], ['SeaShepherds', 'test2'], ['IntegralYoga', 'test0'], ['Bahai', 'test6'], ['Bahai', 'test2'], ['IntegralYoga', 'test7'], ['Bahai', 'test9'], ['SeaShepherds', 'test3'], ['IntegralYoga', 'test3'], ['Bahai', 'test5'], ['Bahai', 'test1'], ['IntegralYoga', 'test6'], ['Bahai', 'test8'], ['IntegralYoga', 'test2'], ['Bahai', 'test4'], ['SeaShepherds', 'test0'], ['Bahai', 'test0'], ['IntegralYoga', 'test9'], ['IntegralYoga', 'test5']]\n",
      "%%%%%\n",
      "length of subgroupList is 26\n"
     ]
    }
   ],
   "source": [
    "fileDF=gnd.newDocsToDF('./data_dsicap/', bin=5) ################################### WHERE THE NEW FILES ARE\n",
    "\n",
    "fileList=fileDF.values.tolist()\n",
    "\n",
    "fileList=[[fileList[i][0],fileList[i][1],fileList[i][2]] for i in range(len(fileList))]\n",
    "\n",
    "\n",
    "#Get set of subgroups\n",
    "subgroupList=[ list(y) for y in set((x[0],x[2]) for x in fileList) ]\n",
    "print(subgroupList)\n",
    "print('%%%%%\\nlength of subgroupList is ' + str(len(subgroupList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawPath = './data_dsicap/' ###############change this eventually\n",
    "runDirectory='./modelOutput/'\n",
    "#groupList=['DorothyDay','JohnPiper','MehrBaba','NaumanKhan','PastorAnderson',\n",
    "#   'Rabbinic','Shepherd','Unitarian','WBC']\n",
    "groupList=['DorothyDay','NaumanKhan','Rabbinic','NawDawg','SeaShepherds','IntegralYoga','Bahai']\n",
    "#cocoWindow=int(sys.argv[1])\n",
    "#cvWindow=int(sys.argv[2])\n",
    "#startCount=int(sys.argv[3])\n",
    "#netAngle=int(sys.argv[4])\n",
    "cocoWindow=3\n",
    "cvWindow=3\n",
    "startCount=0\n",
    "netAngle=30\n",
    "groupSize=10\n",
    "#testSplit=.3\n",
    "targetWordCount=10\n",
    "svdInt=50\n",
    "simCount=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "#Create paramList\n",
    "paramList=[[x,fileList,targetWordCount,cocoWindow,svdInt,cvWindow,simCount,startCount,netAngle] for x in subgroupList]\n",
    "print(len(paramList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run calculation \n",
    "#masterOutput=[textAnalysis(x) for x in paramList]  ### INSTEAD OF THIS, WE MAKE THE OBJECT\n",
    "paramPick = paramList[0] ### instead of looping through, we just pick one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IntegralYoga', 'test11']\n"
     ]
    }
   ],
   "source": [
    "#def textAnalysis(paramPick):\n",
    "startTime=time.time()\n",
    "groupId=paramPick[0]\n",
    "fileList=paramPick[1]\n",
    "targetWordCount=paramPick[2]\n",
    "cocoWindow=paramPick[3]\n",
    "svdInt=paramPick[4]\n",
    "cvWindow=paramPick[5]\n",
    "simCount=paramPick[6]\n",
    "startCount=paramPick[7]\n",
    "netAngle=paramPick[8]    \n",
    "\n",
    "print(groupId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['./data_dsicap/IntegralYoga/raw/YV04.txt', './data_dsicap/IntegralYoga/raw/YV27.txt', './data_dsicap/IntegralYoga/raw/YV34.txt', './data_dsicap/IntegralYoga/raw/YV50.txt']\n"
     ]
    }
   ],
   "source": [
    "#Get list of subfiles\n",
    "subFileList=[x[1] for x in fileList if x[0]==groupId[0] and x[2]==groupId[1]]\n",
    "print(len(subFileList))\n",
    "print(subFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#Create lingual object\n",
    "loTest=la.lingualObject(subFileList)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LOOK AT LIST OF TOKENS FOR FILE\n",
    "#print(subFileList[0])\n",
    "#loTest.tokens[subFileList[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%\n",
      "cocoDict, length 817\n",
      "---the first ten keys:\n",
      "[u'all', u'forget', u'whatev', u'lack', u'focus', u'sleep', 'go', u'follow', u'children', u'whose']\n",
      "---the first entry:\n",
      "all\n",
      "{u'all': 2, u'codecerror': 1, u'over': 1, u'rest': 1, u'veri': 1, u'onli': 1, 'to': 3, u'do': 1, u'remedi': 1, u'good': 1, u'prakriti': 1, u'they': 1, u'not': 1, u'world': 2, u'sin': 2, u'this': 2, u'she': 1, u'elimin': 1, u'are': 1, u'our': 3, u'yogic': 1, u'calam': 1, u'spiritu': 1, u'for': 2, u'god': 1, u'behind': 4, u'common': 1, 'we': 3, u'someon': 1, u'bodi': 1, 'of': 6, u'ill': 1, u'share': 1, u'undergo': 1, 'or': 1, u'love': 2, u'feel': 1, u'one': 1, u'sacr': 1, u'mistak': 1, u'pranayama': 2, u'given': 1, u'happi': 1, u'breath': 1, u'live': 1, u'form': 1, u'forc': 1, u'peopl': 2, u'bundl': 1, u'with': 3, u'serv': 1, u'kind': 1, u'these': 3, u'work': 1, u'aim': 1, u'merci': 1, u'can': 1, u'purpos': 2, u'everyon': 1, u'and': 2, u'constant': 1, u'then': 1, 'is': 7, u'mind': 1, u'it': 1, 'an': 1, u'have': 1, 'in': 1, u'uniti': 1, u'make': 1, u'compel': 1, u'toxin': 1, u'rememb': 1, u'you': 2, u'medit': 1, u'divers': 1, u'after': 1, u'whi': 1, u'intens': 1, u'the': 9, 'a': 1, u'practic': 4, u'scientif': 1, u'doe': 1, u'mother': 1, u'everyth': 1}\n"
     ]
    }
   ],
   "source": [
    "#Get coco\n",
    "loTest.getCoco(cocoWindow)\n",
    "\n",
    "#        self.cocoWindow=k\n",
    "#        self.cocoDict={}\n",
    "#        self.TF={}\n",
    "#        self.docTF={}\n",
    "\n",
    "print('%%%%\\ncocoDict, length ' + str(len(loTest.cocoDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cocoDict.keys()[:10])\n",
    "print('---the first entry:')\n",
    "key1 = loTest.cocoDict.keys()[0]\n",
    "print(key1)\n",
    "print(loTest.cocoDict[key1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.svdK: 50\n",
      "%%%%\n",
      "DSM, length 817\n",
      "---the first ten keys:\n",
      "[u'all', u'forget', u'whatev', u'lack', u'focus', u'sleep', u'go', u'follow', u'children', u'whose']\n",
      "---the first entry:\n",
      "{0: 1.1214756080553279, 1: 0.14559073769964412, 2: -0.70559179055885313, 3: 0.30188124777197162, 4: -0.21873321016122674, 5: 0.043320866150066376, 6: 0.21646796612983507, 7: 0.044322091987744582, 8: 0.36347195085417988, 9: -0.40568586159846987, 10: 0.28446347423191415, 11: 0.13141277732942178, 12: -0.005904409531775988, 13: 0.13389266011131948, 14: -0.18825978909861205, 15: -0.0088639059845848685, 16: -0.059951940167040967, 17: -0.24591464800477308, 18: -0.17888852417393716, 19: -0.068252056982236006, 20: -0.14349207298709607, 21: 0.013326196248844506, 22: -0.076610525463243276, 23: 0.15104260678688461, 24: -0.005249227804420489, 25: -0.014940950181386709, 26: 0.22813054856744813, 27: 0.1782909538007876, 28: 0.12994095814348203, 29: -0.14976064321721475, 30: 0.13810988966478036, 31: 0.036989309128688794, 32: 0.0094910450667747542, 33: 0.20050675708962409, 34: -0.070377468212698607, 35: -0.053719466025913327, 36: 0.0041061820326547677, 37: 0.27234021944255099, 38: 0.013327191248221021, 39: 0.022469485097848706, 40: 0.044068332201052912, 41: -0.0054529045975609544, 42: -0.076637567805605336, 43: -0.03752969305075321, 44: 0.020633745317512595, 45: 0.018168645927234429, 46: -0.044839015260116938, 47: 0.035858242141417411, 48: 0.0097948324706053219, 49: 0.054405462082777738}\n"
     ]
    }
   ],
   "source": [
    "#Get DSM\n",
    "loTest.getDSM(svdInt)\n",
    "print('loTest.svdK: ' + str(loTest.svdK))\n",
    "\n",
    "print('%%%%\\nDSM, length ' + str(len(loTest.DSM)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.DSM.keys()[:10])\n",
    "print('---the first entry:')\n",
    "print(loTest.DSM[loTest.DSM.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'not', 'more', 'only', 'so', 'very', 'why', 'spiritual', 'clean', 'most']\n",
      "%%%%%\n",
      "when\n",
      "%%%%%\n",
      "not\n",
      "%%%%%\n",
      "more\n",
      "%%%%%\n",
      "only\n",
      "%%%%%\n",
      "so\n",
      "%%%%%\n",
      "very\n",
      "%%%%%\n",
      "why\n",
      "%%%%%\n",
      "spiritual\n",
      "%%%%%\n",
      "clean\n",
      "%%%%%\n",
      "most\n",
      "{u'and': 4, u'work': 2, u'love': 1, u'when': 1, 'is': 5, u'mind': 3, u'life': 1, u'feet': 1, u'say': 1, u'human': 1, u'limit': 1, u'your': 5, u'onli': 3, u'yoga': 1, u'for': 1, u'how': 1, u'rather': 1, u'god': 1, u'get': 1, u'yogi': 1, 'to': 6, u'restrain': 1, u'lot': 1, u'natur': 2, 'it': 1, u'sens': 1, u'you': 2, u'yama': 1, u'obsess': 1, u'noncovet': 1, u'head': 4, u'good': 1, u'that': 2, u'symbol': 1, u'act': 1, u'surfac': 1, u'focus': 2, u'befor': 1, 'we': 2, u'base': 2, u'codecerror': 4, u'such': 1, u'part': 1, u'than': 1, 'a': 3, u'practic': 1, u'this': 2, u'medit': 1, 'no': 1, 'us': 1, 'or': 2, u'harden': 1, u'continu': 2, 'so': 2, u'stand': 5, u'learn': 2, u'the': 7, u'think': 1}\n",
      "{u'and': 1, 'a': 2, u'right': 1, u'fieri': 1, u'without': 1, 'of': 2, 'is': 2, 'or': 1, u'mind': 1, u'your': 1, u'bodi': 1, u'attach': 1, u'asana': 1, u'reflect': 1, 'in': 3, u'real': 1, u'selfless': 1, u'the': 3, u'servic': 3, u'clear': 1, u'must': 1}\n"
     ]
    }
   ],
   "source": [
    "#Set keywords\n",
    "loTest.setKeywords('adjAdv',targetWordCount,startCount)\n",
    "print(loTest.keywords)\n",
    "\n",
    "for key in loTest.keywords: ### get context vectors for keywords...\n",
    "    print('%%%%%\\n' + key)\n",
    "    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n",
    "#print(loTest.cocoDict['spiritual'])\n",
    "print(loTest.cocoDict['spirit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV04.txt\n",
      "when\n",
      "not\n",
      "more\n",
      "so\n",
      "clean\n",
      "most\n",
      "SPIRIT!\n",
      "./data_dsicap/IntegralYoga/raw/YV27.txt\n",
      "when\n",
      "not\n",
      "SPIRIT!\n",
      "./data_dsicap/IntegralYoga/raw/YV34.txt\n",
      "when\n",
      "not\n",
      "more\n",
      "so\n",
      "most\n",
      "./data_dsicap/IntegralYoga/raw/YV50.txt\n",
      "when\n",
      "not\n",
      "more\n",
      "most\n"
     ]
    }
   ],
   "source": [
    "## keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in loTest.keywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "    if 'spirtual' in filetokens:\n",
    "        print(\"UAL!\")\n",
    "    if 'spirit' in filetokens:\n",
    "        print(\"SPIRIT!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.cvWindow: 3\n",
      "%%%%\n",
      "cvDict, length 4\n",
      "---the first ten keys:\n",
      "['./data_dsicap/IntegralYoga/raw/YV50.txt', './data_dsicap/IntegralYoga/raw/YV27.txt', './data_dsicap/IntegralYoga/raw/YV04.txt', './data_dsicap/IntegralYoga/raw/YV34.txt']\n",
      "---the keywords each file:\n",
      "./data_dsicap/IntegralYoga/raw/YV50.txt: [u'not', u'most', u'when', u'more']\n",
      "./data_dsicap/IntegralYoga/raw/YV27.txt: [u'not', u'when']\n",
      "./data_dsicap/IntegralYoga/raw/YV04.txt: [u'when', u'most', 'so', u'clean', u'not', u'more']\n",
      "./data_dsicap/IntegralYoga/raw/YV34.txt: [u'not', u'when', u'most', 'so', u'more']\n",
      "%%%%%%%\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV50.txt (4 keys):\n",
      "---keys: [u'not', u'most', u'when', u'more']\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 2 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "------thisfile[most]:\n",
      "-------length: \"most\" appears 4 times in this file.\n",
      "---------length of thisfile[most][1]: 50\n",
      "---------length of thisfile[most][2]: 50\n",
      "---------length of thisfile[most][3]: 50\n",
      "---------length of thisfile[most][4]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 2 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "------thisfile[more]:\n",
      "-------length: \"more\" appears 4 times in this file.\n",
      "---------length of thisfile[more][1]: 50\n",
      "---------length of thisfile[more][2]: 50\n",
      "---------length of thisfile[more][3]: 50\n",
      "---------length of thisfile[more][4]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV27.txt (2 keys):\n",
      "---keys: [u'not', u'when']\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 3 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 2 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV04.txt (6 keys):\n",
      "---keys: [u'when', u'most', 'so', u'clean', u'not', u'more']\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 14 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "---------length of thisfile[when][5]: 50\n",
      "---------length of thisfile[when][6]: 50\n",
      "---------length of thisfile[when][7]: 50\n",
      "---------length of thisfile[when][8]: 50\n",
      "---------length of thisfile[when][9]: 50\n",
      "---------length of thisfile[when][10]: 50\n",
      "---------length of thisfile[when][11]: 50\n",
      "---------length of thisfile[when][12]: 50\n",
      "---------length of thisfile[when][13]: 50\n",
      "---------length of thisfile[when][14]: 50\n",
      "------thisfile[most]:\n",
      "-------length: \"most\" appears 1 times in this file.\n",
      "---------length of thisfile[most][1]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 19 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "---------length of thisfile[so][7]: 50\n",
      "---------length of thisfile[so][8]: 50\n",
      "---------length of thisfile[so][9]: 50\n",
      "---------length of thisfile[so][10]: 50\n",
      "---------length of thisfile[so][11]: 50\n",
      "---------length of thisfile[so][12]: 50\n",
      "---------length of thisfile[so][13]: 50\n",
      "---------length of thisfile[so][14]: 50\n",
      "---------length of thisfile[so][15]: 50\n",
      "---------length of thisfile[so][16]: 50\n",
      "---------length of thisfile[so][17]: 50\n",
      "---------length of thisfile[so][18]: 50\n",
      "---------length of thisfile[so][19]: 50\n",
      "------thisfile[clean]:\n",
      "-------length: \"clean\" appears 9 times in this file.\n",
      "---------length of thisfile[clean][1]: 50\n",
      "---------length of thisfile[clean][2]: 50\n",
      "---------length of thisfile[clean][3]: 50\n",
      "---------length of thisfile[clean][4]: 50\n",
      "---------length of thisfile[clean][5]: 50\n",
      "---------length of thisfile[clean][6]: 50\n",
      "---------length of thisfile[clean][7]: 50\n",
      "---------length of thisfile[clean][8]: 50\n",
      "---------length of thisfile[clean][9]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 8 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "------thisfile[more]:\n",
      "-------length: \"more\" appears 7 times in this file.\n",
      "---------length of thisfile[more][1]: 50\n",
      "---------length of thisfile[more][2]: 50\n",
      "---------length of thisfile[more][3]: 50\n",
      "---------length of thisfile[more][4]: 50\n",
      "---------length of thisfile[more][5]: 50\n",
      "---------length of thisfile[more][6]: 50\n",
      "---------length of thisfile[more][7]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV34.txt (5 keys):\n",
      "---keys: [u'not', u'when', u'most', 'so', u'more']\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 2 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 3 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "------thisfile[most]:\n",
      "-------length: \"most\" appears 2 times in this file.\n",
      "---------length of thisfile[most][1]: 50\n",
      "---------length of thisfile[most][2]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 3 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "------thisfile[more]:\n",
      "-------length: \"more\" appears 2 times in this file.\n",
      "---------length of thisfile[more][1]: 50\n",
      "---------length of thisfile[more][2]: 50\n"
     ]
    }
   ],
   "source": [
    "#######################            \n",
    "###Semantic analysis###\n",
    "#######################\n",
    "\n",
    "#Get context vectors\n",
    "loTest.getContextVectors(cvWindow)\n",
    "print('loTest.cvWindow: ' + str(loTest.cvWindow))\n",
    "\n",
    "#        self.cvWindow=k\n",
    "#        self.cvDict={}\n",
    "\n",
    "print('%%%%\\ncvDict, length ' + str(len(loTest.cvDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cvDict.keys()[:10])\n",
    "print('---the keywords each file:')\n",
    "for key in loTest.cvDict.keys():\n",
    "    print(key + ': ' + str(loTest.cvDict[key].keys()))\n",
    "print('%%%%%%%')\n",
    "#file1 = loTest.cvDict.keys()[0] #'./data_dsicap/IntegralYoga/raw/YV38.txt'\n",
    "    \n",
    "for file1 in loTest.cvDict.keys():    \n",
    "    first = loTest.cvDict[file1]\n",
    "    #print('---the first entry (length ' + str(len(first[first.keys()[0]])) + '):')\n",
    "    print('%%%%%\\n' + file1 + ' (' + str(len(first.keys())) + ' keys):')\n",
    "    print('---keys: ' + str(first.keys()))\n",
    "    for wordkey in first.keys():\n",
    "        print('------thisfile[' + wordkey + ']:')\n",
    "        tftk = first[wordkey]\n",
    "        print('-------length: \"' + wordkey + '\" appears ' + str(len(tftk.keys())) + ' times in this file.')\n",
    "        for numkey in tftk.keys():\n",
    "            print('---------length of thisfile[' + wordkey +'][' + str(numkey) + ']: ' + str(len(tftk[numkey])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['when', 'not', 'more', 'only', 'so', 'very', 'why', 'spiritual', 'clean', 'most']\n",
      "[0.670873416634855, 0.66478235750125025, 0.68892746971429009, nan, 0.71317730228338561, nan, nan, nan, 0.80586521750004081, 0.74469429533923281]\n"
     ]
    }
   ],
   "source": [
    "#Get average semantic density\n",
    "#avgSD=np.mean([x[1] for x in loTest.getSD(simCount)])\n",
    "#print(avgSD)\n",
    "\n",
    "SD = [x[1] for x in loTest.getSD(simCount)]\n",
    "print(len(SD))\n",
    "print(loTest.keywords)\n",
    "print(SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "###POS Tagging and Judgement Analysis###\n",
    "########################################\n",
    "judgementAvg=list(np.mean(np.array([[x[1],x[2]] for x in loTest.getJudgements()]),axis=0))\n",
    "\n",
    "########################\n",
    "###Sentiment Analysis###\n",
    "########################\n",
    "\n",
    "sentimentList=loTest.sentimentLookup()\n",
    "\n",
    "############################\n",
    "###Network Quantification###\n",
    "############################\n",
    "loTest.setNetwork(netAngle)\n",
    "\n",
    "avgEVC=loTest.evc()\n",
    "\n",
    "endTime=time.time()\n",
    "timeRun=endTime-startTime\n",
    "print('finished running'+'_'.join(groupId)+' in '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#Append outputs to masterOutput\n",
    "return(['_'.join(groupId)]+[len(subFileList),timeRun]+sentimentList+judgementAvg+[avgSD]+[avgEVC])   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
